id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/892:159,performance,Lock,Lock,159,"Hi @Axel-Naumann ,. a trivial use case could be:. ```. root -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();\"");};std::thread t(w);t.join()"". ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:159,security,Lock,Lock,159,"Hi @Axel-Naumann ,. a trivial use case could be:. ```. root -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();\"");};std::thread t(w);t.join()"". ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:498,deployability,build,build,498,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:591,deployability,patch,patch,591,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:453,energy efficiency,CPU,CPU,453,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:463,integrability,coupl,couple,463,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:463,modifiability,coupl,couple,463,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:125,performance,Lock,Lock,125,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:271,performance,deadlock,deadlock,271,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:453,performance,CPU,CPU,453,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:509,reliability,doe,does,509,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:591,safety,patch,patch,591,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:125,security,Lock,Lock,125,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:591,security,patch,patch,591,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:463,testability,coupl,couple,463,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:579,testability,verif,verify,579,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:297,usability,user,userland,297,"I tried. ```. root.exe -l -b -q -e ""ROOT::EnableThreadSafety();auto w = [&](){gInterpreter->ProcessLine(\""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();\"");};std::thread t(w);t.join()"". ```. and that works both with and without this PR. (Without the `UnLock()` I deadlock coming back from userland with this PR.). I also tried to *interpret* root/multicore/mt303, 304 and 305: 303 and 305 work, only 304 gets into an (near?) infinite loop (100% CPU for a couple of minutes in an llvm debug build). It does so with with and without this PR. I.e. I don't have a way yet to verify this patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:181,performance,Lock,Lock,181,"Hi,. indeed it does not work if it is one single line. Try it as a macro:. ```. void a(){. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();"");};. std::thread t(w);. t.join();. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:15,reliability,doe,does,15,"Hi,. indeed it does not work if it is one single line. Try it as a macro:. ```. void a(){. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();"");};. std::thread t(w);. t.join();. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:181,security,Lock,Lock,181,"Hi,. indeed it does not work if it is one single line. Try it as a macro:. ```. void a(){. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();"");};. std::thread t(w);. t.join();. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:303,deployability,patch,patch,303,"This code. ```. #include ""TROOT.h"". #include ""TInterpreter.h"". #include <thread>. void clinglock() {. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();"");};. std::thread t(w);. t.join();. }. ```. works both before and after my patch, both compiled and interpreted, both as a parameter to root.exe and as "".x"". I.e. I still don't know what I'm fixing :-(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:351,modifiability,paramet,parameter,351,"This code. ```. #include ""TROOT.h"". #include ""TInterpreter.h"". #include <thread>. void clinglock() {. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();"");};. std::thread t(w);. t.join();. }. ```. works both before and after my patch, both compiled and interpreted, both as a parameter to root.exe and as "".x"". I.e. I still don't know what I'm fixing :-(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:192,performance,Lock,Lock,192,"This code. ```. #include ""TROOT.h"". #include ""TInterpreter.h"". #include <thread>. void clinglock() {. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();"");};. std::thread t(w);. t.join();. }. ```. works both before and after my patch, both compiled and interpreted, both as a parameter to root.exe and as "".x"". I.e. I still don't know what I'm fixing :-(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:303,safety,patch,patch,303,"This code. ```. #include ""TROOT.h"". #include ""TInterpreter.h"". #include <thread>. void clinglock() {. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();"");};. std::thread t(w);. t.join();. }. ```. works both before and after my patch, both compiled and interpreted, both as a parameter to root.exe and as "".x"". I.e. I still don't know what I'm fixing :-(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:192,security,Lock,Lock,192,"This code. ```. #include ""TROOT.h"". #include ""TInterpreter.h"". #include <thread>. void clinglock() {. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();"");};. std::thread t(w);. t.join();. }. ```. works both before and after my patch, both compiled and interpreted, both as a parameter to root.exe and as "".x"". I.e. I still don't know what I'm fixing :-(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:303,security,patch,patch,303,"This code. ```. #include ""TROOT.h"". #include ""TInterpreter.h"". #include <thread>. void clinglock() {. ROOT::EnableThreadSafety();. auto w = [&](){gInterpreter->ProcessLine(""gInterpreterMutex->Lock();gInterpreterMutex->UnLock();"");};. std::thread t(w);. t.join();. }. ```. works both before and after my patch, both compiled and interpreted, both as a parameter to root.exe and as "".x"". I.e. I still don't know what I'm fixing :-(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:25,performance,deadlock,deadlock,25,"Hi,. this does trigger a deadlock on my machine. I think it's best to look at this together...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:10,reliability,doe,does,10,"Hi,. this does trigger a deadlock on my machine. I think it's best to look at this together...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:263,performance,lock,lock,263,"> and that works both with and without this PR. Yes that it is expected. It is fundamental that the enable thread safety and the thread lauching are in *two* different Cling transaction. This is because before the thread safely in enabled there is (of course) no lock being taken. So try. ```. root.exe -b -l -e ""ROOT::EnableThreadSafety();"" -e ""std::thread([](){gInterpreter->ProcessLine(\""printf(\\\""Stuck\\\"")\"");}).join()"" -q. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:114,safety,safe,safety,114,"> and that works both with and without this PR. Yes that it is expected. It is fundamental that the enable thread safety and the thread lauching are in *two* different Cling transaction. This is because before the thread safely in enabled there is (of course) no lock being taken. So try. ```. root.exe -b -l -e ""ROOT::EnableThreadSafety();"" -e ""std::thread([](){gInterpreter->ProcessLine(\""printf(\\\""Stuck\\\"")\"");}).join()"" -q. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:221,safety,safe,safely,221,"> and that works both with and without this PR. Yes that it is expected. It is fundamental that the enable thread safety and the thread lauching are in *two* different Cling transaction. This is because before the thread safely in enabled there is (of course) no lock being taken. So try. ```. root.exe -b -l -e ""ROOT::EnableThreadSafety();"" -e ""std::thread([](){gInterpreter->ProcessLine(\""printf(\\\""Stuck\\\"")\"");}).join()"" -q. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:263,security,lock,lock,263,"> and that works both with and without this PR. Yes that it is expected. It is fundamental that the enable thread safety and the thread lauching are in *two* different Cling transaction. This is because before the thread safely in enabled there is (of course) no lock being taken. So try. ```. root.exe -b -l -e ""ROOT::EnableThreadSafety();"" -e ""std::thread([](){gInterpreter->ProcessLine(\""printf(\\\""Stuck\\\"")\"");}).join()"" -q. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:21,performance,deadlock,deadlock,21,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:127,performance,deadlock,deadlock,127,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:151,performance,deadlock,deadlock,151,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:355,performance,lock,lock,355,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:398,performance,lock,lock,398,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:455,performance,deadlock,deadlock,455,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:645,performance,deadlock,deadlocked,645,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:694,performance,lock,lock,694,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1067,performance,content,content,1067,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1086,performance,lock,lock,1086,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1263,performance,lock,lock,1263,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1522,performance,lock,lock,1522,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1750,performance,deadlock,deadlock,1750,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:355,security,lock,lock,355,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:398,security,lock,lock,398,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:694,security,lock,lock,694,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1086,security,lock,lock,1086,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1124,security,access,access,1124,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1263,security,lock,lock,1263,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:1522,security,lock,lock,1522,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:178,testability,emul,emulate,178,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:474,testability,Emul,Emulate,474,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:957,testability,simul,simulate,957,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:712,usability,user,user,712,"Also the file below (deadlock.cxx) is a Cling standalone reproducer of the mechanics of the problem. To use:. ```. root [0] .L deadlock.cxx+. root [1] deadlock(false); // Do not emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. Work being done within the lock of Second. Work being done within the lock of First. We successfully reached the end. root [2] deadlock(true); // Emulate the 'protection' the internal of cling. WWoouulldd eexxeeccuuttee:: WWoorrkk((**((ssttdd::::ssttrriinngg**))00xx770000000000100830ee3300));;. ..... Process is now deadlocked ..... i.e. the point is that the same lock taken by the user code (Function Work) must be the same as the one used to 'protect the internal of cling'. ```. ```. #include <mutex>. #include <thread>. #include <iostream>. #include <sstream>. std::mutex gMutex;. void Work(const std::string &name). {. // simulate a long page fetch. std::this_thread::sleep_for(std::chrono::seconds(2));. std::string result = ""fake content"";. // This lock would be taken indirectly by any access to the global database. // (TClass, TCling, etc..). std::lock_guard<std::mutex> guard(gMutex);. cerr << ""Work being done within the lock of "" << name << '\n';. }. void IndirectWork(const std::string &name, bool takelock). {. std::stringstream cmd;. cmd << ""Work(*(std::string*)"";. cmd << (void*)&name;. cmd << "");"" ;. cerr << ""Would execute: "" << cmd.str()<< '\n';. if (takelock) {. // This lock is taken by gROOT->ProcessLine. std::lock_guard<std::mutex> guard(gMutex);. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. } else {. /*. interpreter->execute(cmd.str().c_str());. */. Work(name);. }. }. void deadlock(bool takelock = true). {. std::thread t1(IndirectWork, ""First"", takelock);. std::thread t2(IndirectWork, ""Second"", takelock);. t1.join();. t2.join();. cerr << ""We successfully reached the end.\n"";. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:152,interoperability,specif,specific,152,"Did you try a pertubation of the example that make sure the nested-lock taking is induced by interpreter level static initialization? Even without this specific test, this looks good to do ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:67,performance,lock,lock,67,"Did you try a pertubation of the example that make sure the nested-lock taking is induced by interpreter level static initialization? Even without this specific test, this looks good to do ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:161,safety,test,test,161,"Did you try a pertubation of the example that make sure the nested-lock taking is induced by interpreter level static initialization? Even without this specific test, this looks good to do ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:67,security,lock,lock,67,"Did you try a pertubation of the example that make sure the nested-lock taking is induced by interpreter level static initialization? Even without this specific test, this looks good to do ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:161,testability,test,test,161,"Did you try a pertubation of the example that make sure the nested-lock taking is induced by interpreter level static initialization? Even without this specific test, this looks good to do ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/893:158,performance,disk,disk,158,"Hi @vgvassilev, . nice and clean! I have two questions:. 1) why do you say ""should""? 2) does this imply that the files in the pch can also be absent from the disk?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:88,reliability,doe,does,88,"Hi @vgvassilev, . nice and clean! I have two questions:. 1) why do you say ""should""? 2) does this imply that the files in the pch can also be absent from the disk?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:67,availability,sla,slate,67,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:101,deployability,patch,patches,101,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:175,performance,disk,disk,175,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:67,reliability,sla,slate,67,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:101,safety,patch,patches,101,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:101,security,patch,patches,101,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:38,usability,progress,progress,38,"I say 'should' because that's work in progress. Once I get a clean slate I will start reverting some patches in clang. Yes, it should be possible to get rid from the files on disk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/898:37,deployability,build,builds,37,"Just for the record, all the Jenkins builds passed, but I just rewrote the commit message so Jenkins is rebuilding it without any changes. Any objections to get this merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/898:82,integrability,messag,message,82,"Just for the record, all the Jenkins builds passed, but I just rewrote the commit message so Jenkins is rebuilding it without any changes. Any objections to get this merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/898:82,interoperability,messag,message,82,"Just for the record, all the Jenkins builds passed, but I just rewrote the commit message so Jenkins is rebuilding it without any changes. Any objections to get this merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/899:23,deployability,patch,patch,23,"Javier is testing this patch, so I marked as do-not-merge until I get positive feedback here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:10,safety,test,testing,10,"Javier is testing this patch, so I marked as do-not-merge until I get positive feedback here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:23,safety,patch,patch,23,"Javier is testing this patch, so I marked as do-not-merge until I get positive feedback here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:23,security,patch,patch,23,"Javier is testing this patch, so I marked as do-not-merge until I get positive feedback here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:10,testability,test,testing,10,"Javier is testing this patch, so I marked as do-not-merge until I get positive feedback here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:79,usability,feedback,feedback,79,"Javier is testing this patch, so I marked as do-not-merge until I get positive feedback here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/902:859,availability,state,state,859,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1160,availability,operat,operation,1160,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:647,deployability,modul,modules,647,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:238,energy efficiency,current,currently,238,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1034,energy efficiency,reduc,reduce,1034,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:859,integrability,state,state,859,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:899,integrability,wrap,wrapper,899,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:100,interoperability,registr,registry,100,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:440,interoperability,semant,semantically,440,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:899,interoperability,wrapper,wrapper,899,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1712,interoperability,registr,registration,1712,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1795,interoperability,registr,registry,1795,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:14,modifiability,concern,concerned,14,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:647,modifiability,modul,modules,647,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:790,modifiability,scal,scalability,790,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1835,modifiability,scal,scalability,1835,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:741,performance,parallel,parallel,741,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:790,performance,scalab,scalability,790,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:965,performance,lock,lock,965,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1041,performance,content,contention,1041,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1195,performance,lock,lock,1195,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1306,performance,lock,lock,1306,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1332,performance,deadlock,deadlocks,1332,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1390,performance,lock,locks,1390,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1440,performance,lock,lock,1440,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1578,performance,parallel,parallel,1578,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1699,performance,multi-thread,multi-thread,1699,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1835,performance,scalab,scalability,1835,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:416,safety,avoid,avoid,416,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:647,safety,modul,modules,647,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:841,safety,compl,completely,841,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:133,security,ident,identified,133,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:841,security,compl,completely,841,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:965,security,lock,lock,965,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1113,security,sign,significant,1113,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1195,security,lock,lock,1195,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1306,security,lock,lock,1306,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1390,security,lock,locks,1390,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1440,security,lock,lock,1440,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:14,testability,concern,concerned,14,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1820,testability,understand,understand,1820,"I am a little concerned about the basic idea. If I understood correctly, there is a (unique) global registry where the histogram are identified based on their 'full path name' (beside the fact that GetNameForRanges seems both brittle and currently seems on first reading 'wrong'/'not-as-intended'). I see two major problems, one is that the 'full path name' may never be really unique i.e. it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This would both reduce contention and guarantees that the histograms are really related. A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). A 4th deficiency is that once activated for one histogram it *seems* to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. And that remind me, that another challenge for the 'unique registry' solution is to understand its scalability where reaching 10 to 100 thousands histograms. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:551,availability,state,state,551,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1095,availability,operat,operation,1095,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:275,deployability,modul,modules,275,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:728,energy efficiency,reduc,reduce,728,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:883,energy efficiency,draw,drawback,883,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:551,integrability,state,state,551,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:591,integrability,wrap,wrapper,591,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:68,interoperability,semant,semantically,68,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:591,interoperability,wrapper,wrapper,591,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1719,interoperability,registr,registration,1719,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:275,modifiability,modul,modules,275,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:480,modifiability,scal,scalability,480,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:431,performance,parallel,parallel,431,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:480,performance,scalab,scalability,480,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:657,performance,lock,lock,657,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:735,performance,content,contention,735,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1130,performance,lock,lock,1130,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1241,performance,lock,lock,1241,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1267,performance,deadlock,deadlocks,1267,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1325,performance,lock,locks,1325,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1375,performance,lock,lock,1375,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1585,performance,parallel,parallel,1585,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1706,performance,multi-thread,multi-thread,1706,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:44,safety,avoid,avoid,44,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:275,safety,modul,modules,275,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:533,safety,compl,completely,533,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:533,security,compl,completely,533,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:657,security,lock,lock,657,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:865,security,control,control,865,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1048,security,sign,significant,1048,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1130,security,lock,lock,1130,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1241,security,lock,lock,1241,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1325,security,lock,locks,1325,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1375,security,lock,lock,1375,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:865,testability,control,control,865,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1394,testability,understand,understand,1394,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1441,usability,close,closer,1441,"Hi Philippe,. . > it might be impossible to avoid synonyms that are semantically distincts ... a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Good point. I admit that did not really think to this case. > The other major problem is that it unnecessary tie (via that global mutex) all the 'parallel' histogram, this means that the overall scalability is inherently decreased. > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. > This would both reduce contention and guarantees that the histograms are really related. I agree on this and TThreadedObject could be the place where to control this. The drawback is that we would then not have a solution outside TThreadedObject, i.e. we will have to find a way to force the use of TThreadedObject in MT cases. > A 3rd significant problem (but fixeable) is that the operation covered by the ReadWrite lock are not atomic (and/or trivial) and for the look of it could plausibly indirectly request the ROOT global lock and thus can lead to deadlocks (from some other code that hold the ROOT global locks and request the Write part of the ReadWrite lock). Not sure to understand, you mean FindObject? I will have a closer look. > A 4th deficiency is that once activated for one histogram it seems to apply to all histogram. i.e. as far as can tell if you one parallel histograms and 10,000 single-thread histograms, filling the single-thread histogram still has to go through the multi-thread registration/mechanism. Ok, a solution 'per histogram' would also address this. Thanks for going deep into it,. Gerri.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:121,deployability,depend,depending,121,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:138,deployability,contain,container,138,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:178,deployability,contain,containee,178,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:121,integrability,depend,depending,121,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:121,modifiability,depend,depending,121,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:102,performance,lock,lock,102,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:260,performance,lock,lock,260,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:360,performance,lock,lock,360,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:415,performance,lock,locked,415,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:121,safety,depend,depending,121,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:102,security,lock,lock,102,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:260,security,lock,lock,260,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:360,security,lock,lock,360,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:415,security,lock,locked,415,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:14,testability,understand,understand,14,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:121,testability,depend,depending,121,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:63,usability,close,closer,63,"> Not sure to understand, you mean FindObject? > I will have a closer look. FindObject might take the lock (or might not depending on the container and the implementation of the containee's function that are called). 'Warning' for sure (sometimes) request the lock as if I recall correctly it uses TClass inside. etc... I.e. if you are not using the ROOT main lock, you must be *very* careful of what is inside the locked section ... and as always might it as 'small' as possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:231,integrability,wrap,wrapper,231,> i.e. we will have to find a way to force the use of TThreadedObject in MT cases. I am not sure what you mean :). We would be saying that if one want the internal implementation of MT histogram then you have to use this (or that) wrapper to enable it.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:231,interoperability,wrapper,wrapper,231,> i.e. we will have to find a way to force the use of TThreadedObject in MT cases. I am not sure what you mean :). We would be saying that if one want the internal implementation of MT histogram then you have to use this (or that) wrapper to enable it.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:663,availability,state,state,663,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1315,availability,consist,consistent,1315,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:332,deployability,modul,modules,332,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:663,integrability,state,state,663,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:703,integrability,wrap,wrapper,703,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:703,interoperability,wrapper,wrapper,703,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:332,modifiability,modul,modules,332,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:470,performance,synch,synchronize,470,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:769,performance,lock,lock,769,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1055,reliability,doe,does,1055,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:332,safety,modul,modules,332,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:645,safety,compl,completely,645,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:401,security,ident,identifier,401,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:645,security,compl,completely,645,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:769,security,lock,lock,769,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:52,usability,close,close,52,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:342,usability,Support,Supporting,342,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:613,usability,support,supporting,613,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1113,usability,behavi,behavior,1113,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1315,usability,consist,consistent,1315,"Hi,. After some more thinking, I believe we have to close this and rethink the all thing. I found particularly tricky this point raised by Philippe:. > a good example is two free standings (not attached to any directory) histograms that happens to have the same name in two distinct and independent part of the code (e.g. two CMSSW modules). Supporting this case makes basically impossible to have an identifier for the histogram. In this moment I do not see how we can synchronize objects that we cannot somehow tag being together. In PROOF we somehow implicitly assumed that this could not happen (PROOF is not supporting it). > Rather than a completely global state, wouldn't it make sense to have a wrapper object (for example TThreadedObject) be the holder of the lock and list for a single set of related histogram. This looked an appealing idea. However, it means that the member of a TThreadedObject has to know that is part of a TThreadedObject (which is not the case now) or that we should have a specialized TThreadedObject for histograms that does some settings on the histograms to steer the special behavior. And remains the fact that people will be forced to use a TThreadedObject (which may be ok). Perhaps it is also worth to investigate if we can find an improved bin-finding algorithm that gives consistent binnings in the first place that can be merged. That would solve the problem at the roots. Cheers,. Gerri .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/904:153,availability,error,error,153,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:173,deployability,fail,failing,173,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:4,energy efficiency,current,currently,4,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:153,performance,error,error,153,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:173,reliability,fail,failing,173,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:30,safety,test,tests,30,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:43,safety,test,test,43,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:153,safety,error,error,153,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:181,safety,test,test,181,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:30,testability,test,tests,30,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:43,testability,test,test,43,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:181,testability,test,test,181,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:153,usability,error,error,153,I'm currently debugging a few tests in the test suite and with this change I don't have to search the CMake files to find out what the actually expected error code is for a failing test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/905:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/905:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/905:9,deployability,build,build,9,Previous build could not fetch git.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/906:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/906
https://github.com/root-project/root/pull/906:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/906
https://github.com/root-project/root/pull/907:138,integrability,interfac,interface,138,"As a side note, the combination of file move + functional change in a single commit seem to make it hard to see differences in the github interface :(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:138,interoperability,interfac,interface,138,"As a side note, the combination of file move + functional change in a single commit seem to make it hard to see differences in the github interface :(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:138,modifiability,interfac,interface,138,"As a side note, the combination of file move + functional change in a single commit seem to make it hard to see differences in the github interface :(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:53,interoperability,format,format,53,@bbockelm I am merging this PR as-is to get the file format change in as soon as possible. Please send a PR addressing the header copy/paste asap. Also do not forget to backport to v5.34 immediately ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:18,testability,understand,understand,18,@pcanal - I don't understand your comment about the headers. I thought I had explicitly said this in the comments already in the file?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/908:75,deployability,build,build,75,"@pcanal This isn't really work in progress, I just wanted to test that the build would pass. Actually, if you think this commit is ok, we can merge this now, but please let me merge it myself locally, otherwise the GPG signature on the commit is lost.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:61,safety,test,test,61,"@pcanal This isn't really work in progress, I just wanted to test that the build would pass. Actually, if you think this commit is ok, we can merge this now, but please let me merge it myself locally, otherwise the GPG signature on the commit is lost.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:219,security,sign,signature,219,"@pcanal This isn't really work in progress, I just wanted to test that the build would pass. Actually, if you think this commit is ok, we can merge this now, but please let me merge it myself locally, otherwise the GPG signature on the commit is lost.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:61,testability,test,test,61,"@pcanal This isn't really work in progress, I just wanted to test that the build would pass. Actually, if you think this commit is ok, we can merge this now, but please let me merge it myself locally, otherwise the GPG signature on the commit is lost.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:34,usability,progress,progress,34,"@pcanal This isn't really work in progress, I just wanted to test that the build would pass. Actually, if you think this commit is ok, we can merge this now, but please let me merge it myself locally, otherwise the GPG signature on the commit is lost.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:191,availability,sli,slightly,191,"> but please let me merge it myself locally, otherwise the GPG signature on the commit is lost. What do you mean? How is that different from other PR? > if you think this commit is ok. I am 'slightly' surprised it works in C++11 ... .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:191,reliability,sli,slightly,191,"> but please let me merge it myself locally, otherwise the GPG signature on the commit is lost. What do you mean? How is that different from other PR? > if you think this commit is ok. I am 'slightly' surprised it works in C++11 ... .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:63,security,sign,signature,63,"> but please let me merge it myself locally, otherwise the GPG signature on the commit is lost. What do you mean? How is that different from other PR? > if you think this commit is ok. I am 'slightly' surprised it works in C++11 ... .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:365,deployability,contain,containers,365,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:280,energy efficiency,optim,optimizations,280,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:11,integrability,interfac,interface,11,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:11,interoperability,interfac,interface,11,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:11,modifiability,interfac,interface,11,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:276,performance,I/O,I/O,276,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:280,performance,optimiz,optimizations,280,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:340,safety,test,test,340,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:32,security,sign,signatures,32,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:164,security,sign,signatures,164,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:340,testability,test,test,340,"The GitHub interface strips GPG signatures from the commits. I usually merge on my laptop and push, and that way it's as if I pressed merge, but I can keep the GPG signatures. As for the commit, if you look at the date, you'll see it's from a while ago, when I was working on I/O optimizations. I was just trying to improve readability and test range for with ROOT containers. Yes, it works :-) So, I guess we should be trying to use this more than the usual while loop. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:25,security,sign,signatures,25,> but I can keep the GPG signatures. What is the advantage/gain/importance of doing so?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:154,safety,compl,complicated,154,"The advantage in keeping GPG signatures is that it tells people that the change came from a trusted source. We should all be doing this, but due to being complicated, I understand that others don't bother.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:29,security,sign,signatures,29,"The advantage in keeping GPG signatures is that it tells people that the change came from a trusted source. We should all be doing this, but due to being complicated, I understand that others don't bother.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:92,security,trust,trusted,92,"The advantage in keeping GPG signatures is that it tells people that the change came from a trusted source. We should all be doing this, but due to being complicated, I understand that others don't bother.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:154,security,compl,complicated,154,"The advantage in keeping GPG signatures is that it tells people that the change came from a trusted source. We should all be doing this, but due to being complicated, I understand that others don't bother.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:169,testability,understand,understand,169,"The advantage in keeping GPG signatures is that it tells people that the change came from a trusted source. We should all be doing this, but due to being complicated, I understand that others don't bother.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:275,availability,sli,slightly,275,"> Let's not sidestep a 5 line commit into a lenghty discussion on code patterns. My points were triggered by your good point:. > So, I guess we should be trying to use this more than the usual while loop. . where I think to be really recommended as the new pattern we should slightly improve on it. Could you, as a subsequent PR, try to improve the collection in the direction I mentioned (assuming you agree it is 'even' better :) . Anyway. > If you disagree that the code is more readable. I agree it is more readable except for the ```auto method``` which should go back to ```TFunction *method```. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:315,integrability,sub,subsequent,315,"> Let's not sidestep a 5 line commit into a lenghty discussion on code patterns. My points were triggered by your good point:. > So, I guess we should be trying to use this more than the usual while loop. . where I think to be really recommended as the new pattern we should slightly improve on it. Could you, as a subsequent PR, try to improve the collection in the direction I mentioned (assuming you agree it is 'even' better :) . Anyway. > If you disagree that the code is more readable. I agree it is more readable except for the ```auto method``` which should go back to ```TFunction *method```. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:275,reliability,sli,slightly,275,"> Let's not sidestep a 5 line commit into a lenghty discussion on code patterns. My points were triggered by your good point:. > So, I guess we should be trying to use this more than the usual while loop. . where I think to be really recommended as the new pattern we should slightly improve on it. Could you, as a subsequent PR, try to improve the collection in the direction I mentioned (assuming you agree it is 'even' better :) . Anyway. > If you disagree that the code is more readable. I agree it is more readable except for the ```auto method``` which should go back to ```TFunction *method```. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:520,safety,except,except,520,"> Let's not sidestep a 5 line commit into a lenghty discussion on code patterns. My points were triggered by your good point:. > So, I guess we should be trying to use this more than the usual while loop. . where I think to be really recommended as the new pattern we should slightly improve on it. Could you, as a subsequent PR, try to improve the collection in the direction I mentioned (assuming you agree it is 'even' better :) . Anyway. > If you disagree that the code is more readable. I agree it is more readable except for the ```auto method``` which should go back to ```TFunction *method```. Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:214,deployability,Contain,ContaineeIs,214,> By improve the collection you mean changing all while loops to range fors? Not quite (as this might be a good thing for the code refactoring tool to do). . I mean to enable something like:. ```. for (auto item : ContaineeIs<TBaseClass*>(GetListOfBases())). if (auto base = item->GetClassPointer()). ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:131,modifiability,refact,refactoring,131,> By improve the collection you mean changing all while loops to range fors? Not quite (as this might be a good thing for the code refactoring tool to do). . I mean to enable something like:. ```. for (auto item : ContaineeIs<TBaseClass*>(GetListOfBases())). if (auto base = item->GetClassPointer()). ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:131,performance,refactor,refactoring,131,> By improve the collection you mean changing all while loops to range fors? Not quite (as this might be a good thing for the code refactoring tool to do). . I mean to enable something like:. ```. for (auto item : ContaineeIs<TBaseClass*>(GetListOfBases())). if (auto base = item->GetClassPointer()). ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:143,usability,tool,tool,143,> By improve the collection you mean changing all while loops to range fors? Not quite (as this might be a good thing for the code refactoring tool to do). . I mean to enable something like:. ```. for (auto item : ContaineeIs<TBaseClass*>(GetListOfBases())). if (auto base = item->GetClassPointer()). ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:23,safety,compl,complicated,23,"Sure, I don't know how complicated that may be, but if it's doable, we can try in a later PR. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:23,security,compl,complicated,23,"Sure, I don't know how complicated that may be, but if it's doable, we can try in a later PR. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/910:29,deployability,patch,patch,29,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:41,energy efficiency,current,currently,41,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:29,safety,patch,patch,29,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:96,safety,review,review,96,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:122,safety,test,tests,122,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:29,security,patch,patch,29,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:96,testability,review,review,96,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:122,testability,test,tests,122,"@vgvassilev I already have a patch, it's currently running on my clang CI instance. I'll open a review once it passes the tests. See: https://teemperor.de/ccir/git:FixVFSinCI",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:8,safety,review,reviews,8,https://reviews.llvm.org/D37416,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:8,testability,review,reviews,8,https://reviews.llvm.org/D37416,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:33,safety,review,reviews,33,"This PR is superseded by https://reviews.llvm.org/D37416. Once it is committed, it will be backported in a separate PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:33,testability,review,reviews,33,"This PR is superseded by https://reviews.llvm.org/D37416. Once it is committed, it will be backported in a separate PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/911:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/912:21,energy efficiency,green,green,21,"LGTM if the bots are green. I'd expect, in long term, to avoid calling the entire routine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/912:82,integrability,rout,routine,82,"LGTM if the bots are green. I'd expect, in long term, to avoid calling the entire routine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/912:57,safety,avoid,avoid,57,"LGTM if the bots are green. I'd expect, in long term, to avoid calling the entire routine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/912:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/913:11,deployability,build,build,11,"@phsft-bot build. I think that can go in as-is. But Jenkins seems to have died compiling this, so let's see give it another chance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/913:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/914:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/915:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:114,deployability,modul,module,114,"@Teemperor, could you fix the clang-format issue? I am a little worried that we assume *all* decls have an owning module. This however is the direction clang is taking and even if we could have a few corner cases I agree that's the way to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:36,interoperability,format,format,36,"@Teemperor, could you fix the clang-format issue? I am a little worried that we assume *all* decls have an owning module. This however is the direction clang is taking and even if we could have a few corner cases I agree that's the way to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:114,modifiability,modul,module,114,"@Teemperor, could you fix the clang-format issue? I am a little worried that we assume *all* decls have an owning module. This however is the direction clang is taking and even if we could have a few corner cases I agree that's the way to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:114,safety,modul,module,114,"@Teemperor, could you fix the clang-format issue? I am a little worried that we assume *all* decls have an owning module. This however is the direction clang is taking and even if we could have a few corner cases I agree that's the way to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/916:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:15,deployability,patch,patch,15,Thanks for the patch!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:15,safety,patch,patch,15,Thanks for the patch!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:15,security,patch,patch,15,Thanks for the patch!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/921:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:11,deployability,build,build,11,@phsft-bot build with flags -Dclingtest=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:4,deployability,fail,failing,4,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:39,deployability,fail,failing,39,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:4,reliability,fail,failing,4,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:39,reliability,fail,failing,39,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:26,safety,test,test,26,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:26,testability,test,test,26,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:75,testability,regress,regression,75,"The failing count include test is also failing in master, so this is not a regression: https://github.com/root-project/root/pull/962#issuecomment-328043968",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:11,deployability,build,build,11,@phsft-bot build with flags -Dclingtest=Off. let's make sure it's not breaking master,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:62,energy efficiency,green,green,62,Added do not merge as Jenkins is restating so this only looks green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:11,deployability,build,build,11,@phsft-bot build. EDIT: Jenkins is dead...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/923:39,deployability,build,builds,39,Let's see how much this will break the builds as I have no idea what happens to all our header/source globbing...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:47,availability,error,error,47,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:161,availability,error,error,161,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:58,deployability,build,building,58,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:89,deployability,contain,contains,89,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:167,integrability,messag,messages,167,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:167,interoperability,messag,messages,167,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:47,performance,error,error,47,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:161,performance,error,error,161,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:47,safety,error,error,47,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:161,safety,error,error,161,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:47,usability,error,error,47,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:110,usability,support,supported,110,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:131,usability,user,users,131,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:161,usability,error,error,161,"If we don't fix this, then maybe we just add a error that building from a directory that contains `*?+` isn't supported. Otherwise users just get really cryptic error messages.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:17,deployability,continu,continue,17,As long as I can continue to call my directory `');DROP TABLE Students;--`...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:118,deployability,build,build,118,"@Axel-Naumann well, if you put "";"" into the path, then everything explodes. Seems like little bobby tables will never build root in his home directory.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/924:19,availability,failur,failure,19,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:19,deployability,fail,failure,19,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:84,modifiability,concern,concerned,84,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:19,performance,failur,failure,19,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:19,reliability,fail,failure,19,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:14,safety,test,test,14,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:14,testability,test,test,14,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:84,testability,concern,concerned,84,"The dataframe test failure is expected and fixed by a PR in roottest, as far as I'm concerned this PR is good to go :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/925:18,safety,Test,Testing,18,"> Isn't it wrong? Testing floating point for equality is numerically unstable, isn't it? Normal float representation is 1.2345e67. But in trivial cases (like 1 or 2 or 35) integer is much shorter. Yes, `value == std::nearbyint(value)` not always return true for real integer, but this should not be a problem. In such case one just gets value like ""5.0000001e1"". And such value absolutely ok - other side should not expect integer at this place anyway. This is just to save space in produced JSON string.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/925
https://github.com/root-project/root/pull/925:18,testability,Test,Testing,18,"> Isn't it wrong? Testing floating point for equality is numerically unstable, isn't it? Normal float representation is 1.2345e67. But in trivial cases (like 1 or 2 or 35) integer is much shorter. Yes, `value == std::nearbyint(value)` not always return true for real integer, but this should not be a problem. In such case one just gets value like ""5.0000001e1"". And such value absolutely ok - other side should not expect integer at this place anyway. This is just to save space in produced JSON string.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/925
https://github.com/root-project/root/pull/925:238,integrability,event,eventually,238,"Fair enough (then my first recommendation is entirely useless), but please do add a comment expressing what is the intent (i.e. replace only *exact* match to integer or something like you say in your reply :) ). [Otherwise the code will 'eventually' be 'fixed' (wrongly) later on :) ] . Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/925
https://github.com/root-project/root/pull/926:102,energy efficiency,current,currently,102,"@bbockelm Before we can merge this, we need to test with both builtin and external lz4, since ROOT is currently broken with the latter (not caught by PR tests).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:47,safety,test,test,47,"@bbockelm Before we can merge this, we need to test with both builtin and external lz4, since ROOT is currently broken with the latter (not caught by PR tests).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:153,safety,test,tests,153,"@bbockelm Before we can merge this, we need to test with both builtin and external lz4, since ROOT is currently broken with the latter (not caught by PR tests).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:47,testability,test,test,47,"@bbockelm Before we can merge this, we need to test with both builtin and external lz4, since ROOT is currently broken with the latter (not caught by PR tests).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:153,testability,test,tests,153,"@bbockelm Before we can merge this, we need to test with both builtin and external lz4, since ROOT is currently broken with the latter (not caught by PR tests).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:0,deployability,Updat,Updated,0,Updated PR: https://github.com/root-project/root/pull/1012,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:0,safety,Updat,Updated,0,Updated PR: https://github.com/root-project/root/pull/1012,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:0,security,Updat,Updated,0,Updated PR: https://github.com/root-project/root/pull/1012,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:15,usability,close,close,15,Should we just close this PR then and use the newer one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/927:45,availability,error,error,45,"Thanks Oksana! For reference, this fixes the error shown below:. http://cdash.cern.ch/viewBuildError.php?buildid=391981",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:105,deployability,build,buildid,105,"Thanks Oksana! For reference, this fixes the error shown below:. http://cdash.cern.ch/viewBuildError.php?buildid=391981",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:45,performance,error,error,45,"Thanks Oksana! For reference, this fixes the error shown below:. http://cdash.cern.ch/viewBuildError.php?buildid=391981",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:45,safety,error,error,45,"Thanks Oksana! For reference, this fixes the error shown below:. http://cdash.cern.ch/viewBuildError.php?buildid=391981",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:45,usability,error,error,45,"Thanks Oksana! For reference, this fixes the error shown below:. http://cdash.cern.ch/viewBuildError.php?buildid=391981",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:11,deployability,build,build,11,@phsft-bot build just on ubuntu14/classic,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/928:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/930:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_cxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_cxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_cxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:74,availability,error,errors,74,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:37,deployability,modul,modulemap,37,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:47,interoperability,mismatch,mismatches,47,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:37,modifiability,modul,modulemap,37,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:74,performance,error,errors,74,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:37,safety,modul,modulemap,37,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:74,safety,error,errors,74,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:74,usability,error,errors,74,"Ok, the warnings are for the obvious modulemap mismatches we have and the errors are due to the yet missing VFS mapping. Can we get this in that I can make the follow up PRs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/934:94,safety,compl,complete,94,"Hi @bluehood , this is exactly the feature we discussed a while ago. To make the PR even more complete, I could suggest a gtest for TThreadedObject, which would also increase our coverage given that it is a template.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:94,security,compl,complete,94,"Hi @bluehood , this is exactly the feature we discussed a while ago. To make the PR even more complete, I could suggest a gtest for TThreadedObject, which would also increase our coverage given that it is a template.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:179,testability,coverag,coverage,179,"Hi @bluehood , this is exactly the feature we discussed a while ago. To make the PR even more complete, I could suggest a gtest for TThreadedObject, which would also increase our coverage given that it is a template.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/935:49,integrability,configur,configure,49,Aren't those change also needed in spirit in the configure/make files? Won't we need them for the backport to 5.34 for example?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:49,modifiability,configur,configure,49,Aren't those change also needed in spirit in the configure/make files? Won't we need them for the backport to 5.34 for example?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:49,security,configur,configure,49,Aren't those change also needed in spirit in the configure/make files? Won't we need them for the backport to 5.34 for example?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:109,deployability,build,build,109,"Yes, in order to backport, we have to take master as it is, since there were a few problems with the classic build that were fixed today with bb0e8b08784f47add12939a874eb009954d8e77a. We will also need to fix xxhash externals in the classic build, or stick with the builtin LZ4 on classic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:241,deployability,build,build,241,"Yes, in order to backport, we have to take master as it is, since there were a few problems with the classic build that were fixed today with bb0e8b08784f47add12939a874eb009954d8e77a. We will also need to fix xxhash externals in the classic build, or stick with the builtin LZ4 on classic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/936:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:333,availability,error,error,333,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:17,integrability,discover,discovered,17,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:17,interoperability,discover,discovered,17,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:333,performance,error,error,333,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:333,safety,error,error,333,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:17,usability,discov,discovered,17,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:333,usability,error,error,333,"(As it seems you discovered :)), the source file of those dictionaries must be distinct as one of the mechanism used for bootstrapping is function overload resolution based on the requested types. However since TemplateName<double> and TemplateName<Double32_t> are, for the C++ compiler, the same name we end with both a compilation error and if the compile succeeds then a call to the 'wrong' function and/or a missing call to one of the two (similar) overloads.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/937:195,testability,simpl,simplified,195,"Hi @bluehood , wouldn't the method to_string be more appropriate in many cases (see http://en.cppreference.com/w/cpp/header/string_view)? We need to back port it but then the PR would be greatly simplified, wouldn't it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/937:195,usability,simpl,simplified,195,"Hi @bluehood , wouldn't the method to_string be more appropriate in many cases (see http://en.cppreference.com/w/cpp/header/string_view)? We need to back port it but then the PR would be greatly simplified, wouldn't it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/937:55,testability,understand,understand,55,"Hi @dpiparo, thanks for looking at the PR! As far as I understand using `to_string` would just mean that wherever I had to write `std::string(strview)` to create a string from a string view I would write `std::to_string(strview)` instead?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/938:76,deployability,build,build,76,I try to fix this crash: http://cdash.cern.ch/testDetails.php?test=28771748&build=392563,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:46,safety,test,testDetails,46,I try to fix this crash: http://cdash.cern.ch/testDetails.php?test=28771748&build=392563,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:62,safety,test,test,62,I try to fix this crash: http://cdash.cern.ch/testDetails.php?test=28771748&build=392563,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:46,testability,test,testDetails,46,I try to fix this crash: http://cdash.cern.ch/testDetails.php?test=28771748&build=392563,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:62,testability,test,test,62,I try to fix this crash: http://cdash.cern.ch/testDetails.php?test=28771748&build=392563,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:11,deployability,build,build,11,@phsft-bot build with flags -Dmemory_termination=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:0,safety,Test,Testing,0,Testing in #945 if this actually also fixed some tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:49,safety,test,tests,49,Testing in #945 if this actually also fixed some tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:0,testability,Test,Testing,0,Testing in #945 if this actually also fixed some tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:49,testability,test,tests,49,Testing in #945 if this actually also fixed some tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:51,deployability,fail,failed,51,"Ok, this fixed a few hundred tests that previously failed due to the redefinition of the macro.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:51,reliability,fail,failed,51,"Ok, this fixed a few hundred tests that previously failed due to the redefinition of the macro.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:29,safety,test,tests,29,"Ok, this fixed a few hundred tests that previously failed due to the redefinition of the macro.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:29,testability,test,tests,29,"Ok, this fixed a few hundred tests that previously failed due to the redefinition of the macro.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:11,deployability,build,build,11,@phsft-bot build with flags -Dmemory_termination=Off,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/939:11,deployability,build,build,11,"@phsft-bot build, please",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/939
https://github.com/root-project/root/pull/939:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/939
https://github.com/root-project/root/pull/940:10,safety,compl,complement,10,Could you complement the fix with a test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:36,safety,test,test,36,Could you complement the fix with a test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:10,security,compl,complement,10,Could you complement the fix with a test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:36,testability,test,test,36,Could you complement the fix with a test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:51,deployability,patch,patch,51,@vgvassilev Of course - the test is older than the patch :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:28,safety,test,test,28,@vgvassilev Of course - the test is older than the patch :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:51,safety,patch,patch,51,@vgvassilev Of course - the test is older than the patch :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:51,security,patch,patch,51,@vgvassilev Of course - the test is older than the patch :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:28,testability,test,test,28,@vgvassilev Of course - the test is older than the patch :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/941:73,performance,deadlock,deadlocks,73,"Testing locally, it seems like `roottest/root/dataframe/test_snapshot.C` deadlocks again after this change, so the unlocking is still required.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:0,safety,Test,Testing,0,"Testing locally, it seems like `roottest/root/dataframe/test_snapshot.C` deadlocks again after this change, so the unlocking is still required.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:0,testability,Test,Testing,0,"Testing locally, it seems like `roottest/root/dataframe/test_snapshot.C` deadlocks again after this change, so the unlocking is still required.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:11,deployability,build,build,11,@phsft-bot build please.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:147,deployability,stack,stacktrace,147,"Good news: I ran `test_snapshot` and `ctest -R dataframe` for several hours today, with no deadlocks. Furthermore, I let @Axel-Naumann look at the stacktrace of yesterday's deadlock (which I cannot currently reproduce) and it turns out it was unrelated to the issue object of this PR and probably due to a dirty build. The red jenkins builds, instead, are because of connection problems. All in all this has been a very unlucky PR but it might just be that we can actually remove `gROOTMutex->UnLock()` without issues :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:312,deployability,build,build,312,"Good news: I ran `test_snapshot` and `ctest -R dataframe` for several hours today, with no deadlocks. Furthermore, I let @Axel-Naumann look at the stacktrace of yesterday's deadlock (which I cannot currently reproduce) and it turns out it was unrelated to the issue object of this PR and probably due to a dirty build. The red jenkins builds, instead, are because of connection problems. All in all this has been a very unlucky PR but it might just be that we can actually remove `gROOTMutex->UnLock()` without issues :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:335,deployability,build,builds,335,"Good news: I ran `test_snapshot` and `ctest -R dataframe` for several hours today, with no deadlocks. Furthermore, I let @Axel-Naumann look at the stacktrace of yesterday's deadlock (which I cannot currently reproduce) and it turns out it was unrelated to the issue object of this PR and probably due to a dirty build. The red jenkins builds, instead, are because of connection problems. All in all this has been a very unlucky PR but it might just be that we can actually remove `gROOTMutex->UnLock()` without issues :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:198,energy efficiency,current,currently,198,"Good news: I ran `test_snapshot` and `ctest -R dataframe` for several hours today, with no deadlocks. Furthermore, I let @Axel-Naumann look at the stacktrace of yesterday's deadlock (which I cannot currently reproduce) and it turns out it was unrelated to the issue object of this PR and probably due to a dirty build. The red jenkins builds, instead, are because of connection problems. All in all this has been a very unlucky PR but it might just be that we can actually remove `gROOTMutex->UnLock()` without issues :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:91,performance,deadlock,deadlocks,91,"Good news: I ran `test_snapshot` and `ctest -R dataframe` for several hours today, with no deadlocks. Furthermore, I let @Axel-Naumann look at the stacktrace of yesterday's deadlock (which I cannot currently reproduce) and it turns out it was unrelated to the issue object of this PR and probably due to a dirty build. The red jenkins builds, instead, are because of connection problems. All in all this has been a very unlucky PR but it might just be that we can actually remove `gROOTMutex->UnLock()` without issues :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/941:173,performance,deadlock,deadlock,173,"Good news: I ran `test_snapshot` and `ctest -R dataframe` for several hours today, with no deadlocks. Furthermore, I let @Axel-Naumann look at the stacktrace of yesterday's deadlock (which I cannot currently reproduce) and it turns out it was unrelated to the issue object of this PR and probably due to a dirty build. The red jenkins builds, instead, are because of connection problems. All in all this has been a very unlucky PR but it might just be that we can actually remove `gROOTMutex->UnLock()` without issues :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/942:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:38,deployability,updat,update,38,"Do not merge yet, I found a bug, will update on Monday.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:38,safety,updat,update,38,"Do not merge yet, I found a bug, will update on Monday.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:38,security,updat,update,38,"Do not merge yet, I found a bug, will update on Monday.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:170,deployability,modul,module,170,"Closing this. There are much bigger and invasive changes needed, so I decided to just implement `ROOT_GENERATE_DICTIONARY` and `ROOT_LINKER_LIBRARY` inside our own CMake module based on the root implementation for now. Maybe in the future I can contribute them back.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:170,modifiability,modul,module,170,"Closing this. There are much bigger and invasive changes needed, so I decided to just implement `ROOT_GENERATE_DICTIONARY` and `ROOT_LINKER_LIBRARY` inside our own CMake module based on the root implementation for now. Maybe in the future I can contribute them back.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:170,safety,modul,module,170,"Closing this. There are much bigger and invasive changes needed, so I decided to just implement `ROOT_GENERATE_DICTIONARY` and `ROOT_LINKER_LIBRARY` inside our own CMake module based on the root implementation for now. Maybe in the future I can contribute them back.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/943:462,deployability,modul,modules,462,"If it's true that the only conflicting file is `tree/tree/CMakeLists.txt`, then it should be easy for Brian to fix (I can't commit directly to this pull request). He added `ROOT/*.hxx` to a `ROOT_GENERATE_DICTIONARY` macro, but in the meantime this macro call was replaced with a `ROOT_STANDARD_LIBRARY_PACKAGE`. The definition of [`ROOT_STANDARD_LIBRARY_PACKAGE` is here](https://github.com/root-project/root/blob/182a914a20991ad629dc9098dc4eaeb1da75d6ae/cmake/modules/RootNewMacros.cmake#L845). It looks like the argument is now ""`HEADERS ROOT/*.hxx`"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:27,interoperability,conflict,conflicting,27,"If it's true that the only conflicting file is `tree/tree/CMakeLists.txt`, then it should be easy for Brian to fix (I can't commit directly to this pull request). He added `ROOT/*.hxx` to a `ROOT_GENERATE_DICTIONARY` macro, but in the meantime this macro call was replaced with a `ROOT_STANDARD_LIBRARY_PACKAGE`. The definition of [`ROOT_STANDARD_LIBRARY_PACKAGE` is here](https://github.com/root-project/root/blob/182a914a20991ad629dc9098dc4eaeb1da75d6ae/cmake/modules/RootNewMacros.cmake#L845). It looks like the argument is now ""`HEADERS ROOT/*.hxx`"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:462,modifiability,modul,modules,462,"If it's true that the only conflicting file is `tree/tree/CMakeLists.txt`, then it should be easy for Brian to fix (I can't commit directly to this pull request). He added `ROOT/*.hxx` to a `ROOT_GENERATE_DICTIONARY` macro, but in the meantime this macro call was replaced with a `ROOT_STANDARD_LIBRARY_PACKAGE`. The definition of [`ROOT_STANDARD_LIBRARY_PACKAGE` is here](https://github.com/root-project/root/blob/182a914a20991ad629dc9098dc4eaeb1da75d6ae/cmake/modules/RootNewMacros.cmake#L845). It looks like the argument is now ""`HEADERS ROOT/*.hxx`"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:462,safety,modul,modules,462,"If it's true that the only conflicting file is `tree/tree/CMakeLists.txt`, then it should be easy for Brian to fix (I can't commit directly to this pull request). He added `ROOT/*.hxx` to a `ROOT_GENERATE_DICTIONARY` macro, but in the meantime this macro call was replaced with a `ROOT_STANDARD_LIBRARY_PACKAGE`. The definition of [`ROOT_STANDARD_LIBRARY_PACKAGE` is here](https://github.com/root-project/root/blob/182a914a20991ad629dc9098dc4eaeb1da75d6ae/cmake/modules/RootNewMacros.cmake#L845). It looks like the argument is now ""`HEADERS ROOT/*.hxx`"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:32,interoperability,conflict,conflict,32,@jpivarski - resolved the merge conflict.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:48,availability,state,state,48,This is because `ReAllocStateFun_t` now takes a state object in lieu of arguments (being a function pointer).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:48,integrability,state,state,48,This is because `ReAllocStateFun_t` now takes a state object in lieu of arguments (being a function pointer).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:24,integrability,interfac,interface-wise,24,Can we find a way to be interface-wise backward compatible? (Maybe offer two function overload instead of one).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:24,interoperability,interfac,interface-wise,24,Can we find a way to be interface-wise backward compatible? (Maybe offer two function overload instead of one).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:48,interoperability,compatib,compatible,48,Can we find a way to be interface-wise backward compatible? (Maybe offer two function overload instead of one).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:24,modifiability,interfac,interface-wise,24,Can we find a way to be interface-wise backward compatible? (Maybe offer two function overload instead of one).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:155,availability,state,state,155,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:374,availability,state,state,374,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:471,availability,state,state,471,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:23,deployability,fail,failing,23,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:155,integrability,state,state,155,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:242,integrability,interfac,interface,242,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:374,integrability,state,state,374,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:471,integrability,state,state,471,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:242,interoperability,interfac,interface,242,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:275,interoperability,compatib,compatible,275,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:242,modifiability,interfac,interface,242,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:23,reliability,fail,failing,23,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:15,safety,test,test,15,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:492,safety,test,test,492,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:580,safety,test,test,580,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:516,security,modif,modification,516,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:15,testability,test,test,15,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:492,testability,test,test,492,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:580,testability,test,test,580,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:199,usability,effectiv,effectively,199,"@bbockelm This test is failing because of your change in the way TBufferFile reallocation functions are passed— you added the ability to pass a pointer to state so that the reallocation function can effectively have an argument. Perhaps this interface could be made backward-compatible by naming the new function pointer type the same as the old one (i.e. without the word ""state"" in its typedef name) and the arguments could take `nullptr` as a default argument for the state. That way, the test could pass without modification. Otherwise, it could pass by a minor change in the test. Then we'd find out what the next bug is. If there is one, of course. :).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:26,usability,statu,status,26,"@bbockelm, can we put WIP status here, what you think about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/944:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_cxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:11,deployability,build,build,11,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:32,deployability,patch,patch,32,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:67,deployability,modul,modules,67,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:75,deployability,build,build,75,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:126,deployability,build,builds,126,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:67,modifiability,modul,modules,67,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:100,reliability,doe,doesn,100,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:32,safety,patch,patch,32,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:67,safety,modul,modules,67,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:32,security,patch,patch,32,@phsft-bot build! It seems that patch works: it triggers a runtime modules build. Let's check if it doesn't break the regular builds.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:4,deployability,patch,patch,4,The patch wouldn't suffice though because we have a few places in e.g. TCling where we need the ROOT_MODULES defined.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:4,safety,patch,patch,4,The patch wouldn't suffice though because we have a few places in e.g. TCling where we need the ROOT_MODULES defined.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:4,security,patch,patch,4,The patch wouldn't suffice though because we have a few places in e.g. TCling where we need the ROOT_MODULES defined.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:17,safety,test,test,17,You mean for the test running? That will probably be another PR where we have to actually use an source-code switch (e.g. a define) that enables/disables that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:17,testability,test,test,17,You mean for the test running? That will probably be another PR where we have to actually use an source-code switch (e.g. a define) that enables/disables that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:67,safety,test,test,67,"Well, the other change could have already been merged and we could test the rootcling PR by now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:67,testability,test,test,67,"Well, the other change could have already been merged and we could test the rootcling PR by now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:19,deployability,build,build,19,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:40,deployability,configurat,configuration,40,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:82,deployability,updat,update,82,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:40,integrability,configur,configuration,40,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:40,modifiability,configur,configuration,40,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:82,safety,updat,update,82,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:40,security,configur,configuration,40,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:82,security,updat,update,82,Breaks the classic build because of the configuration define. Give me a minute to update that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/945:11,deployability,build,build,11,@phsft-bot build with flags -Dmemory_termination=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/945
https://github.com/root-project/root/pull/946:24,safety,review,review,24,@dpiparo @pcanal please review post merge!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:24,testability,review,review,24,@dpiparo @pcanal please review post merge!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/948:56,deployability,fail,failing,56,"Hi Raphael, could you please rebase and push again? The failing test should be fixed now. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:56,reliability,fail,failing,56,"Hi Raphael, could you please rebase and push again? The failing test should be fixed now. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:64,safety,test,test,64,"Hi Raphael, could you please rebase and push again? The failing test should be fixed now. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:64,testability,test,test,64,"Hi Raphael, could you please rebase and push again? The failing test should be fixed now. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:358,availability,failur,failures,358,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:56,deployability,patch,patches-invalid-preprocessing-directive,56,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:344,deployability,configurat,configuration,344,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:358,deployability,fail,failures,358,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:344,integrability,configur,configuration,344,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:374,interoperability,conflict,conflicting,374,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:344,modifiability,configur,configuration,344,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:358,performance,failur,failures,358,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:358,reliability,fail,failures,358,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:56,safety,patch,patches-invalid-preprocessing-directive,56,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:323,safety,prevent,prevent,323,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:56,security,patch,patches-invalid-preprocessing-directive,56,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:323,security,preven,prevent,323,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:344,security,configur,configuration,344,"So this fixes https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197 but if experiments rely on this line, then probably we are stuck on this side. We could at least try to make it less aggressive when searching (so, forbid some of the binary directories and CMake internal directories) to prevent these random configuration failures due to conflicting file names in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/949:11,deployability,build,build,11,@phsft-bot build. I want that green check mark pls,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/949
https://github.com/root-project/root/pull/949:30,energy efficiency,green,green,30,@phsft-bot build. I want that green check mark pls,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/949
https://github.com/root-project/root/pull/950:39,deployability,build,build,39,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:174,deployability,modul,modules,174,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:174,modifiability,modul,modules,174,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:139,safety,prevent,prevent,139,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:174,safety,modul,modules,174,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:131,security,hack,hack,131,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:139,security,preven,prevent,139,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:123,usability,minim,minimal,123,"Well, turns out that ROOT has it's own build system in TFile that breaks with properly fixing this, so let's just make the minimal hack to prevent people from activating C++ modules from this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/953:29,interoperability,format,format,29,Note: reformatted with clang-format and pushed again.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:9,availability,failur,failure,9,The test failure is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:9,deployability,fail,failure,9,The test failure is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:9,performance,failur,failure,9,The test failure is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:9,reliability,fail,failure,9,The test failure is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:4,safety,test,test,4,The test failure is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:4,testability,test,test,4,The test failure is unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:87,deployability,version,version,87,"Alright, I believe I addressed all your comments. Please take another look at this new version and let me know what you think. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:87,integrability,version,version,87,"Alright, I believe I addressed all your comments. Please take another look at this new version and let me know what you think. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:87,modifiability,version,version,87,"Alright, I believe I addressed all your comments. Please take another look at this new version and let me know what you think. Cheers,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:13,availability,sli,slightly,13,"Note, I only slightly edited commit messages, no need to retest.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:36,integrability,messag,messages,36,"Note, I only slightly edited commit messages, no need to retest.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:36,interoperability,messag,messages,36,"Note, I only slightly edited commit messages, no need to retest.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:13,reliability,sli,slightly,13,"Note, I only slightly edited commit messages, no need to retest.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:10,availability,failur,failures,10,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:169,availability,monitor,monitor,169,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:10,deployability,fail,failures,10,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:49,deployability,build,build,49,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:169,deployability,monitor,monitor,169,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:169,energy efficiency,monitor,monitor,169,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:123,integrability,messag,message,123,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:123,interoperability,messag,message,123,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:10,performance,failur,failures,10,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:10,reliability,fail,failures,10,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:169,reliability,monitor,monitor,169,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:169,safety,monitor,monitor,169,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:169,testability,monitor,monitor,169,"I believe failures were due to pushing while the build was running. Everything passed before and I only changed the commit message with latest push. In any case, I will monitor the incrementals and revert if any more problems show up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/954:11,deployability,build,build,11,"@phsft-bot build, please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/954
https://github.com/root-project/root/pull/954:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/954
https://github.com/root-project/root/pull/955:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/955
https://github.com/root-project/root/pull/956:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:40,deployability,build,builds,40,"Hi @oshadura, please let me know if the builds are failing for other reasons so that I can review again and merge. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:51,deployability,fail,failing,51,"Hi @oshadura, please let me know if the builds are failing for other reasons so that I can review again and merge. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:51,reliability,fail,failing,51,"Hi @oshadura, please let me know if the builds are failing for other reasons so that I can review again and merge. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:91,safety,review,review,91,"Hi @oshadura, please let me know if the builds are failing for other reasons so that I can review again and merge. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:91,testability,review,review,91,"Hi @oshadura, please let me know if the builds are failing for other reasons so that I can review again and merge. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:46,energy efficiency,Cloud,Cloudflare,46,"@amadio, there is also next improvements from Cloudflare by adding aarch64 systems support for SIMD vectorization, but I could maybe propose it as a next iteration (not to make this PR forever lasting :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:83,usability,support,support,83,"@amadio, there is also next improvements from Cloudflare by adding aarch64 systems support for SIMD vectorization, but I could maybe propose it as a next iteration (not to make this PR forever lasting :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:18,deployability,version,version,18,"Closing as an old version of PR, the new one is in PR# 1527",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:18,integrability,version,version,18,"Closing as an old version of PR, the new one is in PR# 1527",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:18,modifiability,version,version,18,"Closing as an old version of PR, the new one is in PR# 1527",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/957:24,interoperability,architectur,architectures,24,"Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). Therefore, any thread will either see `fBase == nullptr` and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:97,performance,cach,cache,97,"Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). Therefore, any thread will either see `fBase == nullptr` and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:243,performance,lock,lock,243,"Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). Therefore, any thread will either see `fBase == nullptr` and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:154,safety,safe,safe,154,"Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). Therefore, any thread will either see `fBase == nullptr` and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:243,security,lock,lock,243,"Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). Therefore, any thread will either see `fBase == nullptr` and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:656,availability,consist,consistent,656,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:306,deployability,updat,update,306,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:711,deployability,updat,updated,711,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:26,interoperability,architectur,architectures,26,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:216,interoperability,standard,standard,216,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:477,interoperability,platform,platforms,477,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:676,interoperability,standard,standard,676,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:99,performance,cach,cache,99,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:285,performance,concurren,concurrently,285,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:331,performance,synch,synchronization,331,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:815,performance,lock,lock,815,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:871,performance,synch,synchronization,871,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:985,performance,lock,lock,985,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:387,reliability,pra,practice,387,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:156,safety,safe,safe,156,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:306,safety,updat,update,306,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:711,safety,updat,updated,711,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:306,security,updat,update,306,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:648,security,polic,policy,648,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:711,security,updat,updated,711,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:815,security,lock,lock,815,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:985,security,lock,lock,985,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:1112,testability,simpl,simply,1112,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:260,usability,behavi,behavior,260,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:656,usability,consist,consistent,656,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:1112,usability,simpl,simply,1112,"> Note: at least on Intel architectures, a single 64bit pointer cannot be split into more than one cache line due to alignment of 8 bytes (i.e. it's thread-safe to read it). . Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. > Therefore, any thread will either see fBase == nullptr and acquire a lock to create the list of bases, or it will find the value already computed and return it immediately. In this case this true simply due to the fact that fBase is already an std::atomic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:488,availability,consist,consistent,488,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:132,deployability,updat,update,132,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:543,deployability,updat,updated,543,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:42,interoperability,standard,standard,42,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:303,interoperability,platform,platforms,303,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:508,interoperability,standard,standard,508,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:111,performance,concurren,concurrently,111,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:157,performance,synch,synchronization,157,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:647,performance,lock,lock,647,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:703,performance,synch,synchronization,703,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:213,reliability,pra,practice,213,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:132,safety,updat,update,132,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:543,safety,updat,updated,543,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:820,safety,safe,safe,820,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:132,security,updat,update,132,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:480,security,polic,policy,480,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:543,security,updat,updated,543,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:647,security,lock,lock,647,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:86,usability,behavi,behavior,86,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:488,usability,consist,consistent,488,"> Even-though this might be true, the C++ standard explicit says that it is undefined behavior to read a value concurrently with an update with any explicit synchronization mechanism (for example std::atomic). In practice, this means that the same 'happenstance' you describe might not be true on other platforms. Furthermore the compiler is also allowed to re-order code in 'surprising ways' that would thwart/foil the assumption on the happenstance you describe. > . > Thus our policy, consistent with the standard is that if a value can be updated while being read, it either must be an atomic or both the read and write must be protected by a lock. [This is not meant to preclude any other means of synchronization to achieve the same goal]. Yes, you are right. I will redo the changes while also making them thread-safe. On ARM a 64bit store can use more than one instruction, actually. I will also add comments explaining the code, I agree it's a bit confusing at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:134,testability,emul,emulated,134,"Looking at JIRA, I found out that `GetListOfBases()` is apparently already [wrong](https://sft.its.cern.ch/jira/browse/ROOT-5178) for emulated classes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:134,testability,emul,emulated,134,"Looking at JIRA, I found out that `GetListOfBases()` is apparently already [wrong](https://sft.its.cern.ch/jira/browse/ROOT-5178) for emulated classes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/958:46,deployability,version,versions,46,"Well, I guess this is not possible untill all versions are larger than 3.9...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:46,integrability,version,versions,46,"Well, I guess this is not possible untill all versions are larger than 3.9...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:46,modifiability,version,versions,46,"Well, I guess this is not possible untill all versions are larger than 3.9...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:14,availability,Error,Errors,14,Tests passed. Errors here are due to the fact I had to rebase again before the final merge.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:14,performance,Error,Errors,14,Tests passed. Errors here are due to the fact I had to rebase again before the final merge.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:0,safety,Test,Tests,0,Tests passed. Errors here are due to the fact I had to rebase again before the final merge.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:14,safety,Error,Errors,14,Tests passed. Errors here are due to the fact I had to rebase again before the final merge.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:0,testability,Test,Tests,0,Tests passed. Errors here are due to the fact I had to rebase again before the final merge.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:14,usability,Error,Errors,14,Tests passed. Errors here are due to the fact I had to rebase again before the final merge.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/959:198,availability,error,error,198,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:63,deployability,fail,failed,63,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:134,deployability,build,buildid,134,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:204,integrability,messag,message,204,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:204,interoperability,messag,message,204,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:198,performance,error,error,198,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:63,reliability,fail,failed,63,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:29,safety,test,test,29,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:198,safety,error,error,198,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:29,testability,test,test,29,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:12,usability,statu,status,12,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:198,usability,error,error,198,"@pcanal The status bit check test seems a bit flaky as it also failed in the [nightlies](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=394075), albeit with a different problem (segfault, not error message).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:129,availability,error,error,129,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:281,availability,failur,failure,281,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:314,availability,error,error,314,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:57,deployability,fail,failed,57,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:281,deployability,fail,failure,281,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:135,integrability,messag,message,135,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:320,integrability,messag,message,320,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:355,integrability,messag,message,355,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:135,interoperability,messag,message,135,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:320,interoperability,messag,message,320,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:355,interoperability,messag,message,355,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:129,performance,error,error,129,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:281,performance,failur,failure,281,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:314,performance,error,error,314,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:57,reliability,fail,failed,57,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:281,reliability,fail,failure,281,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:23,safety,test,test,23,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:129,safety,error,error,129,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:314,safety,error,error,314,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:23,testability,test,test,23,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:6,usability,statu,status,6,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:129,usability,error,error,129,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:314,usability,error,error,314,"> The status bit check test seems a bit flaky as it also failed in the nightlies, albeit with a different problem (segfault, not error message). @amadio humm ... Odd ... I can't find any recent nightly showing the problem. Can you point me in the right direction? Also odd, *this* failure is a segfault and not an error message (aka I am confused by your message ;) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:81,availability,failur,failure,81,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:81,deployability,fail,failure,81,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:107,energy efficiency,core,core-execStatusBitsCheck,107,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:81,performance,failur,failure,81,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:81,reliability,fail,failure,81,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:41,safety,review,review,41,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:187,safety,avoid,avoids,187,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:221,safety,test,test,221,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:41,testability,review,review,41,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:221,testability,test,test,221,@pcanal - I believe I have addressed all review comments. I cannot reproduce the failure of `roottest-root-core-execStatusBitsCheck`; it's possible the fact I switched to an `enum class` avoids the underlying bug in that test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:25,availability,failur,failure,25,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:25,deployability,fail,failure,25,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:218,deployability,depend,dependent,218,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:249,deployability,depend,depend,249,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:280,deployability,build,build,280,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:50,energy efficiency,core,core-execStatusBitsCheck,50,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:218,integrability,depend,dependent,218,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:249,integrability,depend,depend,249,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:209,interoperability,platform,platform,209,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:218,modifiability,depend,dependent,218,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:249,modifiability,depend,depend,249,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:25,performance,failur,failure,25,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:25,reliability,fail,failure,25,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:127,safety,avoid,avoids,127,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:161,safety,test,test,161,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:218,safety,depend,dependent,218,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:249,safety,depend,depend,249,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:161,testability,test,test,161,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:218,testability,depend,dependent,218,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:249,testability,depend,depend,249,> I cannot reproduce the failure of roottest-root-core-execStatusBitsCheck; it's possible the fact I switched to an enum class avoids the underlying bug in that test? It is indeed possible. It could also be a platform dependent thing or it could be depend on the library actually build as part of ROOT ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:83,deployability,releas,release,83,Last step :) ... we need to add a nice description of this feature in at least the release notes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:69,availability,failur,failure,69,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:10,deployability,releas,release,10,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:24,deployability,updat,updated,24,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:69,deployability,fail,failure,69,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:69,performance,failur,failure,69,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:69,reliability,fail,failure,69,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:24,safety,updat,updated,24,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:64,safety,test,test,64,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:24,security,updat,updated,24,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:64,testability,test,test,64,"@pcanal - release notes updated. I tried to reproduce the above test failure locally, but was unable to. Do you recognize it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/962:11,deployability,build,build,11,@phsft-bot build with flags -Dclingtest=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/962
https://github.com/root-project/root/pull/963:59,availability,failur,failure,59,"Hi @Teemperor , I fixed the issue that led to the previous failure. @phsft-bot build please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:59,deployability,fail,failure,59,"Hi @Teemperor , I fixed the issue that led to the previous failure. @phsft-bot build please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:79,deployability,build,build,79,"Hi @Teemperor , I fixed the issue that led to the previous failure. @phsft-bot build please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:59,performance,failur,failure,59,"Hi @Teemperor , I fixed the issue that led to the previous failure. @phsft-bot build please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:59,reliability,fail,failure,59,"Hi @Teemperor , I fixed the issue that led to the previous failure. @phsft-bot build please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/965:82,deployability,updat,update,82,"Well, looks like not everything is passing... I will investigate the problems and update this branch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:82,safety,updat,update,82,"Well, looks like not everything is passing... I will investigate the problems and update this branch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:82,security,updat,update,82,"Well, looks like not everything is passing... I will investigate the problems and update this branch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:346,modifiability,concern,concerned,346,Very fast coding and nice functionality indeed! I added some punctual comments in the code. Perhaps we can put in this PR a tutorial too which illustrates how to compare different compression algorithms and/or levels. Also we would need tests. It would be fine to have these elements in a separate PR and the tests in roottest too as far as I am concerned.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:237,safety,test,tests,237,Very fast coding and nice functionality indeed! I added some punctual comments in the code. Perhaps we can put in this PR a tutorial too which illustrates how to compare different compression algorithms and/or levels. Also we would need tests. It would be fine to have these elements in a separate PR and the tests in roottest too as far as I am concerned.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:309,safety,test,tests,309,Very fast coding and nice functionality indeed! I added some punctual comments in the code. Perhaps we can put in this PR a tutorial too which illustrates how to compare different compression algorithms and/or levels. Also we would need tests. It would be fine to have these elements in a separate PR and the tests in roottest too as far as I am concerned.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:237,testability,test,tests,237,Very fast coding and nice functionality indeed! I added some punctual comments in the code. Perhaps we can put in this PR a tutorial too which illustrates how to compare different compression algorithms and/or levels. Also we would need tests. It would be fine to have these elements in a separate PR and the tests in roottest too as far as I am concerned.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:309,testability,test,tests,309,Very fast coding and nice functionality indeed! I added some punctual comments in the code. Perhaps we can put in this PR a tutorial too which illustrates how to compare different compression algorithms and/or levels. Also we would need tests. It would be fine to have these elements in a separate PR and the tests in roottest too as far as I am concerned.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:346,testability,concern,concerned,346,Very fast coding and nice functionality indeed! I added some punctual comments in the code. Perhaps we can put in this PR a tutorial too which illustrates how to compare different compression algorithms and/or levels. Also we would need tests. It would be fine to have these elements in a separate PR and the tests in roottest too as far as I am concerned.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:106,availability,sli,slightly,106,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:83,energy efficiency,green,green,83,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:106,reliability,sli,slightly,106,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:58,safety,test,test,58,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:225,safety,compl,complain,225,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:225,security,compl,complain,225,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:58,testability,test,test,58,"As soon as ~~`T const&` is switched to `const T&` and~~ a test is added the PR has green light from me. I slightly disagree with @dpiparo here and I think it would be nice to add a gtest in this same PR, but I'm not going to complain if this won't be the case :smile:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:136,energy efficiency,current,current,136,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:35,safety,test,tests,35,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:107,safety,review,reviewed,107,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:120,safety,test,tested,120,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:144,safety,test,tests,144,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:188,safety,test,tests,188,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:35,testability,test,tests,35,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:107,testability,review,reviewed,107,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:120,testability,test,tested,120,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:144,testability,test,tests,144,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:188,testability,test,tests,188,@dpiparo Surely I can add some new tests and a tutorial. I just wanted to put the code here so it could be reviewed and tested with the current tests. I will add the remaining changes and tests soon.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:191,modifiability,paramet,parameter,191,"Ok, but level has to be an `Int_t`, as that's the type `TFile` accepts. *Edit:* The reasoning is that I want to avoid warnings about truncation when the enum and char are mixed to create the parameter that is passed to TFile. Also 300 is a perfect value for algorithm when creating the `Int_t` that TFile takes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:112,safety,avoid,avoid,112,"Ok, but level has to be an `Int_t`, as that's the type `TFile` accepts. *Edit:* The reasoning is that I want to avoid warnings about truncation when the enum and char are mixed to create the parameter that is passed to TFile. Also 300 is a perfect value for algorithm when creating the `Int_t` that TFile takes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:155,safety,test,tests,155,"Alright, compression algorithm and level are now split in snapshot options. Please let me know if you have any more comments. Otherwise, I will merge once tests pass.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/965:155,testability,test,tests,155,"Alright, compression algorithm and level are now split in snapshot options. Please let me know if you have any more comments. Otherwise, I will merge once tests pass.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/969:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:83,energy efficiency,current,current,83,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:59,safety,test,tested,59,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:91,safety,test,testRocWeights,91,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:115,safety,test,test,115,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:59,testability,test,tested,59,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:91,testability,test,testRocWeights,91,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:110,testability,unit,unit,110,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:115,testability,test,test,115,Thank you for this PR. I assume everything changed here is tested already with the current testRocWeights.cxx unit test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/971:11,deployability,build,build,11,@phsft-bot build with flags -DCMAKE_BUILD_TYPE=Optimized,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:47,energy efficiency,Optim,Optimized,47,@phsft-bot build with flags -DCMAKE_BUILD_TYPE=Optimized,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:47,performance,Optimiz,Optimized,47,@phsft-bot build with flags -DCMAKE_BUILD_TYPE=Optimized,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:13,testability,understand,understand,13,"Hi, I do not understand this PR. ""-Ofast"" activates -ffast-math, right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:86,availability,toler,tolerances,86,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:122,deployability,build,builds,122,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:147,deployability,build,builds,147,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:196,deployability,build,builds,196,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:229,deployability,build,build,229,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:271,deployability,fail,failing,271,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:86,reliability,toleran,tolerances,86,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:271,reliability,fail,failing,271,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:342,reliability,doe,doesn,342,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:23,safety,test,test,23,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:212,safety,detect,detect,212,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:263,safety,test,test,263,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:425,safety,test,test,425,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:212,security,detect,detect,212,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:23,testability,test,test,23,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:263,testability,test,test,263,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:425,testability,test,test,425,"@dpiparo in filemerger test I am using R__FAST_MATH(```__FAST_MATH__```), to separate tolerances for fast math and normal builds, in case of clang builds everything works fine, but in case of gcc builds it never detect fast-math build, and as a result filemerger test is failing. I rechecked and the reason is that -Ofast is actually for gcc doesn't define ```__FAST_MATH__``` but only -ffast-math. After this fix filemerger test is working properly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:34,deployability,fail,failing,34,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:42,interoperability,architectur,architectures,42,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:34,reliability,fail,failing,34,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:11,safety,test,tested,11,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:100,safety,test,test,100,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:11,testability,test,tested,11,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:100,testability,test,test,100,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:76,usability,behavi,behavior,76,"@dpiparo I tested this changes on failing architectures, and it shows right behavior for filemerger test (I can send you screenshot)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:301,availability,error,error,301,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1635,availability,error,error,1635,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:618,deployability,build,build,618,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:641,deployability,instal,install-,641,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:745,deployability,version,version,745,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1110,deployability,build,build,1110,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1131,deployability,instal,install,1131,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1406,deployability,build,build,1406,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1431,deployability,instal,install,1431,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1578,deployability,version,version,1578,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:727,energy efficiency,model,model,727,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1560,energy efficiency,model,model,1560,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:530,integrability,wrap,wrapper,530,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:568,integrability,Configur,Configured,568,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:598,integrability,configur,configure,598,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:745,integrability,version,version,745,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1017,integrability,wrap,wrapper,1017,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1060,integrability,Configur,Configured,1060,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1090,integrability,configur,configure,1090,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1578,integrability,version,version,1578,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:530,interoperability,wrapper,wrapper,530,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1017,interoperability,wrapper,wrapper,1017,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:568,modifiability,Configur,Configured,568,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:598,modifiability,configur,configure,598,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:745,modifiability,version,version,745,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1060,modifiability,Configur,Configured,1060,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1090,modifiability,configur,configure,1090,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1578,modifiability,version,version,1578,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:301,performance,error,error,301,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1376,performance,time,time,1376,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1635,performance,error,error,1635,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:315,reliability,doe,does,315,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1649,reliability,doe,does,1649,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:301,safety,error,error,301,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1635,safety,error,error,1635,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:568,security,Configur,Configured,568,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:598,security,configur,configure,598,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:727,security,model,model,727,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1060,security,Configur,Configured,1060,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1090,security,configur,configure,1090,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1560,security,model,model,1560,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:64,testability,understand,understand,64,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1750,testability,understand,understand,1750,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:301,usability,error,error,301,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:1635,usability,error,error,1635,"Hi @oshadura , thanks for the investigation! One thing I do not understand is that both on an old gcc, 4.9/4.8, and on gcc 6, *-Ofast* seems to define *__FAST_MATH__*, at least on lxplus7:. ```. $ cat a.C . #ifdef __FAST_MATH__. aaaa. #endif. $ g++ -o a -c a.C -O2. $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^~~~. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/6.2.0native/x86_64-centos7/bin/../libexec/gcc/x86_64-pc-linux-gnu/6.2.0/lto-wrapper. Target: x86_64-pc-linux-gnu. Configured with: ../gcc-6.2.0/configure --prefix=/build/pmendez-sftnight/install-620native -with-system-zlib --disable-multilib --enable-languages=all. Thread model: posix. gcc version 6.2.0 (GCC) . $ source /cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/setup.sh. $ g++ -v. Using built-in specs. COLLECT_GCC=g++. COLLECT_LTO_WRAPPER=/cvmfs/sft.cern.ch/lcg/external/gcc/4.9.1/x86_64-slc6/bin/../libexec/gcc/x86_64-unknown-linux-gnu/4.9.1/lto-wrapper. Target: x86_64-unknown-linux-gnu. Configured with: ../gcc-4.9.1/configure --prefix=/build/hegner/gcc/gcc-install --with-mpfr=/afs/cern.ch/sw/lcg/external/mpfr/3.1.2/x86_64-slc6-gcc48-opt --with-gmp=/afs/cern.ch/sw/lcg/external/gmp/5.1.1/x86_64-slc6-gcc48-opt --with-mpc=/afs/cern.ch/sw/lcg/external/mpc/1.0.1/x86_64-slc6-gcc48-opt --enable-libstdcxx-time --enable-lto --with-isl=/build/hegner/gcc/isl/isl-install --with-cloog=/afs/cern.ch/sw/lcg/external/cloog/0.18.0/x86_64-slc6-gcc48-opt --enable-languages=c,c++,fortran,go. Thread model: posix. gcc version 4.9.1 (GCC) . $ g++ -o a -c a.C -Ofast. a.C:2:1: error: ‘aaaa’ does not name a type. aaaa. ^. $ g++ -o a -c a.C -O2. ```. I see your fix works, I am just trying to understand all the details here since we are looking for the cause of this since a while :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:49,deployability,build,build,49,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:75,deployability,build,build,75,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:194,deployability,build,builds,194,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:533,deployability,ToolChain,ToolChains,533,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:615,deployability,build,build,615,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:65,energy efficiency,Optim,Optimized,65,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:65,performance,Optimiz,Optimized,65,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:32,safety,test,test,32,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:212,safety,test,test,212,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:286,safety,test,test,286,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:32,testability,test,test,32,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:212,testability,test,test,212,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:286,testability,test,test,286,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:510,usability,tool,tools,510,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:533,usability,Tool,ToolChains,533,"@dpiparo absolutely right! Nice test! But, if to build ROOT with Optimized build and try exactly the same example, we have next output:. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root-opt/builds$ cat ../../test.C . #ifdef __FAST_MATH__. aaaa. #endif. =========. root [1] .X ../../test.C . root [2] . ```. Could it be connected to llvm/clang/cling interpreter? It is actually mentioned in clang code: https://github.com/root-project/root/blob/dc9a26819b6549b51b7bd380be61235edde8f21f/interpreter/llvm/src/tools/clang/lib/Driver/ToolChains/Clang.cpp#L2403. It makes sense then because for linux+clang fast math build, the flags are: . ```. ""-O3 -ffast-math .."". ````. and it work fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:251,deployability,fail,fails,251,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:202,energy efficiency,optim,optimisation,202,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:78,modifiability,concern,concerned,78,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:107,reliability,Doe,Does,107,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:251,reliability,fail,fails,251,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:246,safety,test,test,246,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:78,testability,concern,concerned,78,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:246,testability,test,test,246,"Hi @oshadura , got it. Yes, you are absolutely right. This PR, as far as I am concerned, should be merged. Does what you say above mean that no macro / interpreted code was executed with O3 -ffast-math optimisation by cling up to now and that no test fails because of that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:11,deployability,build,build,11,Aren't the build flags propagated to cling in cling-compiledata.h?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:98,usability,help,help,98,"@dpiparo, yes you are right, there was no such case before unfortunately.. @Axel-Naumann, can you help me please to point what is the next step then?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:170,integrability,inject,inject,170,"@oshadura interpreter/cling/lib/Interpreter/CIFactory.cpp has. ```. #ifdef __FAST_MATH__. Opts.FastMath = 1;. #endif. ```. Shouldn't that work? I'd have expected that to inject the proper preprocessor definition into cling's runtime, just like for `__STRICT_ANSI__` / `Opts.GNUMode`. Could you check whether `Opts.FastMath` is `1` when it should be? Then we'll have to see why `__STRICT_ANSI__` gets set but `__FAST_MATH__` doesn't, looking at cling's calls to clang / the `Preprocessor` setup.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:424,reliability,doe,doesn,424,"@oshadura interpreter/cling/lib/Interpreter/CIFactory.cpp has. ```. #ifdef __FAST_MATH__. Opts.FastMath = 1;. #endif. ```. Shouldn't that work? I'd have expected that to inject the proper preprocessor definition into cling's runtime, just like for `__STRICT_ANSI__` / `Opts.GNUMode`. Could you check whether `Opts.FastMath` is `1` when it should be? Then we'll have to see why `__STRICT_ANSI__` gets set but `__FAST_MATH__` doesn't, looking at cling's calls to clang / the `Preprocessor` setup.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:170,security,inject,inject,170,"@oshadura interpreter/cling/lib/Interpreter/CIFactory.cpp has. ```. #ifdef __FAST_MATH__. Opts.FastMath = 1;. #endif. ```. Shouldn't that work? I'd have expected that to inject the proper preprocessor definition into cling's runtime, just like for `__STRICT_ANSI__` / `Opts.GNUMode`. Could you check whether `Opts.FastMath` is `1` when it should be? Then we'll have to see why `__STRICT_ANSI__` gets set but `__FAST_MATH__` doesn't, looking at cling's calls to clang / the `Preprocessor` setup.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/972:50,deployability,patch,patch,50,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:67,deployability,contain,containing,67,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:511,deployability,patch,patch,511,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:816,energy efficiency,current,currently,816,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1045,energy efficiency,green,green,1045,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:934,integrability,sub,substitutes,934,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:50,safety,patch,patch,50,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:511,safety,patch,patch,511,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:852,safety,test,tests,852,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:50,security,patch,patch,50,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:511,security,patch,patch,511,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:852,testability,test,tests,852,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:537,usability,user,user-images,537,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:660,usability,user,user-images,660,"Great!!! I ran the following snippet against this patch (on a tree containing 1e8 floats in branch ""x""):. ```c++. #include ""ROOT/TDataFrame.hxx"". #include ""TROOT.h"". #include <iostream>. int main(). {. const auto poolSize = 4; // the higher, the worse. ROOT::EnableImplicitMT(poolSize);. std::cout << ""pool size: "" << poolSize << std::endl;. ROOT::Experimental::TDataFrame d(""tree"", ""file.root"");. auto h = d.Histo1D(""x"");. std::cout << ""stddev: "" << h->GetStdDev() << std::endl;. return 0;. }. ```. Before the patch:. ![before](https://user-images.githubusercontent.com/10999034/30320789-02d22b70-97b4-11e7-8215-f90e18fe7ba5.png). and after. ![after](https://user-images.githubusercontent.com/10999034/30320798-085a8a42-97b4-11e7-9698-666386fea052.png). One can see that runtime is now spent doing useful work. I'm currently running all of TDataFrame tests in a loop just to be sure. Before merging I would like to add a commit that substitutes `ProcessLine` with `Calc` also in the remaining occurrences, but besides this the PR is absolutely green for me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:280,deployability,build,building,280,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:33,performance,deadlock,deadlock,33,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:139,performance,lock,lock,139,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:12,safety,test,tests,12,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:263,safety,test,test,263,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:139,security,lock,lock,139,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:173,security,sign,signal,173,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:12,testability,test,tests,12,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:263,testability,test,test,263,"Running the tests I saw the same deadlock that we had after the changes to cling that allowed not jitting `gROOTMutex->UnLock()` (due to a lock being recursively taken in a signal handler after cling crashed). I believe this is due to a ""dirty"" incremental. I'll test again after building ROOT from scratch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:22,performance,deadlock,deadlock,22,@Axel-Naumann I see a deadlock even after rebuilding ROOT from scratch,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:117,deployability,stack,stack,117,Can you reproduce in a debugger and/or can you attach a debugger to the deadlocked process and print/show the set of stack traces. This should tell us who are the two threads holding the same lock.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:72,performance,deadlock,deadlocked,72,Can you reproduce in a debugger and/or can you attach a debugger to the deadlocked process and print/show the set of stack traces. This should tell us who are the two threads holding the same lock.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:192,performance,lock,lock,192,Can you reproduce in a debugger and/or can you attach a debugger to the deadlocked process and print/show the set of stack traces. This should tell us who are the two threads holding the same lock.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:192,security,lock,lock,192,Can you reproduce in a debugger and/or can you attach a debugger to the deadlocked process and print/show the set of stack traces. This should tell us who are the two threads holding the same lock.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:123,testability,trace,traces,123,Can you reproduce in a debugger and/or can you attach a debugger to the deadlocked process and print/show the set of stack traces. This should tell us who are the two threads holding the same lock.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:26,deployability,stack,stacktrace,26,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:226,deployability,artifact,artifact,226,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:244,deployability,build,build,244,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:265,deployability,depend,dependencies,265,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:531,energy efficiency,green,green,531,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:265,integrability,depend,dependencies,265,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:265,modifiability,depend,dependencies,265,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:551,modifiability,concern,concerned,551,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:80,performance,lock,locking,80,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:265,safety,depend,dependencies,265,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:438,safety,test,tests,438,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:80,security,lock,locking,80,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:265,testability,depend,dependencies,265,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:438,testability,test,tests,438,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:551,testability,concern,concerned,551,"Hi @pcanal, please find a stacktrace below. It is one single thread recursively locking a mutex. This is an issue I had before, also after a change in cling. I rebuilt ROOT from scratch and retested again, I believe it was an artifact of a bad build. Probably some dependencies missing. I'd ask @Axel-Naumann to merge [this PR of mine](https://github.com/Axel-Naumann/root/pull/196) into this branch of his. I'll trigger another round of tests (as soon as possible) just to be sure everything works as intended, then everything is green as far as I'm concerned. Thanks again for the fix!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:24,deployability,stack,stacktrace,24,@bluehood please find a stacktrace below. . github is hiding it from me ... do you know where to find it?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:211,availability,operat,operator,211,"my bad:. ```. #0 __lll_lock_wait_private () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:95. #1 0x00007fd43ffaafd2 in __GI___libc_malloc (bytes=140549586459392) at malloc.c:2926. #2 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #3 0x00007fd440b24fd5 in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::reserve(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #4 0x00007fd440b1911e in std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::overflow(int) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #5 0x00007fd440b23549 in std::basic_streambuf<char, std::char_traits<char> >::xsputn(char const*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd440",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1576,availability,operat,operator,1576,"rflow(int) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #5 0x00007fd440b23549 in std::basic_streambuf<char, std::char_traits<char> >::xsputn(char const*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::Em",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:2165,availability,operat,operator,2165,"t<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #19 0x00007fd43bfd73b5 in clang::CodeGen::CodeGenFunction::StartFunction(clang::GlobalDecl, clang::QualType, llvm::Function*, clang::CodeGen::CGFunctionInfo const&, clang::CodeGen::FunctionArgList const&, clan",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6978,availability,error,error,6978,"3bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_bui",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6984,availability,error,error,6984,"31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_build/roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:4777,deployability,Releas,Release,4777,"/eguiraud/ROOT/root_build/lib/libCling.so. #23 0x00007fd43c00119b in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #24 0x00007fd43c0011b7 in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #25 0x00007fd43c0011b7 in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #26 0x00007fd43c0011b7 in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #27 0x00007fd43c0011b7 in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #28 0x00007fd43c0011b7 in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #29 0x00007fd43c0011b7 in clang::CodeGen::CodeGenModule::EmitDeferred() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #30 0x00007fd43c001261 in clang::CodeGen::CodeGenModule::Release() () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #31 0x00007fd43bf6cb97 in clang::CodeGeneratorImpl::HandleTranslationUnit(clang::ASTContext&) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #32 0x00007fd43bf14df7 in cling::IncrementalParser::codeGenTransaction(cling::Transaction*) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #33 0x00007fd43bf14a62 in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #34 0x00007fd43bf17c4e in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #35 0x00007fd43bebca8b in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:376,energy efficiency,alloc,allocator,376,"my bad:. ```. #0 __lll_lock_wait_private () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:95. #1 0x00007fd43ffaafd2 in __GI___libc_malloc (bytes=140549586459392) at malloc.c:2926. #2 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #3 0x00007fd440b24fd5 in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::reserve(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #4 0x00007fd440b1911e in std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::overflow(int) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #5 0x00007fd440b23549 in std::basic_streambuf<char, std::char_traits<char> >::xsputn(char const*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd440",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:558,energy efficiency,alloc,allocator,558,"my bad:. ```. #0 __lll_lock_wait_private () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:95. #1 0x00007fd43ffaafd2 in __GI___libc_malloc (bytes=140549586459392) at malloc.c:2926. #2 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #3 0x00007fd440b24fd5 in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::reserve(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #4 0x00007fd440b1911e in std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::overflow(int) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #5 0x00007fd440b23549 in std::basic_streambuf<char, std::char_traits<char> >::xsputn(char const*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd440",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1593,energy efficiency,optim,optimized,1593," /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #5 0x00007fd440b23549 in std::basic_streambuf<char, std::char_traits<char> >::xsputn(char const*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1727,energy efficiency,optim,optimized,1727,"onst*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1771,energy efficiency,core,core,1771,"x-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::Co",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:5806,energy efficiency,alloc,allocator,5806,"OOT/root_build/lib/libCling.so. #31 0x00007fd43bf6cb97 in clang::CodeGeneratorImpl::HandleTranslationUnit(clang::ASTContext&) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #32 0x00007fd43bf14df7 in cling::IncrementalParser::codeGenTransaction(cling::Transaction*) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #33 0x00007fd43bf14a62 in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #34 0x00007fd43bf17c4e in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #35 0x00007fd43bebca8b in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #36 0x00007fd43bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6083,energy efficiency,alloc,allocator,6083,"from /home/eguiraud/ROOT/root_build/lib/libCling.so. #33 0x00007fd43bf14a62 in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #34 0x00007fd43bf17c4e in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #35 0x00007fd43bebca8b in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #36 0x00007fd43bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6841,energy efficiency,core,core,6841,"ilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #36 0x00007fd43bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6962,energy efficiency,optim,optimized,6962,"#36 0x00007fd43bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:7040,energy efficiency,core,core,7040,"tring<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #45 0x00007fd4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1593,performance,optimiz,optimized,1593," /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #5 0x00007fd440b23549 in std::basic_streambuf<char, std::char_traits<char> >::xsputn(char const*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1727,performance,optimiz,optimized,1727,"onst*, long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #6 0x00007fd440b08cae in std::ostreambuf_iterator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6962,performance,optimiz,optimized,6962,"#36 0x00007fd43bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6978,performance,error,error,6978,"3bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_bui",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6984,performance,error,error,6984,"31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_build/roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6978,safety,error,error,6978,"3bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_bui",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6984,safety,error,error,6984,"31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_build/roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1834,security,sign,signal,1834,"terator<char, std::char_traits<char> > std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::_M_insert_int<unsigned long>(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #7 0x00007fd440b08ded in std::num_put<char, std::ostreambuf_iterator<char, std::char_traits<char> > >::do_put(std::ostreambuf_iterator<char, std::char_traits<char> >, std::ios_base&, char, unsigned long) const. () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #8 0x00007fd440b14cba in std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #9 0x00007fd441061c1e in std::ostream::operator<< (__n=<optimized out>, this=0x7fff30eaf700) at /usr/include/c++/6/ostream:185. #10 textinput::TerminalDisplayUnix::HandleResizeSignal (this=<optimized out>) at /home/eguiraud/ROOT/root/core/textinput/src/textinput/TerminalDisplayUnix.cpp:148. #11 <signal handler called>. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6978,usability,error,error,6978,"3bebcd31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_bui",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:6984,usability,error,error,6984,"31 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. #37 0x00007fd43bf4d3bf in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #38 0x00007fd43be441aa in HandleInterpreterException (metaProcessor=0x558e2aa2dcc0, . input_line=0x558e32ba5ec0 ""reinterpret_cast<ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>*>(0x7fff30eb3a10)->Snapshot<int, vector<float>, int, float>(\""a/myTree\"", \""test_snapshot_inDirectory_output.root\"", *r""..., compRes=@0x7fff30eb351c: cling::Interpreter::kSuccess, result=result@entry=0x7fff30eb3640) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:1927. #39 0x00007fd43be5331e in TCling::ProcessLine (this=this@entry=0x558e2a66d6f0, line=<optimized out>, error=error@entry=0x7fff30eb390c) at /home/eguiraud/ROOT/root/core/metacling/src/TCling.cxx:2085. #40 0x00007fd4359a3504 in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=this@entry=0x7fff30eb41a0, treename=..., filename=..., . columnList=std::vector of length 4, capacity 32 = {...}) at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:403. #41 0x00007fd4359a55ba in ROOT::Experimental::TDF::TInterface<ROOT::Detail::TDF::TFilterBase>::Snapshot (this=0x7fff30eb41a0, treename=..., filename=..., columnNameRegexp=...). at /home/eguiraud/ROOT/root_build/include/ROOT/TDFInterface.hxx:458. #42 0x00007fd436299f11 in do_work(char const*, char const*, char const*, char const*) () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #43 0x00007fd43629ac08 in runTest() () from /home/eguiraud/ROOT/root_build/roottest/root/dataframe/test_snapshot_C.so. #44 0x00007fd43629ac26 in test_snapshot() () from /home/eguiraud/ROOT/root_build/roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:118,deployability,build,build,118,"yes, the deadlock happens before fanning out to multi-threading. but as I said I cannot reproduce it now with a clean build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:9,performance,deadlock,deadlock,9,"yes, the deadlock happens before fanning out to multi-threading. but as I said I cannot reproduce it now with a clean build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:48,performance,multi-thread,multi-threading,48,"yes, the deadlock happens before fanning out to multi-threading. but as I said I cannot reproduce it now with a clean build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:72,availability,fault,fault,72,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:529,availability,operat,operator,529,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:72,energy efficiency,fault,fault,72,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:100,energy efficiency,alloc,allocate,100,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:27,performance,lock,lock,27,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:72,performance,fault,fault,72,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:109,performance,memor,memory,109,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1350,performance,memor,memory,1350,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:72,reliability,fault,fault,72,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:72,safety,fault,fault,72,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:27,security,lock,lock,27,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1488,security,sign,signal,1488,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:109,usability,memor,memory,109,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:1350,usability,memor,memory,1350,"Ok. Fair enough. The 'dead-lock' is a red-herring. It is due to the sig-fault handler attempting to allocate memory (we have a proposal to fix that which is waiting on me to do some cleanups). The 'real' problem is:. ```. #12 malloc_consolidate (av=av@entry=0x7fd4402c9b00 <main_arena>) at malloc.c:4211. #13 0x00007fd43ffa8dca in _int_malloc (av=av@entry=0x7fd4402c9b00 <main_arena>, bytes=bytes@entry=1536) at malloc.c:3488. #14 0x00007fd43ffaaf34 in __GI___libc_malloc (bytes=1536) at malloc.c:2928. #15 0x00007fd440a967a8 in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6. #16 0x00007fd43bfb375a in llvm::DenseMap<clang::Decl const*, clang::CodeGen::Address, llvm::DenseMapInfo<clang::Decl const*>, llvm::detail::DenseMapPair<clang::Decl const*, clang::CodeGen::Address> >::grow(unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #17 0x00007fd43c0c386a in clang::CodeGen::CodeGenFunction::EmitParmDecl(clang::VarDecl const&, clang::CodeGen::CodeGenFunction::ParamValue, unsigned int) () from /home/eguiraud/ROOT/root_build/lib/libCling.so. #18 0x00007fd43c09b812 in clang::CodeGen::CodeGenFunction::EmitFunctionProlog(clang::CodeGen::CGFunctionInfo const&, llvm::Function*, clang::CodeGen::FunctionArgList const&) (). from /home/eguiraud/ROOT/root_build/lib/libCling.so. ```. I.e. a crash (out-of-memory?) during malloc during JIT compilation. I recommend running with valgrind to get some more information. (And/or disabling the ROOT signal handler to see the real issue a little better).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:46,deployability,build,build,46,@pcanal you don't think it was due to a dirty build dir? I can't reproduce it anymore.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:11,deployability,build,build,11,"@phsft-bot build, please",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:55,deployability,build,build,55,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:102,deployability,build,build,102,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:210,deployability,build,build,210,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:188,interoperability,compatib,compatible,188,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:163,reliability,diagno,diagnostic,163,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:177,safety,compl,completely,177,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:177,security,compl,completely,177,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:163,testability,diagno,diagnostic,163,> but as I said I cannot reproduce it now with a clean build. > you don't think it was due to a dirty build dir? I can't reproduce it anymore. Sorry I misread. My diagnostic is completely compatible with a bad build (i.e crazy malloc because two of the .o files disagree on the size of something for example ....).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/972:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/972
https://github.com/root-project/root/pull/976:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/976
https://github.com/root-project/root/pull/976:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/976
https://github.com/root-project/root/pull/977:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:0,deployability,Updat,Updated,0,Updated documentation. Ready for merge from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:0,safety,Updat,Updated,0,Updated documentation. Ready for merge from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:0,security,Updat,Updated,0,Updated documentation. Ready for merge from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:8,usability,document,documentation,8,Updated documentation. Ready for merge from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:90,availability,operat,operator,90,This PR is now fine and can be merged. I will add now also a simple test for the new mod. operator,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:68,safety,test,test,68,This PR is now fine and can be merged. I will add now also a simple test for the new mod. operator,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:61,testability,simpl,simple,61,This PR is now fine and can be merged. I will add now also a simple test for the new mod. operator,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:68,testability,test,test,68,This PR is now fine and can be merged. I will add now also a simple test for the new mod. operator,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:61,usability,simpl,simple,61,This PR is now fine and can be merged. I will add now also a simple test for the new mod. operator,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/979:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/979
https://github.com/root-project/root/pull/980:49,deployability,patch,patches-invalid-preprocessing-directive,49,Fixes: https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:49,safety,patch,patches-invalid-preprocessing-directive,49,Fixes: https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:49,security,patch,patches-invalid-preprocessing-directive,49,Fixes: https://root-forum.cern.ch/t/f26-v6-10-00-patches-invalid-preprocessing-directive/26197,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:31,reliability,doe,doesn,31,@peremato Can this go in? This doesn't effect the experiments and just fixes the linked issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:28,safety,review,review,28,Let's rely on a post-commit review by @peremato.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:28,testability,review,review,28,Let's rely on a post-commit review by @peremato.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/982:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:111,availability,slo,slots,111,"@dpiparo what would be a good test for the feature? It's hard to ""prove"" that different threads pass different slots",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:111,reliability,slo,slots,111,"@dpiparo what would be a good test for the feature? It's hard to ""prove"" that different threads pass different slots",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:30,safety,test,test,30,"@dpiparo what would be a good test for the feature? It's hard to ""prove"" that different threads pass different slots",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:30,testability,test,test,30,"@dpiparo what would be a good test for the feature? It's hard to ""prove"" that different threads pass different slots",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:373,availability,slo,slot,373,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:385,availability,slo,slot,385,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:698,deployability,scale,scale,698,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:63,energy efficiency,batter,battery,63,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:698,energy efficiency,scale,scale,698,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:698,modifiability,scal,scale,698,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:740,modifiability,scal,scaling,740,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:698,performance,scale,scale,698,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:373,reliability,slo,slot,373,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:385,reliability,slo,slot,385,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:77,safety,test,tests,77,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:77,testability,test,tests,77,"Hi @bluehood , good question: it's important to come up with a battery of (g)tests which stresses the feature! For how TDF from scratch works, perhaps a first, trivial check one could do is. ``` cpp. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<std::thread_id, nSlots> ids;. TDataFrame d(nSlots);. auto m = d.DefineSlot(""x"", [&ids](unsigned int slot) { ids[slot] = std::this_thread::get_id(); return 1 }).Max(""x"");. EXPECT_EQ(1, *m); // just in case. std::set<std::thread_id> s(ids.begin(), ids.end());. EXPECT_EQ(4, s.size());. ```. Others perhaps need to be added. As a side note, @amadio , this feature, in conjunction with all the fixes done to make the jitted code scale, is perhaps a trigger to revive the scaling of the Pythia generation on KNL :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:32,safety,test,tests,32,I'll now merge this and add the tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:32,testability,test,tests,32,I'll now merge this and add the tests.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:155,deployability,updat,update,155,@dpiparo Should I rerun everything on the Xeon server + KNL and get scaling data then? We do have the I/O workshop coming up and I will have to present an update there...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:68,modifiability,scal,scaling,68,@dpiparo Should I rerun everything on the Xeon server + KNL and get scaling data then? We do have the I/O workshop coming up and I will have to present an update there...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:102,performance,I/O,I/O,102,@dpiparo Should I rerun everything on the Xeon server + KNL and get scaling data then? We do have the I/O workshop coming up and I will have to present an update there...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:155,safety,updat,update,155,@dpiparo Should I rerun everything on the Xeon server + KNL and get scaling data then? We do have the I/O workshop coming up and I will have to present an update there...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:155,security,updat,update,155,@dpiparo Should I rerun everything on the Xeon server + KNL and get scaling data then? We do have the I/O workshop coming up and I will have to present an update there...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/983:90,integrability,interfac,interface,90,Working on the tdatasource in parallel here (https://github.com/dpiparo/tdatasource). The interface designed for it seems to do the job well. Still some issues in reading root files - working on them!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:90,interoperability,interfac,interface,90,Working on the tdatasource in parallel here (https://github.com/dpiparo/tdatasource). The interface designed for it seems to do the job well. Still some issues in reading root files - working on them!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:90,modifiability,interfac,interface,90,Working on the tdatasource in parallel here (https://github.com/dpiparo/tdatasource). The interface designed for it seems to do the job well. Still some issues in reading root files - working on them!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:30,performance,parallel,parallel,30,Working on the tdatasource in parallel here (https://github.com/dpiparo/tdatasource). The interface designed for it seems to do the job well. Still some issues in reading root files - working on them!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:90,usability,interface design,interface designed,90,Working on the tdatasource in parallel here (https://github.com/dpiparo/tdatasource). The interface designed for it seems to do the job well. Still some issues in reading root files - working on them!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:88,integrability,transform,transformations,88,"The only big thing missing is support for data-source columns in jitted actions (jitted transformations should work). It requires a bit of refactoring, I will get to it once we know the implementation is sound.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:88,interoperability,transform,transformations,88,"The only big thing missing is support for data-source columns in jitted actions (jitted transformations should work). It requires a bit of refactoring, I will get to it once we know the implementation is sound.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:139,modifiability,refact,refactoring,139,"The only big thing missing is support for data-source columns in jitted actions (jitted transformations should work). It requires a bit of refactoring, I will get to it once we know the implementation is sound.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:139,performance,refactor,refactoring,139,"The only big thing missing is support for data-source columns in jitted actions (jitted transformations should work). It requires a bit of refactoring, I will get to it once we know the implementation is sound.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:30,usability,support,support,30,"The only big thing missing is support for data-source columns in jitted actions (jitted transformations should work). It requires a bit of refactoring, I will get to it once we know the implementation is sound.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:125,deployability,contain,contains,125,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:233,integrability,interfac,interface,233,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:233,interoperability,interfac,interface,233,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:233,modifiability,interfac,interface,233,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:288,safety,test,tests,288,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:288,testability,test,tests,288,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:246,usability,document,documentation,246,The work @dpiparo has done has been merged into this branch:. * trivial data-source implementation: has just one column that contains the entry number. * ROOT data-source implementation: allows reading ROOT files via the data-source interface. * documentation for `TDataSource`. * google tests for both data-sources. Thanks Danilo!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:157,performance,multi-thread,multi-thread,157,**To do**. - [ ] gtest for support of non-copiable types in TDF+TDS. - [ ] gtest for support of non-default-constructible types in TDF+TDS. - [ ] gtests for multi-thread execution of TDF+TDS. - [x] add support for data-source columns in jitted actions,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:27,usability,support,support,27,**To do**. - [ ] gtest for support of non-copiable types in TDF+TDS. - [ ] gtest for support of non-default-constructible types in TDF+TDS. - [ ] gtests for multi-thread execution of TDF+TDS. - [x] add support for data-source columns in jitted actions,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:85,usability,support,support,85,**To do**. - [ ] gtest for support of non-copiable types in TDF+TDS. - [ ] gtest for support of non-default-constructible types in TDF+TDS. - [ ] gtests for multi-thread execution of TDF+TDS. - [x] add support for data-source columns in jitted actions,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:202,usability,support,support,202,**To do**. - [ ] gtest for support of non-copiable types in TDF+TDS. - [ ] gtest for support of non-default-constructible types in TDF+TDS. - [ ] gtests for multi-thread execution of TDF+TDS. - [x] add support for data-source columns in jitted actions,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/987:20,deployability,updat,update,20,Thanks for the nice update of the rootmap generation!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/987
https://github.com/root-project/root/pull/987:20,safety,updat,update,20,Thanks for the nice update of the rootmap generation!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/987
https://github.com/root-project/root/pull/987:20,security,updat,update,20,Thanks for the nice update of the rootmap generation!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/987
https://github.com/root-project/root/pull/988:63,deployability,patch,patch,63,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:79,deployability,fail,fails,79,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:114,deployability,fail,fails,114,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:228,deployability,modul,modules,228,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:228,modifiability,modul,modules,228,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:79,reliability,fail,fails,79,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:114,reliability,fail,fails,114,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:63,safety,patch,patch,63,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:95,safety,test,test,95,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:125,safety,test,test,125,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:228,safety,modul,modules,228,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:63,security,patch,patch,63,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:95,testability,test,test,95,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:125,testability,test,test,125,"I moved this into an extra PR because it somehow the CIFactory patch from #930 fails a certain test. If this also fails this test, then I at least know it's related to this ASTConsumer (as everything else should be behind a `if(modules)`).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:47,deployability,fail,failing,47,"@vgvassilev @Axel-Naumann any clue why this is failing this test? The only outside visible change should be that you now no longer can `do getASTConsumer()` and then cast it to the custom consumer type, but I don't see any point where we do this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:47,reliability,fail,failing,47,"@vgvassilev @Axel-Naumann any clue why this is failing this test? The only outside visible change should be that you now no longer can `do getASTConsumer()` and then cast it to the custom consumer type, but I don't see any point where we do this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:60,safety,test,test,60,"@vgvassilev @Axel-Naumann any clue why this is failing this test? The only outside visible change should be that you now no longer can `do getASTConsumer()` and then cast it to the custom consumer type, but I don't see any point where we do this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:60,testability,test,test,60,"@vgvassilev @Axel-Naumann any clue why this is failing this test? The only outside visible change should be that you now no longer can `do getASTConsumer()` and then cast it to the custom consumer type, but I don't see any point where we do this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:181,usability,custom,custom,181,"@vgvassilev @Axel-Naumann any clue why this is failing this test? The only outside visible change should be that you now no longer can `do getASTConsumer()` and then cast it to the custom consumer type, but I don't see any point where we do this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/991:23,availability,failur,failure,23,This fixes the obscure failure in #988,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/991
https://github.com/root-project/root/pull/991:23,deployability,fail,failure,23,This fixes the obscure failure in #988,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/991
https://github.com/root-project/root/pull/991:23,performance,failur,failure,23,This fixes the obscure failure in #988,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/991
https://github.com/root-project/root/pull/991:23,reliability,fail,failure,23,This fixes the obscure failure in #988,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/991
https://github.com/root-project/root/pull/993:48,security,immut,immutable,48,I decided to use `()` because a Python tuple is immutable and matches well the C++ initializer list `{...}`. . @Axel-Naumann do you refer to std::initializer_list?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/993
https://github.com/root-project/root/pull/993:11,deployability,build,build,11,"@phsft-bot build, please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/993
https://github.com/root-project/root/pull/994:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_modules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_modules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/995:16,safety,test,test,16,Could you add a test testing this under `cling/test`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:21,safety,test,testing,21,Could you add a test testing this under `cling/test`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:47,safety,test,test,47,Could you add a test testing this under `cling/test`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:16,testability,test,test,16,Could you add a test testing this under `cling/test`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:21,testability,test,testing,21,Could you add a test testing this under `cling/test`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:47,testability,test,test,47,Could you add a test testing this under `cling/test`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/996:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:11,deployability,build,build,11,"@phsft-bot build, again and again...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/997:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/997
https://github.com/root-project/root/pull/997:11,deployability,build,build,11,@phsft-bot build on mac1012/native,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/997
https://github.com/root-project/root/pull/999:52,energy efficiency,sustainab,sustainability,52,"Yes I'll have to take care of this - it's under the sustainability flag, so never high priority enough :-( I'll get to it at some point!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/999
https://github.com/root-project/root/pull/1002:367,deployability,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:472,deployability,build,build,472,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:563,energy efficiency,reduc,reduces,563,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:367,integrability,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:367,interoperability,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:367,modifiability,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:367,reliability,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:485,reliability,doe,doesn,485,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:61,security,team,team,61,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:367,security,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:367,testability,integr,integrate-root-my-project-cmake,367,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:513,testability,simpl,simplification,513,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:513,usability,simpl,simplification,513,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:532,usability,user,users,532,"Thanks for your PR, @guiguem ! After a discussion within the team we decided not to apply it for the following reasons:. - RooFit is not even enabled by default. If we reconsider that ROOT should really be built with RooFit then we will revisit your PR (or something similar). - it is fairly trivial to add `RooFit` to CMake's `find_package` https://root.cern.ch/how/integrate-root-my-project-cmake / to add a `-lRooFit` behind `root-config --libs`, so adding this to our build system doesn't appear to be a huge simplification for users. I hope this explanation reduces a bit the frustration that our decision might cause - we do appreciate your suggestion especially as it's a PR!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:83,security,modif,modification,83,"Thank you for considering this PR and for your answer, @Axel-Naumann . The way the modification was designed accounts for the case when RooFit is not enabled (by not adding the library), so I don't understand your first reason. Also I thought this findROOT.cmake was supposed to be used generically by people willing to find the root libs via cmake. Even if I agree this is possible, it is not obvious from the documentation and the page you just mention, which is the reason why I modified the findROOT.cmake in the first place. Maybe I think adding some documentation would then be helpful if this PR is not applied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:482,security,modif,modified,482,"Thank you for considering this PR and for your answer, @Axel-Naumann . The way the modification was designed accounts for the case when RooFit is not enabled (by not adding the library), so I don't understand your first reason. Also I thought this findROOT.cmake was supposed to be used generically by people willing to find the root libs via cmake. Even if I agree this is possible, it is not obvious from the documentation and the page you just mention, which is the reason why I modified the findROOT.cmake in the first place. Maybe I think adding some documentation would then be helpful if this PR is not applied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:198,testability,understand,understand,198,"Thank you for considering this PR and for your answer, @Axel-Naumann . The way the modification was designed accounts for the case when RooFit is not enabled (by not adding the library), so I don't understand your first reason. Also I thought this findROOT.cmake was supposed to be used generically by people willing to find the root libs via cmake. Even if I agree this is possible, it is not obvious from the documentation and the page you just mention, which is the reason why I modified the findROOT.cmake in the first place. Maybe I think adding some documentation would then be helpful if this PR is not applied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:411,usability,document,documentation,411,"Thank you for considering this PR and for your answer, @Axel-Naumann . The way the modification was designed accounts for the case when RooFit is not enabled (by not adding the library), so I don't understand your first reason. Also I thought this findROOT.cmake was supposed to be used generically by people willing to find the root libs via cmake. Even if I agree this is possible, it is not obvious from the documentation and the page you just mention, which is the reason why I modified the findROOT.cmake in the first place. Maybe I think adding some documentation would then be helpful if this PR is not applied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:556,usability,document,documentation,556,"Thank you for considering this PR and for your answer, @Axel-Naumann . The way the modification was designed accounts for the case when RooFit is not enabled (by not adding the library), so I don't understand your first reason. Also I thought this findROOT.cmake was supposed to be used generically by people willing to find the root libs via cmake. Even if I agree this is possible, it is not obvious from the documentation and the page you just mention, which is the reason why I modified the findROOT.cmake in the first place. Maybe I think adding some documentation would then be helpful if this PR is not applied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:584,usability,help,helpful,584,"Thank you for considering this PR and for your answer, @Axel-Naumann . The way the modification was designed accounts for the case when RooFit is not enabled (by not adding the library), so I don't understand your first reason. Also I thought this findROOT.cmake was supposed to be used generically by people willing to find the root libs via cmake. Even if I agree this is possible, it is not obvious from the documentation and the page you just mention, which is the reason why I modified the findROOT.cmake in the first place. Maybe I think adding some documentation would then be helpful if this PR is not applied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:299,deployability,build,build,299,"Dear Mathieu @guiguem - excellent point on the doc, thanks! I have created https://sft.its.cern.ch/jira/browse/ROOT-9009 for it. The first reason is about RooFit being a crucial part or not. If it is, we should include it in the (crucial) libraries that `find_package` sets; but then we should also build it by default (because it's crucial). As long as we don't build it by default we mark it as ""not crucial for ROOT"". This might well change in the near future, given the relevance of RooFit - at which point we'll add it to `find_package`, too!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:363,deployability,build,build,363,"Dear Mathieu @guiguem - excellent point on the doc, thanks! I have created https://sft.its.cern.ch/jira/browse/ROOT-9009 for it. The first reason is about RooFit being a crucial part or not. If it is, we should include it in the (crucial) libraries that `find_package` sets; but then we should also build it by default (because it's crucial). As long as we don't build it by default we mark it as ""not crucial for ROOT"". This might well change in the near future, given the relevance of RooFit - at which point we'll add it to `find_package`, too!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1003:103,integrability,interfac,interface,103,One meta point. I am not sure whether a global setting (as opposed to a per tree) setting is the right interface. (As is the setting is inherently non-thread safe and another thread could switch during the creation of a TTree) ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:103,interoperability,interfac,interface,103,One meta point. I am not sure whether a global setting (as opposed to a per tree) setting is the right interface. (As is the setting is inherently non-thread safe and another thread could switch during the creation of a TTree) ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:103,modifiability,interfac,interface,103,One meta point. I am not sure whether a global setting (as opposed to a per tree) setting is the right interface. (As is the setting is inherently non-thread safe and another thread could switch during the creation of a TTree) ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:158,safety,safe,safe,158,One meta point. I am not sure whether a global setting (as opposed to a per tree) setting is the right interface. (As is the setting is inherently non-thread safe and another thread could switch during the creation of a TTree) ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:42,availability,error,error,42,> /tree/tree/src/TTreeSettings.cxx:61:25: error: no template named 'TRangeStaticCast'; did you mean 'ROOT::Detail::TRangeStaticCast'? My apologies. I moved TRangeStaticCast to ROOT::Detail.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:42,performance,error,error,42,> /tree/tree/src/TTreeSettings.cxx:61:25: error: no template named 'TRangeStaticCast'; did you mean 'ROOT::Detail::TRangeStaticCast'? My apologies. I moved TRangeStaticCast to ROOT::Detail.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:42,safety,error,error,42,> /tree/tree/src/TTreeSettings.cxx:61:25: error: no template named 'TRangeStaticCast'; did you mean 'ROOT::Detail::TRangeStaticCast'? My apologies. I moved TRangeStaticCast to ROOT::Detail.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:42,usability,error,error,42,> /tree/tree/src/TTreeSettings.cxx:61:25: error: no template named 'TRangeStaticCast'; did you mean 'ROOT::Detail::TRangeStaticCast'? My apologies. I moved TRangeStaticCast to ROOT::Detail.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:192,usability,minim,minimally,192,"@pcanal - this settings _is_ done on a per-tree basis, not global. Or, are you suggesting it should be global (I don't particularly care for globals, as experimental settings should target as minimally as possible!)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:119,integrability,interfac,interface,119,"> this settings is done on a per-tree basis, not global. . Fair enough. I have to read the example more carefully, the interface seems at very a bit awkward.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:119,interoperability,interfac,interface,119,"> this settings is done on a per-tree basis, not global. . Fair enough. I have to read the example more carefully, the interface seems at very a bit awkward.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:119,modifiability,interfac,interface,119,"> this settings is done on a per-tree basis, not global. . Fair enough. I have to read the example more carefully, the interface seems at very a bit awkward.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:13,integrability,interfac,interface,13,"Agreed - the interface is awkward. However, since I wanted any use of the interface to go through the `ROOT::Experimental` namespace, I couldn't come up with anything cleaner. Suggestions are welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:74,integrability,interfac,interface,74,"Agreed - the interface is awkward. However, since I wanted any use of the interface to go through the `ROOT::Experimental` namespace, I couldn't come up with anything cleaner. Suggestions are welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:13,interoperability,interfac,interface,13,"Agreed - the interface is awkward. However, since I wanted any use of the interface to go through the `ROOT::Experimental` namespace, I couldn't come up with anything cleaner. Suggestions are welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:74,interoperability,interfac,interface,74,"Agreed - the interface is awkward. However, since I wanted any use of the interface to go through the `ROOT::Experimental` namespace, I couldn't come up with anything cleaner. Suggestions are welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:13,modifiability,interfac,interface,13,"Agreed - the interface is awkward. However, since I wanted any use of the interface to go through the `ROOT::Experimental` namespace, I couldn't come up with anything cleaner. Suggestions are welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:74,modifiability,interfac,interface,74,"Agreed - the interface is awkward. However, since I wanted any use of the interface to go through the `ROOT::Experimental` namespace, I couldn't come up with anything cleaner. Suggestions are welcome!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:16,deployability,API,API,16,So the proposed API seems like:. ```. TTree *t1 = new TTree(...);. ROOT::Experimental::TTreeSettings settings(t1);. settings.SetFeature(TBasket::EIOBits::kGenerateOffsetMap);. ```. advantage: lives in ROOT::Experimental::. disadvantage: external setter. disadvantage: Setting of TTree using TBasket bits .... So an alternative could be. ```. t1->SetFeature(ROOT::Experiemental::EIOBits::kBasketGenerateOffsetMap). ```. disadvantage: EIOBits is in neither TTree nor TBranch nor TBaskets (i.e. harder to find) and mixed various bits/ideas together ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:16,integrability,API,API,16,So the proposed API seems like:. ```. TTree *t1 = new TTree(...);. ROOT::Experimental::TTreeSettings settings(t1);. settings.SetFeature(TBasket::EIOBits::kGenerateOffsetMap);. ```. advantage: lives in ROOT::Experimental::. disadvantage: external setter. disadvantage: Setting of TTree using TBasket bits .... So an alternative could be. ```. t1->SetFeature(ROOT::Experiemental::EIOBits::kBasketGenerateOffsetMap). ```. disadvantage: EIOBits is in neither TTree nor TBranch nor TBaskets (i.e. harder to find) and mixed various bits/ideas together ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:16,interoperability,API,API,16,So the proposed API seems like:. ```. TTree *t1 = new TTree(...);. ROOT::Experimental::TTreeSettings settings(t1);. settings.SetFeature(TBasket::EIOBits::kGenerateOffsetMap);. ```. advantage: lives in ROOT::Experimental::. disadvantage: external setter. disadvantage: Setting of TTree using TBasket bits .... So an alternative could be. ```. t1->SetFeature(ROOT::Experiemental::EIOBits::kBasketGenerateOffsetMap). ```. disadvantage: EIOBits is in neither TTree nor TBranch nor TBaskets (i.e. harder to find) and mixed various bits/ideas together ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:103,interoperability,specif,specific,103,> do you really mean Settings or do you mean TSettings. I was beeing 'quick' and did not mean anything specific. If you mean in. ```. TTree::Setting normalSettings; .... ```. The T there is indeed optional as TTree is a class and thus TTree::Setting can not be abbreviated. But in general we do keep the T as a ROOT trademark.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:142,availability,failur,failure,142,@pcanal - I believe all your above issues have been addressed. Note some of these items will revert suggestions from `clang-format`; expect a failure in the Travis-CI build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:142,deployability,fail,failure,142,@pcanal - I believe all your above issues have been addressed. Note some of these items will revert suggestions from `clang-format`; expect a failure in the Travis-CI build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:167,deployability,build,build,167,@pcanal - I believe all your above issues have been addressed. Note some of these items will revert suggestions from `clang-format`; expect a failure in the Travis-CI build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:124,interoperability,format,format,124,@pcanal - I believe all your above issues have been addressed. Note some of these items will revert suggestions from `clang-format`; expect a failure in the Travis-CI build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:142,performance,failur,failure,142,@pcanal - I believe all your above issues have been addressed. Note some of these items will revert suggestions from `clang-format`; expect a failure in the Travis-CI build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:142,reliability,fail,failure,142,@pcanal - I believe all your above issues have been addressed. Note some of these items will revert suggestions from `clang-format`; expect a failure in the Travis-CI build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:43,availability,failur,failures,43,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:18,deployability,build,build,18,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:37,deployability,build,build,37,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:43,deployability,fail,failures,43,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:65,deployability,infrastructur,infrastructure,65,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:43,performance,failur,failures,43,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:43,reliability,fail,failures,43,@phsft-bot please build. @pcanal the build failures look like an infrastructure issue unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:274,availability,error,errors,274,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:316,availability,failur,failure,316,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:316,deployability,fail,failure,316,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:467,deployability,fail,fail,467,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:31,energy efficiency,current,current,31,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:343,modifiability,exten,extend,343,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:274,performance,error,errors,274,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:316,performance,failur,failure,316,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:316,reliability,fail,failure,316,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:467,reliability,fail,fail,467,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:274,safety,error,errors,274,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:274,usability,error,errors,274,"Hi,. There is nice code in the current TBasket.cxx file which potentially has much better compression then proposed one. It is here:. https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L858-L883. It is commented out with remark that it has potential errors. I see two reasons why it may have failure. First, one should extend check:. if (1 && fEntryOffset && fNevBuf>=3 && !fDisplacement) . If `!fDisplacement` missing, then some classes will fail. And second, probably some readers relies that `TBasket::GetEntryOffset()` returns array - even when fNevBufSize set. In such case one need to reintroduce `fEntryOffset` array in reading part of TBasket. My opinion, that such change will bring much better compression.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:400,integrability,event,event,400,"@linev - while I think that's a reasonable improvement, it's orthogonal to this PR. It can be done independently in a separate PR. It will also _not_ produce as significant gains in the following cases:. 1. This PR will skip entry offset array serialization even when the entries in the basket have different sizes. 2. Even when entry offset array serialization can't be skipped, this serializes the event sizes in the array, not the offsets. When entry sizes are ""mostly the same"" (i.e., it's the number of muons in the event, which would have a low dynamic range), this will compress better. Is there a ticket open for the case where all the entry offsets just happen to be the same? We can do that in a follow-up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:521,integrability,event,event,521,"@linev - while I think that's a reasonable improvement, it's orthogonal to this PR. It can be done independently in a separate PR. It will also _not_ produce as significant gains in the following cases:. 1. This PR will skip entry offset array serialization even when the entries in the basket have different sizes. 2. Even when entry offset array serialization can't be skipped, this serializes the event sizes in the array, not the offsets. When entry sizes are ""mostly the same"" (i.e., it's the number of muons in the event, which would have a low dynamic range), this will compress better. Is there a ticket open for the case where all the entry offsets just happen to be the same? We can do that in a follow-up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:161,security,sign,significant,161,"@linev - while I think that's a reasonable improvement, it's orthogonal to this PR. It can be done independently in a separate PR. It will also _not_ produce as significant gains in the following cases:. 1. This PR will skip entry offset array serialization even when the entries in the basket have different sizes. 2. Even when entry offset array serialization can't be skipped, this serializes the event sizes in the array, not the offsets. When entry sizes are ""mostly the same"" (i.e., it's the number of muons in the event, which would have a low dynamic range), this will compress better. Is there a ticket open for the case where all the entry offsets just happen to be the same? We can do that in a follow-up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:135,deployability,fail,fails,135,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:183,energy efficiency,estimat,estimation,183,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:382,interoperability,format,format,382,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:444,interoperability,format,format,444,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:135,reliability,fail,fails,135,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:428,reliability,doe,does,428,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:256,testability,simpl,simple,256,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:256,usability,simpl,simple,256,"@bbockelm . My proposal (which actually not my) is not orthogonal - it solves similar problem in much more compact way. And only if it fails, one could try your approach. Do you have estimation in overall compression gain? It could be, that after applying simple algorithm such gain will be negligible on realistic data. And probably one could just skip your changes in TBasket raw format. . As you could see - Victor algorithm does not change format.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:569,energy efficiency,measur,measure,569,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:378,integrability,sub,subset,378,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:409,integrability,event,events,409,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:358,reliability,doe,does,358,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:480,security,ident,identical,480,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:227,testability,simpl,simple,227,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:386,testability,simpl,simple,386,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:227,usability,simpl,simple,227,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:386,usability,simpl,simple,386,"It solves a relatively different problem. It skips offset array generation in the case of ""arbitrary objects are serialized and all objects in the basket happen to have the same size"". This PR skips offset array generation of ""simple objects of all different sizes"". So, the approaches differ in which classes/types they apply to and under what cases. There does exist a common subset (simple types where all events have the same size); in those cases, they will result in mostly-identical output (the uncompressed basket from this PR will be a single byte larger). We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:5,energy efficiency,measur,measure,5,"> We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4. My expectation, that simple approach gives 10% or maybe more - while it much more efficient in terms of produced data size. Therefore I would recommend to try it first - it is really very simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:102,testability,simpl,simple,102,"> We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4. My expectation, that simple approach gives 10% or maybe more - while it much more efficient in terms of produced data size. Therefore I would recommend to try it first - it is really very simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:269,testability,simpl,simple,269,"> We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4. My expectation, that simple approach gives 10% or maybe more - while it much more efficient in terms of produced data size. Therefore I would recommend to try it first - it is really very simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:102,usability,simpl,simple,102,"> We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4. My expectation, that simple approach gives 10% or maybe more - while it much more efficient in terms of produced data size. Therefore I would recommend to try it first - it is really very simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:163,usability,efficien,efficient,163,"> We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4. My expectation, that simple approach gives 10% or maybe more - while it much more efficient in terms of produced data size. Therefore I would recommend to try it first - it is really very simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:269,usability,simpl,simple,269,"> We measure an ~18% decrease when applied to CMS's NanoAOD compressed with LZ4. My expectation, that simple approach gives 10% or maybe more - while it much more efficient in terms of produced data size. Therefore I would recommend to try it first - it is really very simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:271,security,ident,identical,271,"@pcanal @bbockelm. Actually, another idea. If we can compress (eliminate) fEntryOffset, why not try to compress data themselves in same manner. . If all data portions of the same size, one can just check if all data the same. And instead of trying to save 1000 copies of identical data and hoping for good compression (GZIP or LZ4), just save only one entry of such identical data",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:366,security,ident,identical,366,"@pcanal @bbockelm. Actually, another idea. If we can compress (eliminate) fEntryOffset, why not try to compress data themselves in same manner. . If all data portions of the same size, one can just check if all data the same. And instead of trying to save 1000 copies of identical data and hoping for good compression (GZIP or LZ4), just save only one entry of such identical data",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:51,integrability,interfac,interface,51,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:151,integrability,translat,translated,151,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:51,interoperability,interfac,interface,51,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:151,interoperability,translat,translated,151,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:51,modifiability,interfac,interface,51,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:172,performance,disk,disk,172,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:8,usability,person,person,8,"From in-person discussion with Philippe:. - Change interface at the `TIOFeatures`-level from `TBasket::EIOBits` to `ROOT::EIOFeatures`, which then get translated to the on-disk IO bits. - Add the corresponding `ROOT::Experimental::EIOFeatures` and `ROOT::Experimental::EIOUnsupportedFeatures` enums. - The above also allows us to move `TIOFeatures` into the `ROOT` namespace. Instead of storing `UChar_t` directly in the `TTree` / `TBranch` / `TBasket` classes, we can store `TIOFeature`. We would only use `TBasket::EIOBits` in the serialization code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:32,safety,review,review,32,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:67,safety,compl,completed,67,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:101,safety,test,tests,101,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:67,security,compl,completed,67,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:32,testability,review,review,32,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:96,testability,unit,unit,96,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:101,testability,test,tests,101,@pcanal - I think I got all the review items from the latest round completed. Let's see how the unit tests go.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1004:81,deployability,configurat,configuration,81,"For some reason I had problems making this work on gcc > 4.9.2, but It may be my configuration. This PR will test that too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:81,integrability,configur,configuration,81,"For some reason I had problems making this work on gcc > 4.9.2, but It may be my configuration. This PR will test that too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:81,modifiability,configur,configuration,81,"For some reason I had problems making this work on gcc > 4.9.2, but It may be my configuration. This PR will test that too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:109,safety,test,test,109,"For some reason I had problems making this work on gcc > 4.9.2, but It may be my configuration. This PR will test that too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:81,security,configur,configuration,81,"For some reason I had problems making this work on gcc > 4.9.2, but It may be my configuration. This PR will test that too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:109,testability,test,test,109,"For some reason I had problems making this work on gcc > 4.9.2, but It may be my configuration. This PR will test that too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:11,deployability,build,builds,11,"Passes the builds without vectorization. Boh, I guess it was my problem 🤷‍♂️",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:11,deployability,build,build,11,@phsft-bot build with flags -Dbultin_veccore=ON -Dbuiltin_vc=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:8,interoperability,format,formatting,8,Applied formatting changes,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:123,deployability,build,buildid,123,Good that now this is streamlined. Small note: this pr introduces warnings: http://cdash.cern.ch/viewBuildError.php?type=1&buildid=397963. Perhaps it would be good to address them before merging.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:54,safety,test,test-veccore,54,"@dpiparo They are Vc warnings. The first one jumps in test-veccore, which I didn't touch, so I'm not sure I can do anything there... @amadio?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:54,testability,test,test-veccore,54,"@dpiparo They are Vc warnings. The first one jumps in test-veccore, which I didn't touch, so I'm not sure I can do anything there... @amadio?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:159,performance,time,times,159,"With that I meant that these look like the Vc warnings we know we get on Mac, which people with way better knowledge than me on this area have tackled several times and, from last time I heard, not succeeded. But I may also be mistaken, maybe that's not the cause or maybe there's some workaround in place until Vc is fixed. Of course, I plan to discuss it, check it and confirm it. I can tag this as ""do not merge"" until then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:180,performance,time,time,180,"With that I meant that these look like the Vc warnings we know we get on Mac, which people with way better knowledge than me on this area have tackled several times and, from last time I heard, not succeeded. But I may also be mistaken, maybe that's not the cause or maybe there's some workaround in place until Vc is fixed. Of course, I plan to discuss it, check it and confirm it. I can tag this as ""do not merge"" until then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:338,testability,plan,plan,338,"With that I meant that these look like the Vc warnings we know we get on Mac, which people with way better knowledge than me on this area have tackled several times and, from last time I heard, not succeeded. But I may also be mistaken, maybe that's not the cause or maybe there's some workaround in place until Vc is fixed. Of course, I plan to discuss it, check it and confirm it. I can tag this as ""do not merge"" until then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:371,usability,confirm,confirm,371,"With that I meant that these look like the Vc warnings we know we get on Mac, which people with way better knowledge than me on this area have tackled several times and, from last time I heard, not succeeded. But I may also be mistaken, maybe that's not the cause or maybe there's some workaround in place until Vc is fixed. Of course, I plan to discuss it, check it and confirm it. I can tag this as ""do not merge"" until then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:172,safety,test,tests,172,"This is strange indeed, maybe that particular kind of warning is not suppressed in the headers. In any case, the warnings are not due to Xavi's code, but due to Vc. If the tests passed, I'd say the warnings are not a blocker and this can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:172,testability,test,tests,172,"This is strange indeed, maybe that particular kind of warning is not suppressed in the headers. In any case, the warnings are not due to Xavi's code, but due to Vc. If the tests passed, I'd say the warnings are not a blocker and this can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1005:34,safety,test,test,34,"Thanks for your PR! Can you add a test or maybe just post a few lines of python code that are fixed by this PR, so we can add it to our python test suite ourselves?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:143,safety,test,test,143,"Thanks for your PR! Can you add a test or maybe just post a few lines of python code that are fixed by this PR, so we can add it to our python test suite ourselves?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:34,testability,test,test,34,"Thanks for your PR! Can you add a test or maybe just post a few lines of python code that are fixed by this PR, so we can add it to our python test suite ourselves?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:143,testability,test,test,143,"Thanks for your PR! Can you add a test or maybe just post a few lines of python code that are fixed by this PR, so we can add it to our python test suite ourselves?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:359,availability,error,error,359,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:13,deployability,patch,patch,13,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:434,deployability,modul,module,434,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:434,modifiability,modul,module,434,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:359,performance,error,error,359,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:13,safety,patch,patch,13,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:93,safety,test,test,93,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:101,safety,test,test,101,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:199,safety,except,exception,199,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:247,safety,except,exception,247,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:359,safety,error,error,359,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:434,safety,modul,module,434,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:13,security,patch,patch,13,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:93,testability,test,test,93,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:101,testability,test,test,101,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:370,testability,Trace,Traceback,370,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:359,usability,error,error,359,"Without this patch, using python 3.6 in anaconda3:. ```. >>> import ROOT. >>> h = ROOT.TH1D('test', 'test', 100, 0, 1). AttributeError: type object 'TArray' has no attribute '__getitem__'. The above exception was the direct cause of the following exception:. SystemError: <built-in method mro of ROOT.PyRootType object at 0x17d57b8> returned a result with an error set. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 459, in __getattr1. return getattr( self, name ). File ""/home/maxnoe/.local/root5/lib/ROOT.py"", line 486, in __getattr2. attr = _root.LookupRootEntity( name ). AttributeError: TH1D. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:10,deployability,build,build,10,"We do not build ROOT 5.34 with Python 3.6 on our nightlies. We do not actively maintain this version anymore. So, I am going to merge the RP and cross the fingers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:93,deployability,version,version,93,"We do not build ROOT 5.34 with Python 3.6 on our nightlies. We do not actively maintain this version anymore. So, I am going to merge the RP and cross the fingers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:93,integrability,version,version,93,"We do not build ROOT 5.34 with Python 3.6 on our nightlies. We do not actively maintain this version anymore. So, I am going to merge the RP and cross the fingers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:79,modifiability,maintain,maintain,79,"We do not build ROOT 5.34 with Python 3.6 on our nightlies. We do not actively maintain this version anymore. So, I am going to merge the RP and cross the fingers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:93,modifiability,version,version,93,"We do not build ROOT 5.34 with Python 3.6 on our nightlies. We do not actively maintain this version anymore. So, I am going to merge the RP and cross the fingers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:79,safety,maintain,maintain,79,"We do not build ROOT 5.34 with Python 3.6 on our nightlies. We do not actively maintain this version anymore. So, I am going to merge the RP and cross the fingers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1007:118,integrability,INTERFAC,INTERFACE,118,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:35,interoperability,specif,specify,35,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:86,interoperability,specif,specify,86,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:118,interoperability,INTERFAC,INTERFACE,118,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:118,modifiability,INTERFAC,INTERFACE,118,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:256,safety,test,test,256,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:256,testability,test,test,256,"The problem I see is that we can't specify ""link only here all of Vc"", but we have to specify this when we create the INTERFACE linking options. So every library that directly links against should get it, but I don't think it propagates. Maybe someone can test this manually (or I'll do when I have a few minutes). Will put a DNM until this is known.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:155,deployability,build,building,155,--while-archive does not work on MacOs. I think one should use -all_load in this case. However applying this change I get a lot of duplicates symbols when building,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:16,reliability,doe,does,16,--while-archive does not work on MacOs. I think one should use -all_load in this case. However applying this change I get a lot of duplicates symbols when building,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:11,deployability,build,build,11,@phsft-bot build with flags -Dbuiltin_vc=ON -Dbuiltin_veccore=ON -Dvc=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:694,performance,content,content,694,"I am trying to create a VecCore/Vc benchmark in rootbench but I am hit by that. We cannot find Vc because it is 'external' but the its symbols are not in any ROOT library. I can confirm that `--whole-archive` does not work on OSX. Using `-all_load` or `-force_load` yields duplicate symbols. Eg. ```. duplicate symbol __ZN4Vc_16Common13TrigonometricINS_15ImplementationTILj6EEEE4atanINS_6VectorIdNS_9VectorAbi3AvxEEEEET_RKSA_ in:. ../../externals//usr/local/lib/libVc.a(trigonometric_AVX.cpp.o). ../../externals//usr/local/lib/libVc.a(trigonometric_AVX+FMA.cpp.o). ```. The duplication seems to be by design because Vc generates eg. `trigonometric_AVX.cpp` and `trigonometric_AVX+FMA.cpp`. The content of both is the same, thus `trigonometric_AVX.cpp.o` and `trigonometric_AVX+FMA.cpp.o` have duplicate symbols.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:209,reliability,doe,does,209,"I am trying to create a VecCore/Vc benchmark in rootbench but I am hit by that. We cannot find Vc because it is 'external' but the its symbols are not in any ROOT library. I can confirm that `--whole-archive` does not work on OSX. Using `-all_load` or `-force_load` yields duplicate symbols. Eg. ```. duplicate symbol __ZN4Vc_16Common13TrigonometricINS_15ImplementationTILj6EEEE4atanINS_6VectorIdNS_9VectorAbi3AvxEEEEET_RKSA_ in:. ../../externals//usr/local/lib/libVc.a(trigonometric_AVX.cpp.o). ../../externals//usr/local/lib/libVc.a(trigonometric_AVX+FMA.cpp.o). ```. The duplication seems to be by design because Vc generates eg. `trigonometric_AVX.cpp` and `trigonometric_AVX+FMA.cpp`. The content of both is the same, thus `trigonometric_AVX.cpp.o` and `trigonometric_AVX+FMA.cpp.o` have duplicate symbols.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:178,usability,confirm,confirm,178,"I am trying to create a VecCore/Vc benchmark in rootbench but I am hit by that. We cannot find Vc because it is 'external' but the its symbols are not in any ROOT library. I can confirm that `--whole-archive` does not work on OSX. Using `-all_load` or `-force_load` yields duplicate symbols. Eg. ```. duplicate symbol __ZN4Vc_16Common13TrigonometricINS_15ImplementationTILj6EEEE4atanINS_6VectorIdNS_9VectorAbi3AvxEEEEET_RKSA_ in:. ../../externals//usr/local/lib/libVc.a(trigonometric_AVX.cpp.o). ../../externals//usr/local/lib/libVc.a(trigonometric_AVX+FMA.cpp.o). ```. The duplication seems to be by design because Vc generates eg. `trigonometric_AVX.cpp` and `trigonometric_AVX+FMA.cpp`. The content of both is the same, thus `trigonometric_AVX.cpp.o` and `trigonometric_AVX+FMA.cpp.o` have duplicate symbols.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:0,availability,Ping,Ping,0,Ping... Shall we close that one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1007:17,usability,close,close,17,Ping... Shall we close that one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1010:182,energy efficiency,measur,measure,182,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:452,energy efficiency,schedul,schedule,452,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:437,integrability,asynchron,asynchronously,437,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:134,performance,time,time,134,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:437,performance,asynch,asynchronously,437,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:452,performance,schedul,schedule,452,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:369,testability,understand,understand,369,"Hi @zzxuanyuan , . a lot of work. Thanks for exploring these aspects. I would have two comments:. 1) Are we really sure that ~3% real time is a number we have enough ""resolution"" to measure accurately? . 2) If that 3% is there systematically for several long runs of a trivial example and for something like a CMSSW skimming job, perhaps we can do something else. If I understand correctly, the TTaskGroup at this point is just a way to asynchronously schedule work. Wouldn't a thread running a lambda invoking TThreadedExecutor do the job too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:433,energy efficiency,schedul,scheduler,433,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:482,energy efficiency,profil,profiling,482,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:56,integrability,event,events,56,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:392,integrability,interfac,interface,392,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:392,interoperability,interfac,interface,392,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:392,modifiability,interfac,interface,392,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:156,performance,perform,performance,156,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:425,performance,time,time,425,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:433,performance,schedul,scheduler,433,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:482,performance,profil,profiling,482,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:20,safety,test,tested,20,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:127,safety,test,test,127,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:20,testability,test,tested,20,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:127,testability,test,test,127,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:156,usability,perform,performance,156,"Hi @dpiparo ,. 1. I tested MainEvent.cxx with 500~50000 events on my desktop running Ubuntu 14.04. I repeated 10 runs for each test case and ~3% is average performance drop. I did not have a chance to run CMSSW skimming job. I am actually not familiar with CMSSW yet. 2. What you were saying is correct. Since my case only needs one thread to invoke TThreadExecutor, using tbb task_group run interface likely spends too much time on scheduler's receive_and_steal function (from the profiling results).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:116,security,polic,policy,116,"Hi @zzxuanyuan , if this new setup reveals good enough to get back that 3% we can even consider having an execution policy for Async to allow the user to hit the runtime, and therefore the workers pool, or spawn a new thread.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:146,usability,user,user,146,"Hi @zzxuanyuan , if this new setup reveals good enough to get back that 3% we can even consider having an execution policy for Async to allow the user to hit the runtime, and therefore the workers pool, or spawn a new thread.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:38,deployability,API,APIs,38,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:38,integrability,API,APIs,38,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:38,interoperability,API,APIs,38,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:81,reliability,doe,does,81,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:63,safety,valid,validate,63,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:63,security,validat,validate,63,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:31,testability,simpl,simple,31,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:31,usability,simpl,simple,31,"@dpiparo , we could start some simple APIs and I hope we could validate that ~3% does be caused by TTaskGroup.Run.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:41,deployability,API,API,41,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:45,deployability,upgrad,upgrade,45,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:169,deployability,Upgrad,Upgrading,169,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:41,integrability,API,API,41,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:41,interoperability,API,API,41,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:45,modifiability,upgrad,upgrade,45,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:140,modifiability,deco,decompression,140,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:169,modifiability,Upgrad,Upgrading,169,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:131,performance,parallel,parallel,131,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:162,safety,test,tests,162,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:162,testability,test,tests,162,"@zzxuanyuan , sure. Before diving in the API upgrade, let's be sure the 3% is gone and start with the thread implementation of the parallel decompression and its tests. Upgrading your solid work will be then straightforward!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:130,integrability,asynchron,asynchronous,130,"Hi @zzxuanyuan , I think we discussed this already, but I 'd like to go through this again. You need TTaskGroup to have something asynchronous. The real work is done by a ""parallel for"" incarnated in an invocation of the TThreadExecutor. . Given that the total number of workers is constant, can you remind me of the advantage we have of launching the ""parallel for"" from a different task/thread rather than having it invoked from the main thread directly? Is it because we think more tasks will be spawned by it in the meanwhile?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:130,performance,asynch,asynchronous,130,"Hi @zzxuanyuan , I think we discussed this already, but I 'd like to go through this again. You need TTaskGroup to have something asynchronous. The real work is done by a ""parallel for"" incarnated in an invocation of the TThreadExecutor. . Given that the total number of workers is constant, can you remind me of the advantage we have of launching the ""parallel for"" from a different task/thread rather than having it invoked from the main thread directly? Is it because we think more tasks will be spawned by it in the meanwhile?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:172,performance,parallel,parallel,172,"Hi @zzxuanyuan , I think we discussed this already, but I 'd like to go through this again. You need TTaskGroup to have something asynchronous. The real work is done by a ""parallel for"" incarnated in an invocation of the TThreadExecutor. . Given that the total number of workers is constant, can you remind me of the advantage we have of launching the ""parallel for"" from a different task/thread rather than having it invoked from the main thread directly? Is it because we think more tasks will be spawned by it in the meanwhile?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:353,performance,parallel,parallel,353,"Hi @zzxuanyuan , I think we discussed this already, but I 'd like to go through this again. You need TTaskGroup to have something asynchronous. The real work is done by a ""parallel for"" incarnated in an invocation of the TThreadExecutor. . Given that the total number of workers is constant, can you remind me of the advantage we have of launching the ""parallel for"" from a different task/thread rather than having it invoked from the main thread directly? Is it because we think more tasks will be spawned by it in the meanwhile?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:191,deployability,API,APIs,191,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:191,integrability,API,APIs,191,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:191,interoperability,API,APIs,191,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:135,modifiability,deco,decompressing,135,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:572,modifiability,deco,decompress,572,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:472,performance,parallel,parallelized,472,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:171,testability,plan,plan,171,"Hi @dpiparo ,. We want to group small baskets together so that a task can work on enough amount of work. Before TThreadExecutor starts decompressing baskets, our original plan (without async APIs) is that the main thread needs to iterate all baskets and assign a task with a group of baskets where their accumulated size is beyond 100KB (For a large basket >100 KB, we just assign that single basket to a task). Iterating all baskets and assigning them to tasks cannot be parallelized. It will block the main thread and it could be harmful if there are lots of baskets to decompress. Therefore, we decided to hide this sequential processing to some background thread and then we came up with idea that adopt async function calls to our code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:44,deployability,updat,updated,44,@zzxuanyuan - is it possible to get this PR updated / revised in the next day or two? I'll be at FNAL on Wednesday and would like to discuss this one with @pcanal.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:44,safety,updat,updated,44,@zzxuanyuan - is it possible to get this PR updated / revised in the next day or two? I'll be at FNAL on Wednesday and would like to discuss this one with @pcanal.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:44,security,updat,updated,44,@zzxuanyuan - is it possible to get this PR updated / revised in the next day or two? I'll be at FNAL on Wednesday and would like to discuss this one with @pcanal.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:209,availability,slo,slower,209,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:253,availability,slo,slow,253,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:258,availability,down,down,258,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:106,deployability,fail,fails,106,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:188,performance,perform,performance,188,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:106,reliability,fail,fails,106,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:209,reliability,slo,slower,209,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:253,reliability,slo,slow,253,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:188,usability,perform,performance,188,"@bbockelm I fix several issues addressed in your comments. Could you look at it now? clang-tidy-modernize fails due to ""sleep(0.2)"". I tried to change it to ""usleep(200000)"", however, the performance was much slower. Removing sleep function also causes slow down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:55,modifiability,variab,variable,55,"Hi, I think the sleep could be replaced by a condition variable? The stl also provide an implementation: http://en.cppreference.com/w/cpp/thread/condition_variable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:498,energy efficiency,current,currently,498,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:678,interoperability,share,share,678,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:48,modifiability,variab,variable,48,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:86,modifiability,variab,variable,86,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:122,performance,overhead,overhead,122,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:217,performance,overhead,overhead,217,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:733,security,sign,significant,733,"@dpiparo - we discussed the idea of a condition variable, but I'm wary. The condition variable approach causes a per-task overhead that is _always_ paid (as notify would have to be done from the tasks). This per-task overhead is one of the things that make the pthreads implementation problematic. However, this particular case is a fairly obscure corner case: this code is only triggered when there is exactly one remaining basket to unzip, the main thread needs it, and one of the TBB threads is currently working on it. Talking to Zhe, I think the best way to go is a busy-loop (with `sched_yield` in the Linux case) instead. It has no penalty in the common case - and won't share the potential to overshoot the waiting by such a significant amount.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:208,availability,slo,slow,208,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:528,availability,cluster,cluster,528,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:594,availability,slo,slow,594,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24,deployability,updat,updates,24,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:111,deployability,updat,updates,111,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:528,deployability,cluster,cluster,528,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:439,energy efficiency,current,current,439,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:556,energy efficiency,current,current,556,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:417,integrability,event,event,417,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:496,integrability,buffer,buffer,496,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:539,integrability,event,events,539,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:787,modifiability,deco,decompressed,787,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:990,modifiability,deco,decompressed,990,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:188,performance,perform,performance,188,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:268,performance,cach,cache,268,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:300,performance,workload,workload,300,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:327,performance,perform,performance,327,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:447,performance,cach,cache,447,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:490,performance,cach,cache,490,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:564,performance,cach,cache,564,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:599,performance,perform,performance,599,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:829,performance,cach,cache,829,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:857,performance,cach,cache,857,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:957,performance,cach,cache,957,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1014,performance,cach,cache,1014,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:208,reliability,slo,slow,208,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:594,reliability,slo,slow,594,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24,safety,updat,updates,24,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:111,safety,updat,updates,111,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24,security,updat,updates,24,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:111,security,updat,updates,111,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:582,security,polic,policy,582,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:910,security,access,accessed,910,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:188,usability,perform,performance,188,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:327,usability,perform,performance,327,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:599,usability,perform,performance,599,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:767,usability,help,helpful,767,"@pcanal @bbockelm . The updates address some issues for random read case and the code should be good now. Some updates after last Friday meeting:. As we discussed last Friday, random read performance is very slow. It technically cannot be improved if we decide to use cache. I also tried random read workload with pthread. The performance was the same with tbb. I think the reason is obvious that reading next random event will invalidate current cache and all baskets need to be reset and cache buffer has to be filled by next cluster of events. Based on current cache replacement policy, the slow performance is reasonable. Philippe pointed out the common use case for ROOT should be mostly sequential reads plus little random reads. I was thinking it would be not helpful if we store decompressed baskets by main thread (when cache miss happens) back to cache. Because for sequential read, they will not be accessed again, neither random reads since the cache will be invalidate and all decompressed baskets in cache should be marked as invalid.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,availability,monitor,monitors,224,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,deployability,monitor,monitors,224,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:43,energy efficiency,current,current,43,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:190,energy efficiency,current,current,190,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,energy efficiency,monitor,monitors,224,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:165,integrability,event,event,165,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:459,integrability,interfac,interface,459,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:565,integrability,event,event,565,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:738,integrability,buffer,buffer,738,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:459,interoperability,interfac,interface,459,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:459,modifiability,interfac,interface,459,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:51,performance,cach,cache,51,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:81,performance,cach,cache,81,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:540,performance,cach,cache,540,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:732,performance,cach,cache,732,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,reliability,monitor,monitors,224,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,safety,monitor,monitors,224,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:69,security,polic,policy,69,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,testability,monitor,monitors,224,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:571,testability,simul,simulation,571,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:425,usability,cancel,cancel,425,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:514,usability,cancel,cancel,514,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:655,usability,cancel,cancel,655,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:692,usability,efficien,efficient,692,"@dpiparo @bbockelm ,. Hi Danilo,. Based on current cache replacement policy, the cache will be invalidated (set fIsTransferred to kFALSE) immediately once the first event miss occurs. In my current implementation, each task monitors fIsTransferred and return immediately without doing actual unzipping work. But we still need to create tasks corresponding to the number of baskets. I am wondering if we should add task_group.cancel() function into TTaskGroup interface? In that case, the main thread only needs to cancel all tasks once the cache is invalid. . With event simulation benchmark, I did not see too much difference between task_group wait and cancel. But I guess it could be more efficient once the number of baskets in cache buffer becomes larger.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:91,integrability,Event,Event,91,"Hi all. The implementation of this feature radically changed wrt ~1 month ago. How is the ""Event"" benchmark performing? How is the ""CMSSW candle"" performing?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:108,performance,perform,performing,108,"Hi all. The implementation of this feature radically changed wrt ~1 month ago. How is the ""Event"" benchmark performing? How is the ""CMSSW candle"" performing?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:146,performance,perform,performing,146,"Hi all. The implementation of this feature radically changed wrt ~1 month ago. How is the ""Event"" benchmark performing? How is the ""CMSSW candle"" performing?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:108,usability,perform,performing,108,"Hi all. The implementation of this feature radically changed wrt ~1 month ago. How is the ""Event"" benchmark performing? How is the ""CMSSW candle"" performing?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:146,usability,perform,performing,146,"Hi all. The implementation of this feature radically changed wrt ~1 month ago. How is the ""Event"" benchmark performing? How is the ""CMSSW candle"" performing?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:105,deployability,version,version,105,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11,integrability,Event,Event,11,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:105,integrability,version,version,105,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:105,modifiability,version,version,105,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:60,safety,test,test,60,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:129,safety,test,test,129,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:60,testability,test,test,60,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:129,testability,test,test,129,@dpiparo . Event benchmark is similar as before. I have not test CMSSW yet since I do not know a correct version of file need to test.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:315,energy efficiency,CPU,CPU,315,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:485,energy efficiency,CPU,CPU,485,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:47,integrability,Event,Event,47,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:404,integrability,Event,Event,404,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:131,performance,parallel,parallel,131,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:304,performance,Time,Time,304,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:315,performance,CPU,CPU,315,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:319,performance,Time,Time,319,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:474,performance,Time,Time,474,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:485,performance,CPU,CPU,485,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:489,performance,Time,Time,489,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:40,safety,test,tests,40,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:116,safety,test,tests,116,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:40,testability,test,tests,40,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:116,testability,test,tests,116,"Hi @dpiparo @bbockelm @pcanal . Run two tests: Event benchmark and B2HHH.root (compressed with zlib-6). Both of the tests disabled parallel TTree::GetEntry since receive_and_steal function from tbb takes ridiculous long in total runtime. B2HHH.root (25 branches and 8556118 entries):. | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 12.42 | 12.42 |. | IMT | 8,12 | 13.93 |. Event benchmark (56 branches and 10000 entries): . | Unzipping | Real Time (s) | CPU Time (s) |. | --- | --- | --- |. | Serial | 8.03 | 8.02 |. | IMT | 5.14 | 9.00 |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17,energy efficiency,current,current,17,"Hi,. What is the current status? Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:25,usability,statu,status,25,"Hi,. What is the current status? Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:426,energy efficiency,current,current,426,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:312,integrability,Sub,Subject,312,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:360,integrability,interfac,interface,360,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:360,interoperability,interfac,interface,360,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:360,modifiability,interfac,interface,360,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:390,performance,parallel,parallel,390,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:70,safety,test,test,70,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:699,security,auth,auth,699,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:70,testability,test,test,70,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:434,usability,statu,status,434,"Hi，. This PR should be able to work. Let me know if there is any more test I should do? Zhe. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Friday, December 15, 2017 11:58:35 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Hi,. What is the current status? Thanks,. Philippe. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352041416>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv-BHdUVdXZimUdINFb9yBtGjbgbpks5tApcrgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:77,deployability,updat,update,77,github claims there is now a conflict in TTree. Can you rebase on master and update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29,interoperability,conflict,conflict,29,github claims there is now a conflict in TTree. Can you rebase on master and update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:77,safety,updat,update,77,github claims there is now a conflict in TTree. Can you rebase on master and update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:77,security,updat,update,77,github claims there is now a conflict in TTree. Can you rebase on master and update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:419,deployability,updat,update,419,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:245,integrability,Sub,Subject,245,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:293,integrability,interfac,interface,293,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:293,interoperability,interfac,interface,293,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:371,interoperability,conflict,conflict,371,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:293,modifiability,interfac,interface,293,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:323,performance,parallel,parallel,323,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:419,safety,updat,update,419,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:419,security,updat,update,419,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:676,security,auth,auth,676,"Sure. I will look at it. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Philippe Canal <notifications@github.com>. Sent: Saturday, December 16, 2017 4:33:34 AM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). github claims there is now a conflict in TTree. Can you rebase on master and update the branch? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-352105016>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlv2SlkSXAPbNMZplkfYbezPn-qxX4ks5tAteegaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:38,deployability,updat,updated,38,"@pcanal @bbockelm ,. This PR has been updated to the upstream. Zhe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:38,safety,updat,updated,38,"@pcanal @bbockelm ,. This PR has been updated to the upstream. Zhe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:38,security,updat,updated,38,"@pcanal @bbockelm ,. This PR has been updated to the upstream. Zhe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:109,availability,failur,failures,109,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:54,deployability,build,build,54,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:109,deployability,fail,failures,109,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:109,performance,failur,failures,109,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:109,reliability,fail,failures,109,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:82,safety,permiss,permission,82,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:75,security,access,access,75,"@pcanal Unfortunately, I can't see what output of the build. I do not have access permission. What are those failures about?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1776,availability,operat,operator,1776,"Guard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1935,availability,operat,operator,1935,"1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2128,availability,operat,operator,2128,"a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_p",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:6661,availability,operat,operator,6661,"Guard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:6820,availability,operat,operator,6820,"1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::bl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:7014,availability,operat,operator,7014,"30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_p",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11402,availability,operat,operator,11402,"rd (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11561,availability,operat,operator,11561,"6016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11754,availability,operat,operator,11754,"0, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_p",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15904,availability,error,error,15904,"0289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16978,availability,operat,operator,16978,"loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17138,availability,operat,operator,17138,"ized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17331,availability,operat,operator,17331,"s=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_p",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23755,availability,error,error,23755,"/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24829,availability,operat,operator,24829,"loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24989,availability,operat,operator,24989,"ized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:25182,availability,operat,operator,25182,"s=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_p",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:279,deployability,stack,stack,279,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:414,deployability,stack,stack,414,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:843,deployability,build,buildimt,843,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2228,deployability,build,buildimt,2228,"src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not fo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2544,deployability,build,buildimt,2544,"zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:4462,deployability,build,buildimt,4462,"rtition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab2fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f16176f2700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 3 (Thread 0x7f1617af3700 (LWP 30316)):. #0 __lll_lock_wait () at ../",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:5728,deployability,build,buildimt,5728,"dc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f16176f2700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 3 (Thread 0x7f1617af3700 (LWP 30316)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tre",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:7114,deployability,build,buildimt,7114,"rc/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:7430,deployability,build,buildimt,7430,"he/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:8131,deployability,build,buildimt,8131,"parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:9200,deployability,build,buildimt,9200,"rtition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab3fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fd00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617af3700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 2 (Thread 0x7f1617ef4700 (LWP 30315)):. #0 __lll_lock_wait () at ../",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:10466,deployability,build,buildimt,10466,"dc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fd00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617af3700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 2 (Thread 0x7f1617ef4700 (LWP 30315)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11854,deployability,build,buildimt,11854,"rc/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:12170,deployability,build,buildimt,12170,"zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:12871,deployability,build,buildimt,12871,"parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:13940,deployability,build,buildimt,13940,"rtition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab37e00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __G",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15327,deployability,Stack,StackTrace,15327,"4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17431,deployability,build,buildimt,17431,"ree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17747,deployability,build,buildimt,17747,"/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:18448,deployability,build,buildimt,18448,"parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19517,deployability,build,buildimt,19517,"rtition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #21 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab46600, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #22 0x00007f161adc5450 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::func",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:20843,deployability,build,buildimt,20843,"_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21270,deployability,build,buildimt,21270,"unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21621,deployability,build,buildimt,21621,"int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TTh",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22266,deployability,build,buildimt,22266,"buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22763,deployability,build,buildimt,22763,"nt)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Canno",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23272,deployability,stack,stack,23272,"include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:25282,deployability,build,buildimt,25282,"ree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:25598,deployability,build,buildimt,25598,"/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:26299,deployability,build,buildimt,26299,"parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:27368,deployability,build,buildimt,27368,"rtition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #21 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab46600, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #22 0x00007f161adc5450 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::func",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:28694,deployability,build,buildimt,28694,"_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29121,deployability,build,buildimt,29121,"unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29472,deployability,build,buildimt,29472,"int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TTh",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30117,deployability,build,buildimt,30117,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30614,deployability,build,buildimt,30614,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1666,energy efficiency,optim,optimized,1666,"_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::ada",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1985,energy efficiency,optim,optimized,1985,"16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:4659,energy efficiency,optim,optimized,4659,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab2fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f16176f2700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 3 (Thread 0x7f1617af3700 (LWP 30316)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLoc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:5164,energy efficiency,optim,optimized,5164,"igned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab2fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f16176f2700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 3 (Thread 0x7f1617af3700 (LWP 30316)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:6551,energy efficiency,optim,optimized,6551,"_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::ad",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:6871,energy efficiency,optim,optimized,6871,"617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:8102,energy efficiency,optim,optimized,8102,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:9397,energy efficiency,optim,optimized,9397,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab3fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fd00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617af3700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 2 (Thread 0x7f1617ef4700 (LWP 30315)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLoc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:9902,energy efficiency,optim,optimized,9902,"igned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab3fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fd00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617af3700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 2 (Thread 0x7f1617ef4700 (LWP 30315)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11292,energy efficiency,optim,optimized,11292,"tex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::ada",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11611,energy efficiency,optim,optimized,11611,"17eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:12842,energy efficiency,optim,optimized,12842,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:14137,energy efficiency,optim,optimized,14137,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab37e00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:14642,energy efficiency,optim,optimized,14642,"igned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab37e00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/mul",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15121,energy efficiency,optim,optimized,15121,".., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15225,energy efficiency,optim,optimized,15225,"nal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/r",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15275,energy efficiency,core,core,15275,") at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15373,energy efficiency,core,core,15373,"x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15529,energy efficiency,core,core,15529,"tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15737,energy efficiency,optim,optimized,15737,"=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16137,energy efficiency,optim,optimized,16137,"/sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::oper",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16158,energy efficiency,optim,optimized,16158,".c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16179,energy efficiency,optim,optimized,16179,"2696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16200,energy efficiency,optim,optimized,16200,"em::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16867,energy efficiency,optim,optimized,16867,"=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17188,energy efficiency,optim,optimized,17188,", loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:18419,energy efficiency,optim,optimized,18419,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19714,energy efficiency,optim,optimized,19714,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #21 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab46600, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #22 0x00007f161adc5450 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21560,energy efficiency,optim,optimized,21560,"b::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21956,energy efficiency,optim,optimized,21956,"l_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //==========",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21999,energy efficiency,core,core,21999,"int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //==================================================",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22228,energy efficiency,optim,optimized,22228,"ge=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22492,energy efficiency,optim,optimized,22492,"ed int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/mu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22553,energy efficiency,core,core,22553,"ast=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22703,energy efficiency,optim,optimized,22703,"allel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBuffer",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23588,energy efficiency,optim,optimized,23588," 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23988,energy efficiency,optim,optimized,23988,"=================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::oper",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24009,energy efficiency,optim,optimized,24009,"e lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24030,energy efficiency,optim,optimized,24030,"int at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24051,energy efficiency,optim,optimized,24051,"he crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24718,energy efficiency,optim,optimized,24718,"=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:25039,energy efficiency,optim,optimized,25039,", loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:26270,energy efficiency,optim,optimized,26270,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:27565,energy efficiency,optim,optimized,27565,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #21 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab46600, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #22 0x00007f161adc5450 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29411,energy efficiency,optim,optimized,29411,"b::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29807,energy efficiency,optim,optimized,29807,"l_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //==========",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29850,energy efficiency,core,core,29850,"int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //==================================================",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30079,energy efficiency,optim,optimized,30079,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30343,energy efficiency,optim,optimized,30343,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30404,energy efficiency,core,core,30404,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30554,energy efficiency,optim,optimized,30554,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23203,integrability,sub,submit,23203,"(f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:119,performance,memor,memory,119,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1666,performance,optimiz,optimized,1666,"_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::ada",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1985,performance,optimiz,optimized,1985,"16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab3bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:4659,performance,optimiz,optimized,4659,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab2fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f16176f2700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 3 (Thread 0x7f1617af3700 (LWP 30316)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLoc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:5164,performance,optimiz,optimized,5164,"igned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab3bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab2fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f16176f2700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 3 (Thread 0x7f1617af3700 (LWP 30316)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:6551,performance,optimiz,optimized,6551,"_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=1235260, len=1248359, loc=. 0x7f1617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::ad",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:6871,performance,optimiz,optimized,6871,"617aee584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617aee620, pos=1235260, len=1248359, free=0x7f1617aee61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f16080008f0, pos=1235260, len=1248359, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f884b0, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f884b0, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=13, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4ba58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:8102,performance,optimiz,optimized,8102,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:9397,performance,optimiz,optimized,9397,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab3fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fd00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617af3700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 2 (Thread 0x7f1617ef4700 (LWP 30315)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLoc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:9902,performance,optimiz,optimized,9902,"igned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4ba40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab3fe00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fd00) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617af3700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 2 (Thread 0x7f1617ef4700 (LWP 30315)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11292,performance,optimiz,optimized,11292,"tex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=19528010, len=1132885, loc=. 0x7f1617eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::ada",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11611,performance,optimiz,optimized,11611,"17eef584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f1617eef620, pos=19528010, len=1132885, free=0x7f1617eef61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f1610000ac0, pos=19528010, len=1132885, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f99770, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f99770, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=6, this=<optimized out>) at /usr/include/c++/5/functional:2267. #10 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4b858) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:12842,performance,optimiz,optimized,12842,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #11 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #12 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #13 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:14137,performance,optimiz,optimized,14137,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab37e00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:14642,performance,optimiz,optimized,14642,"igned int)>, unsigned int>, tbb::auto_partitioner const>'. #14 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4b840) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #15 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab37e00, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/mul",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15121,performance,optimiz,optimized,15121,".., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #16 0x00007f161adc1522 in tbb::internal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15225,performance,optimiz,optimized,15225,"nal::arena::process (this=0x7f161ab4ed00, s=...) at ../../src/tbb/arena.cpp:159. #17 0x00007f161adbffa4 in tbb::internal::market::process (this=0x7f161ab57e80, j=...) at ../../src/tbb/market.cpp:677. #18 0x00007f161adbbbb6 in tbb::internal::rml::private_worker::run (this=0x7f161ab4fc80) at ../../src/tbb/private_server.cpp:271. #19 0x00007f161adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/r",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15737,performance,optimiz,optimized,15737,"=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15904,performance,error,error,15904,"0289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15925,performance,memor,memory,15925,"6258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16137,performance,optimiz,optimized,16137,"/sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::oper",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16158,performance,optimiz,optimized,16158,".c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16179,performance,optimiz,optimized,16179,"2696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16200,performance,optimiz,optimized,16200,"em::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:16867,performance,optimiz,optimized,16867,"=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:17188,performance,optimiz,optimized,17188,", loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:18419,performance,optimiz,optimized,18419,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19714,performance,optimiz,optimized,19714,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #21 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab46600, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #22 0x00007f161adc5450 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21560,performance,optimiz,optimized,21560,"b::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:21956,performance,optimiz,optimized,21956,"l_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //==========",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22228,performance,optimiz,optimized,22228,"ge=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22334,performance,Parallel,ParallelFor,22334,"_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything els",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22492,performance,optimiz,optimized,22492,"ed int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/mu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:22703,performance,optimiz,optimized,22703,"allel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBuffer",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23588,performance,optimiz,optimized,23588," 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23755,performance,error,error,23755,"/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23776,performance,memor,memory,23776,"/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23988,performance,optimiz,optimized,23988,"=================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::oper",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24009,performance,optimiz,optimized,24009,"e lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24030,performance,optimiz,optimized,24030,"int at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24051,performance,optimiz,optimized,24051,"he crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24718,performance,optimiz,optimized,24718,"=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:25039,performance,optimiz,optimized,25039,", loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #14 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #15 0x00007f161afe60b3 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=0, this=<optimized out>) at /usr/include/c++/5/functional:2267. #16 tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>::operator()(tbb::blocked_range<unsigned int> const&) const (r=..., this=0x7f161ab4bd58) at /home/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::interna",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:26270,performance,optimiz,optimized,26270,"me/zhe/buildimt/include/tbb/parallel_for.h:162. #17 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run_body(tbb::blocked_range<unsigned int>&) (r=..., this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:102. #18 tbb::interface9::internal::balancing_partition_type<tbb::interface9::internal::adaptive_mode<tbb::interface9::internal::auto_partition_type> >::work_balance<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=..., this=<optimized out>) at /home/zhe/buildimt/include/tbb/partitioner.h:429. #19 tbb::interface9::internal::partition_type_base<tbb::interface9::internal::auto_partition_type>::execute<tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:27565,performance,optimiz,optimized,27565,"(unsigned int)>, unsigned int>, tbb::auto_partitioner const>, tbb::blocked_range<unsigned int> >(tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>&, tbb::blocked_range<unsigned int>&) (range=..., start=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #20 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::execute() (this=0x7f161ab4bd40) at /home/zhe/buildimt/include/tbb/parallel_for.h:127. #21 0x00007f161adc854b in tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all (this=0x7f161ab46600, parent=..., child=<optimized out>) at ../../src/tbb/custom_scheduler.h:501. #22 0x00007f161adc5450 in tbb::internal::generic_scheduler::local_spawn_root_and_wait (this=0x7f161ab46600, first=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #23 0x00007f161afe48b2 in tbb::task::spawn_root_and_wait (root=warning: RTTI symbol not found for class 'tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>'. #24 tbb::interface9::internal::start_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int>, tbb::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29411,performance,optimiz,optimized,29411,"b::auto_partitioner const>::run(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:90. #25 tbb::parallel_for<tbb::blocked_range<unsigned int>, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:29807,performance,optimiz,optimized,29807,"l_for_body<std::function<void (unsigned int)>, unsigned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //==========",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30079,performance,optimiz,optimized,30079,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30185,performance,Parallel,ParallelFor,30185,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30343,performance,optimiz,optimized,30343,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:30554,performance,optimiz,optimized,30554,"igned int> >(tbb::blocked_range<unsigned int> const&, tbb::internal::parallel_for_body<std::function<void (unsigned int)>, unsigned int> const&, tbb::auto_partitioner const&) (partitioner=..., body=<synthetic pointer>, range=<synthetic pointer>) at /home/zhe/buildimt/include/tbb/parallel_for.h:200. #26 tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (first=0, last=<optimized out>, step=1, f=..., partitioner=...) at /home/zhe/buildimt/include/tbb/parallel_for.h:268. #27 0x00007f161afe4a7d in tbb::strict_ppl::parallel_for_impl<unsigned int, std::function<void (unsigned int)>, tbb::auto_partitioner const>(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&, tbb::auto_partitioner const&) (partitioner=..., f=..., step=1, last=<optimized out>, first=0) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:92. #28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15904,safety,error,error,15904,"0289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23755,safety,error,error,23755,"/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15569,security,sign,signal,15569,"61adbbe09 in tbb::internal::rml::private_worker::thread_routine (arg=<optimized out>) at ../../src/tbb/private_server.cpp:224. #20 0x00007f1624f3c6ba in start_thread (arg=0x7f1617ef4700) at pthread_create.c:333. #21 0x00007f16258e741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109. Thread 1 (Thread 0x7f1626ed7a40 (LWP 30289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15918,security,access,access,15918,"00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23769,security,access,access,23769,"include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:285,testability,trace,trace,285,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:420,testability,trace,trace,420,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23278,testability,trace,trace,23278,"e/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:119,usability,memor,memory,119,"@pcanal @bbockelm If I turn on TBB both for TTree::GetEntry() and TTreeCacheUnzip, the system will crush as due to the memory unalignment read. I do not know why this happens, but if I only turn on TBB for either TTree::GetEntry or TTreeCacheUnzip, it won't happen. . I post the stack trace from gdb as follows:. //===========================================================. There was a crash. This is the entire stack trace of all threads:. //===========================================================. Thread 4 (Thread 0x7f16176f2700 (LWP 30317)):. #0 __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135. #1 0x00007f1624f3ee42 in __GI___pthread_mutex_lock (mutex=0x2e995b0) at ../nptl/pthread_mutex_lock.c:115. #2 0x00007f161a717930 in TLockGuard::TLockGuard (mutex=0x2e9b6e0, this=<synthetic pointer>) at /home/zhe/buildimt/include/TVirtualMutex.h:85. #3 TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=0x7f1616016010 """", pos=18817671, len=647382, loc=. 0x7f16176ed584: -1) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:978. #4 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7f16176ed620, pos=18817671, len=647382, free=0x7f16176ed61c) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #5 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x7f160c0008f0, pos=18817671, len=647382, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #6 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f97910, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #7 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f97910, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1285. #8 0x00007f161a6c6607 in TTree::<lambda()>::operator()(void) const (__closure=0x7ffdc1fce730) at /home/zhe/root/tree/tree/src/TTree.cxx:5478. #9 0x00007f161afe63a6 in std::function<void (unsigned int)>::operator()(unsigned int) const (__args#0=9, this=<optimized out>)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15904,usability,error,error,15904,"0289)):. #0 0x00007f16258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15925,usability,memor,memory,15925,"6258ac0cb in __GI___waitpid (pid=30320, stat_loc=stat_loc. entry=0x7ffdc1fcb5c0, options=options. entry=0) at ../sysdeps/unix/sysv/linux/waitpid.c:29. #1 0x00007f1625824fbb in do_system (line=<optimized out>) at ../sysdeps/posix/system.c:148. #2 0x00007f162696e21d in TUnixSystem::Exec (shellcmd=<optimized out>, this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2118. #3 TUnixSystem::StackTrace (this=0x15da570) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:2412. #4 0x00007f162697085c in TUnixSystem::DispatchSignals (this=0x15da570, sig=kSigSegmentationViolation) at /home/zhe/root/core/unix/src/TUnixSystem.cxx:3643. #5 <signal handler called>. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23034,usability,hint,hint,23034,"#28 tbb::strict_ppl::parallel_for<unsigned int, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23078,usability,help,help,23078,"nt, std::function<void (unsigned int)> >(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (f=..., step=1, last=<optimized out>, first=0) at /home/zhe/buildimt/include/tbb/parallel_for.h:275. #29 ROOT::TThreadExecutor::ParallelFor(unsigned int, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23354,usability,help,help,23354,"nt, unsigned int, unsigned int, std::function<void (unsigned int)> const&) (this=this. entry=0x7ffdc1fce720, start=start. entry=0, end=<optimized out>, step=step. entry=1, f=...) at /home/zhe/root/core/imt/src/TThreadExecutor.cxx:91. #30 0x00007f161a6cb094 in ROOT::TThreadExecutor::Foreach<TTree::GetEntry(Long64_t, Int_t)::<lambda()> > (nTimes=<optimized out>, func=..., this=0x7ffdc1fce720) at /home/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::Re",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23755,usability,error,error,23755,"/zhe/buildimt/include/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:23776,usability,memor,memory,23776,"/ROOT/TThreadExecutor.hxx:115. #31 TTree::GetEntry (this=0x2c85d30, entry=0, getall=0) at /home/zhe/root/tree/tree/src/TTree.cxx:5489. #32 0x00000000004012fd in main (). //===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum http://root.cern.ch/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at http://root.cern.ch/bugs. Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. //===========================================================. #6 __memcpy_sse2_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-sse2-unaligned.S:37. #7 0x00007f1626206eb4 in memcpy (__len=1234974, __src=<optimized out>, __dest=0x7f1616858010) at /usr/include/x86_64-linux-gnu/bits/string3.h:53. #8 TFileCacheRead::ReadBufferExtNormal (this=0x2e97a30, buf=0x7f1616858010 <error: Cannot access memory at address 0x7f1616858010>, pos=286, len=1234974, loc=. 0x7ffdc1fcdf44: 0) at /home/zhe/root/io/io/src/TFileCacheRead.cxx:531. #9 0x00007f161a71794a in TTreeCacheUnzip::ReadBufferExt (this=0x2e97a30, buf=<optimized out>, pos=<optimized out>, len=<optimized out>, loc=<optimized out>) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:979. #10 0x00007f161a716b3c in TTreeCacheUnzip::GetUnzipBuffer (this=0x2e97a30, buf=0x7ffdc1fcdfe0, pos=286, len=1234974, free=0x7ffdc1fcdfdc) at /home/zhe/root/tree/tree/src/TTreeCacheUnzip.cxx:810. #11 0x00007f161a6a7d97 in TBasket::ReadBasketBuffers (this=this. entry=0x2e9b770, pos=286, len=1234974, file=file. entry=0x1e41b90) at /home/zhe/root/tree/tree/src/TBasket.cxx:474. #12 0x00007f161a6b22d0 in TBranch::GetBasket (this=this. entry=0x2f7f180, basketnumber=0) at /home/zhe/root/tree/tree/src/TBranch.cxx:1159. #13 0x00007f161a6b29db in TBranch::GetEntry (this=0x2f7f180, entry=0, getall=<optimized out>) at /home/zhe/root/tree/tree/src/TBranch.cxx:1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:37,availability,failur,failures,37,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:37,deployability,fail,failures,37,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:356,deployability,Build,Build,356,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:362,deployability,fail,failed,362,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:458,deployability,build,build,458,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:480,deployability,Fail,Failing,480,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:624,deployability,build,build,624,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:843,deployability,build,build,843,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1048,deployability,build,build,1048,"Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this becau",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1250,deployability,build,build,1250,"tion. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubsc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1457,deployability,build,build,1457,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1693,deployability,build,build,1693,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1929,deployability,build,build,1929,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:259,integrability,Sub,Subject,259,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:307,integrability,interfac,interface,307,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:307,interoperability,interfac,interface,307,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:307,modifiability,interfac,interface,307,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:37,performance,failur,failures,37,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:337,performance,parallel,parallel,337,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:37,reliability,fail,failures,37,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:362,reliability,fail,failed,362,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:480,reliability,Fail,Failing,480,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:488,safety,test,tests,488,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:636,safety,test,testReport,636,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:855,safety,test,testReport,855,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1060,safety,test,testReport,1060,"S<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1262,safety,test,testReport,1262," Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1469,safety,test,testReport,1469,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1705,safety,test,testReport,1705,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1941,safety,test,testReport,1941,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2258,security,auth,auth,2258,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:488,testability,test,tests,488,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:636,testability,test,testReport,636,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:855,testability,test,testReport,855,"Is there a way for me to look at the failures? Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1060,testability,test,testReport,1060,"S<https://aka.ms/o0ukef>. ________________________________. From: phsft-bot <notifications@github.com>. Sent: Friday, February 2, 2018 5:55:48 PM. To: root-project/root. Cc: Zhe Zhang; Mention. Subject: Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1262,testability,test,testReport,1262," Re: [root-project/root] Use TTaskGroup interface to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1469,testability,test,testReport,1469,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1705,testability,test,testReport,1705,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1941,testability,test,testReport,1941,"to unzip baskets in parallel. (#1010). Build failed on centos7/gcc49. See console output<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/console>. Failing tests:. * projectroot.roottest.cling.typedef.roottest_cling_typedef_assertFuncArray<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling/typedef/roottest_cling_typedef_assertFuncArray/>. * projectroot.roottest.python.basic.roottest_python_basic_overload<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/>. * projectroot.roottest.python.cling.roottest_python_cling_api<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/>. * projectroot.roottest.python.basic.roottest_python_basic_basic<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/>. * projectroot.roottest.python.basic.roottest_python_basic_operator<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_operator/>. * projectroot.roottest.cling.template.separateDict.roottest_cling_template_separateDict_make<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.cling.template/separateDict/roottest_cling_template_separateDict_make/>. * projectroot.roottest.python.basic.roottest_python_basic_datatype<https://epsft-jenkins.cern.ch/job/root-pullrequests-build/16202/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/>. —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/pull/1010#issuecomment-362744985>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AFNlvxALIqMBvmS69P4RlV2saj54dKDWks5tQ6CEgaJpZM4PbhS5>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:63,availability,failur,failures,63,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24,deployability,fail,failed,24,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:63,deployability,fail,failures,63,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:120,deployability,fail,failed,120,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:63,performance,failur,failures,63,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:92,performance,Time,Time,92,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:288,performance,Time,Time,288,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:24,reliability,fail,failed,24,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:63,reliability,fail,failures,63,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:120,reliability,fail,failed,120,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:31,safety,test,test,31,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:127,safety,test,tests,127,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:170,safety,except,except,170,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:342,safety,test,test,342,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:31,testability,test,test,31,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:127,testability,test,tests,127,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:342,testability,test,test,342,"@pcanal @bbockelm . The failed test cases seem to be transient failures that were shown as ""Time Out"". I re-run all the failed tests on my desktop and all of them passed except this one:. [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt]. It is still shown as ""Time Out"" on my desktop. I also tried this particular test with latest upstream root. It can't pass either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19,availability,failur,failure,19,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:174,availability,Error,Error,174,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:193,availability,Operat,Operation,193,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:207,availability,slo,slow,207,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:5,deployability,fail,failed,5,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19,deployability,fail,failure,19,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:115,deployability,fail,failed,115,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:180,integrability,messag,message,180,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:292,integrability,sub,submitting,292,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:180,interoperability,messag,message,180,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19,performance,failur,failure,19,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:174,performance,Error,Error,174,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:5,reliability,fail,failed,5,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:19,reliability,fail,failure,19,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:115,reliability,fail,failed,115,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:207,reliability,slo,slow,207,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:0,safety,Test,Test,0,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:40,safety,test,test,40,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:93,safety,test,tests,93,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:109,safety,test,tests,109,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:174,safety,Error,Error,174,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:0,testability,Test,Test,0,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:40,testability,test,test,40,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:93,testability,test,tests,93,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:109,testability,test,tests,109,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:174,usability,Error,Error,174,"Test failed due to failure of uploading test results to cdash, it seems:. ```. 05:58:48 100% tests passed, 0 tests failed out of 1038. ```. Two minutes later:. ```. 06:00:58 Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds. 06:00:58 Problems when submitting via HTTP. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:11,deployability,build,build,11,"@phsft-bot build. (from the Mattermost discussion, it seems there were overnight issues in CVMFS?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1011:11,deployability,build,build,11,@phsft-bot build with flags -Druntime_modules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1011
https://github.com/root-project/root/pull/1012:18,deployability,build,build,18,"@bbockelm @pcanal build seems to be successful, can you look please?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:7,deployability,build,build,7,"I also build it in classical mode with builtin and without builtin lz4, works for me on Ubuntu.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:13,deployability,updat,update,13,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:24,deployability,releas,release,24,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:69,deployability,version,version-,69,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:86,deployability,patch,patch-release-notes,86,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:69,integrability,version,version-,69,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:69,modifiability,version,version-,69,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:13,safety,updat,update,13,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:86,safety,patch,patch-release-notes,86,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:13,security,updat,update,13,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:86,security,patch,patch-release-notes,86,Can you also update the release notes? (at https://root.cern.ch/root-version-v5-34-00-patch-release-notes),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1013:11,deployability,build,build,11,@phsft-bot build just on ubuntu14/native with flags -Dimt=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1013
https://github.com/root-project/root/pull/1016:14,deployability,contain,contain,14,Does llvm 5.0 contain this revision?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:0,reliability,Doe,Does,0,Does llvm 5.0 contain this revision?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:81,deployability,releas,release,81,It is. Hard to send a link to this commit in a branch but the revision number in release 5.0 is obviously much higher than this one.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:18,deployability,modul,module,18,"But it's breaking module builds as soon as the other PRs have landed, so I made a PR for this too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:25,deployability,build,builds,25,"But it's breaking module builds as soon as the other PRs have landed, so I made a PR for this too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:18,modifiability,modul,module,18,"But it's breaking module builds as soon as the other PRs have landed, so I made a PR for this too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:18,safety,modul,module,18,"But it's breaking module builds as soon as the other PRs have landed, so I made a PR for this too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1017:49,deployability,Modul,Modules,49,"Hmm, we should not go through ParseInternal with Modules?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:49,modifiability,Modul,Modules,49,"Hmm, we should not go through ParseInternal with Modules?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:49,safety,Modul,Modules,49,"Hmm, we should not go through ParseInternal with Modules?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:29,integrability,interfac,interface,29,We should not go through the interface setting CodeGenerationForModule.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:29,interoperability,interfac,interface,29,We should not go through the interface setting CodeGenerationForModule.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:29,modifiability,interfac,interface,29,We should not go through the interface setting CodeGenerationForModule.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:66,deployability,modul,module,66,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:73,deployability,depend,dependency,73,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:73,integrability,depend,dependency,73,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:101,integrability,sub,submit,101,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:66,modifiability,modul,module,66,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:73,modifiability,depend,dependency,73,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:66,safety,modul,module,66,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:73,safety,depend,dependency,73,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:73,testability,depend,dependency,73,We decided to merge this PR to move forward in debugging a cyclic module dependency. @Teemperor will submit another PR in resolving the `CodegenForModules` issue as we suggested before.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:18,integrability,sub,submit,18,> @Teemperor will submit another PR in resolving the CodegenForModules issue as we suggested before. You're the best! Thank you!!!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1018:340,availability,replic,replicating,340,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:275,deployability,depend,dependent,275,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:137,energy efficiency,cool,cool,137,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:356,energy efficiency,current,current,356,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:397,energy efficiency,CPU,CPUs,397,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:275,integrability,depend,dependent,275,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:275,modifiability,depend,dependent,275,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:98,performance,time,times,98,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:397,performance,CPU,CPUs,397,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:457,performance,parallel,parallelizing,457,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:191,safety,reme,remember,191,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:275,safety,depend,dependent,275,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:275,testability,depend,dependent,275,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:444,usability,help,helpful,444,"It's a proposal, totally open to discussion. I found myself in need of this piece of code several times and I always thought it would be cool to have it as a single call instead of having to remember those three lines. You can see it a nicer and useful way for writing nCPUs dependent, processor-agnostic code. I would say it's better than replicating the current process of getting the number of CPUs all over the place. This function will be helpful when parallelizing without IMT/tbb, where you may still be in need of knowing the number of threads you can use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:5,safety,reme,remembered,5,Just remembered std::thread::hardware_concurrency. Closing the PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1019:96,availability,slo,slot,96,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:181,deployability,depend,dependency,181,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:181,integrability,depend,dependency,181,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:106,interoperability,heterogen,heterogeneous,106,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:181,modifiability,depend,dependency,181,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:0,reliability,Doe,Does,0,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:96,reliability,slo,slot,96,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:181,safety,depend,dependency,181,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:181,testability,depend,dependency,181,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:199,usability,behavi,behaviours,199,Does fgMaxSlots have to be static? I can't figure out the reason apart from wanting to keep the slot size heterogeneous at any point of the program. I would need it to be local for dependency on IMT behaviours to make sense.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:85,performance,perform,performance,85,"@dpiparo What do we make of this? It needs a refresh, but is this the right approach performance wise?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:85,usability,perform,performance,85,"@dpiparo What do we make of this? It needs a refresh, but is this the right approach performance wise?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:42,usability,close,close,42,"@dpiparo , @xvallspl left it up to you to close this one",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:42,usability,close,close,42,"@dpiparo , @xvallspl left it up to you to close this one",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1023:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:13,performance,disk,disk,13,"Node has the disk full... Please try again later, as disk space is being cleared now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:53,performance,disk,disk,53,"Node has the disk full... Please try again later, as disk space is being cleared now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:73,usability,clear,cleared,73,"Node has the disk full... Please try again later, as disk space is being cleared now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:11,deployability,build,build,11,@phsft-bot build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:42,energy efficiency,green,green,42,"Alright the bot is not helping, travis is green, I tested locally and everything works as expected, and the changes are small. I will go ahead and merge and keep a close eye on the incrementals for any issue that might arise on platforms different than my own.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:228,interoperability,platform,platforms,228,"Alright the bot is not helping, travis is green, I tested locally and everything works as expected, and the changes are small. I will go ahead and merge and keep a close eye on the incrementals for any issue that might arise on platforms different than my own.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:51,safety,test,tested,51,"Alright the bot is not helping, travis is green, I tested locally and everything works as expected, and the changes are small. I will go ahead and merge and keep a close eye on the incrementals for any issue that might arise on platforms different than my own.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:51,testability,test,tested,51,"Alright the bot is not helping, travis is green, I tested locally and everything works as expected, and the changes are small. I will go ahead and merge and keep a close eye on the incrementals for any issue that might arise on platforms different than my own.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:23,usability,help,helping,23,"Alright the bot is not helping, travis is green, I tested locally and everything works as expected, and the changes are small. I will go ahead and merge and keep a close eye on the incrementals for any issue that might arise on platforms different than my own.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:164,usability,close,close,164,"Alright the bot is not helping, travis is green, I tested locally and everything works as expected, and the changes are small. I will go ahead and merge and keep a close eye on the incrementals for any issue that might arise on platforms different than my own.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1025:54,deployability,build,build,54,"Sorry, I had to take the Mac node offline. @phsft-bot build on mac1012/native but somewhere else.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1026:37,deployability,contain,contains,37,This PR is superseded by #1029 which contains this single commit as part of a bugfix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1026
https://github.com/root-project/root/pull/1028:39,integrability,messag,message,39,"Added the PR description to the commit message, but the test passed. Merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:39,interoperability,messag,message,39,"Added the PR description to the commit message, but the test passed. Merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:56,safety,test,test,56,"Added the PR description to the commit message, but the test passed. Merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:56,testability,test,test,56,"Added the PR description to the commit message, but the test passed. Merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1031:11,deployability,build,build,11,@phsft-bot build please.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1033:4,deployability,fail,failing,4,The failing test is a glitch unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1033:4,reliability,fail,failing,4,The failing test is a glitch unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1033:12,safety,test,test,12,The failing test is a glitch unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1033:12,testability,test,test,12,The failing test is a glitch unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1033:61,deployability,patch,patches,61,"@dpiparo and @Axel-Naumann , can we get this in root 6-10-00-patches branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1033:61,safety,patch,patches,61,"@dpiparo and @Axel-Naumann , can we get this in root 6-10-00-patches branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1033:61,security,patch,patches,61,"@dpiparo and @Axel-Naumann , can we get this in root 6-10-00-patches branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1034:61,deployability,patch,patch,61,Won't fix travis because this just reverts an existing clang patch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:61,safety,patch,patch,61,Won't fix travis because this just reverts an existing clang patch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:61,security,patch,patch,61,Won't fix travis because this just reverts an existing clang patch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:11,deployability,build,build,11,"@phsft-bot build! @Teemperor sure, no problem!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1036:0,energy efficiency,Current,Currently,0,"Currently trying to find a good template for a rootcling test, then I can add a test in roottest for this. Until then DNM please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:57,safety,test,test,57,"Currently trying to find a good template for a rootcling test, then I can add a test in roottest for this. Until then DNM please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:80,safety,test,test,80,"Currently trying to find a good template for a rootcling test, then I can add a test in roottest for this. Until then DNM please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:57,testability,test,test,57,"Currently trying to find a good template for a rootcling test, then I can add a test in roottest for this. Until then DNM please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:80,testability,test,test,80,"Currently trying to find a good template for a rootcling test, then I can add a test in roottest for this. Until then DNM please.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:128,deployability,Modul,Modules,128,@Axel-Naumann The first assert should be safe because we directly dereference the pointer one line later. We can also add a `if(Modules) {}` around the other code to double-check.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:128,modifiability,Modul,Modules,128,@Axel-Naumann The first assert should be safe because we directly dereference the pointer one line later. We can also add a `if(Modules) {}` around the other code to double-check.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:41,safety,safe,safe,41,@Axel-Naumann The first assert should be safe because we directly dereference the pointer one line later. We can also add a `if(Modules) {}` around the other code to double-check.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:128,safety,Modul,Modules,128,@Axel-Naumann The first assert should be safe because we directly dereference the pointer one line later. We can also add a `if(Modules) {}` around the other code to double-check.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:24,testability,assert,assert,24,@Axel-Naumann The first assert should be safe because we directly dereference the pointer one line later. We can also add a `if(Modules) {}` around the other code to double-check.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:11,safety,test,test,11,Will add a test for this once root compiles and we can actually run rootcling.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:11,testability,test,test,11,Will add a test for this once root compiles and we can actually run rootcling.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1037:5,energy efficiency,Current,Currently,5,"N.B. Currently the mechanism is only ""active"" for non-jitted `Histo[1,2,3]D` actions. For now TDF either throws an exception or prints a warning if users register a callback with the results of other actions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:115,safety,except,exception,115,"N.B. Currently the mechanism is only ""active"" for non-jitted `Histo[1,2,3]D` actions. For now TDF either throws an exception or prints a warning if users register a callback with the results of other actions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:148,usability,user,users,148,"N.B. Currently the mechanism is only ""active"" for non-jitted `Histo[1,2,3]D` actions. For now TDF either throws an exception or prints a warning if users register a callback with the results of other actions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:375,energy efficiency,current,current,375,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:42,performance,concurren,concurrently,42,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:95,performance,multi-thread,multi-threading,95,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:198,reliability,doe,does,198,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:186,safety,safe,safe,186,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:163,usability,user,user,163,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:275,usability,clear,clear,275,"> but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled. As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Also, in the blur, in it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. The case 'global partial result' requires merging of the thread's histograms in the case there is one histo copy per thread/worker.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:537,deployability,depend,depends,537,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:411,energy efficiency,current,current,411,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:537,integrability,depend,depends,537,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:537,modifiability,depend,depends,537,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:285,performance,concurren,concurrently,285,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:76,reliability,doe,does,76,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:601,reliability,pra,practice,601,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:64,safety,safe,safe,64,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:537,safety,depend,depends,537,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:684,security,expos,expose,684,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:537,testability,depend,depends,537,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:41,usability,user,user,41,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:172,usability,user,users,172,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:311,usability,clear,clear,311,"> As far as I can tell this requires the user code to be thread safe, which does not seem to be the case of the example. Yes the example is meant to be single threaded. If users run the analysis on multiple threads they have to make sure the callback can be called by multiple threads concurrently. > it is not clear whether the call back will see the global partial result or the partial result so far on the 'current' thread. No guarantees there: it's going to be a ""partial result"". If it's ""thread-local partial"" or ""global partial"" depends on what each action's `PartialUpdate` method will do in practice. For some kind of actions it might be fine in terms of RAM and runtime to expose the ""global"" partial result, for others it could be an issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1262,availability,slo,slot,1262,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1328,availability,slo,slot,1328,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:706,deployability,Updat,Update,706,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1721,deployability,Updat,Update,1721,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:695,energy efficiency,Draw,Draw,695,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:742,energy efficiency,Draw,Draw,742,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1710,energy efficiency,Draw,Draw,1710,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1772,energy efficiency,Draw,Draw,1772,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:56,performance,parallel,parallelism,56,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:341,performance,content,content,341,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1162,performance,content,content,1162,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1759,performance,parallel,parallel,1759,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1262,reliability,slo,slot,1262,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1328,reliability,slo,slot,1328,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:706,safety,Updat,Update,706,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1721,safety,Updat,Update,1721,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:706,security,Updat,Update,706,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1721,security,Updat,Update,1721,"@pcanal here are full working examples with and without parallelism enabled:. **no IMT**. ```c++. #include <thread>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. // setup a TDF with some content. TDataFrame d(5000);. TRandom r;. auto heavyWork = [&r]() {. for (volatile int i = 0; i < 1000000; ++i) {}. return r.Gaus();. };. auto tdf = d.Define(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""hist"");. h.RegisterCallback(100, [&c](TH1D &hist) {. hist.Draw();. c.Update();. });. // run analysis. h->Draw();. app.Run();. return 0;. }. ```. **IMT**. ```c++. #include <algorithm>. #include <thread>. #include <chrono>. #include ""ROOT/TDataFrame.hxx"". #include ""TApplication.h"". #include ""TCanvas.h"". #include ""TRandom.h"". using namespace ROOT::Experimental;. int main(). {. TApplication app(""app"", nullptr, nullptr);. ROOT::EnableImplicitMT();. const auto nSlots = ROOT::GetImplicitMTPoolSize();. // setup a TDF with some content. TDataFrame d(5000);. std::vector<TRandom> rs(nSlots);. auto heavyWork = [&rs](unsigned int slot) {. for (volatile int i = 0; i < 1000000; ++i) {}. return rs[slot].Gaus();. };. auto tdf = d.DefineSlot(""x"", heavyWork);. // get a histogram and register a callback. auto h = tdf.Histo1D<double>({"""", """", 100, -2., 2.}, ""x"");. TCanvas c(""c"", ""running..."");. const auto mainThreadID = std::this_thread::get_id();. h.RegisterCallback(100, [&c, &mainThreadID](decltype(h)::Value_t &hist) {. if (std::this_thread::get_id() == mainThreadID) {. hist.Draw();. c.Update();. }. });. // run analysis in parallel. h->Draw();. app.Run();. return 0;. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:160,performance,concurren,concurrency,160,"@Axel-Naumann @pcanal @dpiparo . What do you think about changing the behaviour so that only one thread calls the callbacks? So users don't have to worry about concurrency which might be a useless complication. For histograms we wouldn't want to do synchronized partial merges of the thread-local copies anyway, I guess...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:249,performance,synch,synchronized,249,"@Axel-Naumann @pcanal @dpiparo . What do you think about changing the behaviour so that only one thread calls the callbacks? So users don't have to worry about concurrency which might be a useless complication. For histograms we wouldn't want to do synchronized partial merges of the thread-local copies anyway, I guess...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:197,safety,compl,complication,197,"@Axel-Naumann @pcanal @dpiparo . What do you think about changing the behaviour so that only one thread calls the callbacks? So users don't have to worry about concurrency which might be a useless complication. For histograms we wouldn't want to do synchronized partial merges of the thread-local copies anyway, I guess...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:197,security,compl,complication,197,"@Axel-Naumann @pcanal @dpiparo . What do you think about changing the behaviour so that only one thread calls the callbacks? So users don't have to worry about concurrency which might be a useless complication. For histograms we wouldn't want to do synchronized partial merges of the thread-local copies anyway, I guess...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:70,usability,behavi,behaviour,70,"@Axel-Naumann @pcanal @dpiparo . What do you think about changing the behaviour so that only one thread calls the callbacks? So users don't have to worry about concurrency which might be a useless complication. For histograms we wouldn't want to do synchronized partial merges of the thread-local copies anyway, I guess...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:128,usability,user,users,128,"@Axel-Naumann @pcanal @dpiparo . What do you think about changing the behaviour so that only one thread calls the callbacks? So users don't have to worry about concurrency which might be a useless complication. For histograms we wouldn't want to do synchronized partial merges of the thread-local copies anyway, I guess...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:113,deployability,depend,depends,113,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:113,integrability,depend,depends,113,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:113,modifiability,depend,depends,113,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:248,modifiability,scenario,scenario,248,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:113,safety,depend,depends,113,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:113,testability,depend,depends,113,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:269,usability,help,helpful,269,"> No guarantees there: it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:172,integrability,sub,sub,172,"> only one thread calls the callbacks. That's actually the behavior I had expected. I'd even argue that the main thread should register its histograms with ROOT, e.g. in a sub-`TDirectory` of gROOT, e.g. through a function call (`TDF::Publish(""NameOfgROOTSubDir"")`). These histograms should then be the merge target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:235,integrability,Pub,Publish,235,"> only one thread calls the callbacks. That's actually the behavior I had expected. I'd even argue that the main thread should register its histograms with ROOT, e.g. in a sub-`TDirectory` of gROOT, e.g. through a function call (`TDF::Publish(""NameOfgROOTSubDir"")`). These histograms should then be the merge target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:59,usability,behavi,behavior,59,"> only one thread calls the callbacks. That's actually the behavior I had expected. I'd even argue that the main thread should register its histograms with ROOT, e.g. in a sub-`TDirectory` of gROOT, e.g. through a function call (`TDF::Publish(""NameOfgROOTSubDir"")`). These histograms should then be the merge target.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:92,deployability,depend,depends,92,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:92,integrability,depend,depends,92,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:379,integrability,event,events,379,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:447,integrability,sub,subset,447,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:461,integrability,event,events,461,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:774,integrability,event,event,774,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:92,modifiability,depend,depends,92,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:229,modifiability,scenario,scenario,229,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:92,safety,depend,depends,92,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:92,testability,depend,depends,92,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:250,usability,help,helpful,250,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:611,usability,behavi,behavior,611,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:704,usability,behavi,behavior,704,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:824,usability,user,users,824,"> it's going to be a ""partial result"". > If it's ""thread-local partial"" or ""global partial"" depends on what each action's. > I am afraid that this is going to be confusing/hard-to-explain .... On the other hand in some debugging scenario it might be helpful. I would just leave the explanation at: ""you get a partial analysis result (histogram filled with a part of the selected events, counter incremented only up to a certain point, mean over a subset of the events and so forth)"". I think this is enough to enjoy the feature and use it correctly. > only one thread calls the callbacks. > That's actually the behavior I had expected. . Fair enough. If no one has anything against it, I will change the behavior to have only one thread call the callback. @Axel-Naumann the event loop is still blocking so I'm not sure what users could do with the histograms we register with ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:11,integrability,coupl,couple,11,"Throw in a couple of `gSystem->ProcessEvents()`, maybe? :-) No idea whether that's enough to make it usable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:11,modifiability,coupl,couple,11,"Throw in a couple of `gSystem->ProcessEvents()`, maybe? :-) No idea whether that's enough to make it usable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:11,testability,coupl,couple,11,"Throw in a couple of `gSystem->ProcessEvents()`, maybe? :-) No idea whether that's enough to make it usable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:101,usability,usab,usable,101,"Throw in a couple of `gSystem->ProcessEvents()`, maybe? :-) No idea whether that's enough to make it usable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:634,availability,consist,consists,634,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:251,deployability,build,building,251,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:794,energy efficiency,optim,optimised,794,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:894,energy efficiency,measur,measurements,894,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:984,energy efficiency,measur,measurements,984,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:292,integrability,asynchron,asynchronously,292,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:755,interoperability,platform,platform,755,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:292,performance,asynch,asynchronously,292,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1086,performance,time,time,1086,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:942,safety,detect,detector,942,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:942,security,detect,detector,942,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:406,testability,hook,hooks,406,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:935,testability,simpl,simple,935,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:284,usability,user,user,284,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:634,usability,consist,consists,634,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:653,usability,user,users,653,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:678,usability,custom,customise,678,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:935,usability,simpl,simple,935,"As a side note, the feature of ""snapshot merging""/""peeping at results in the making"" is something we had already in the first implementation of TThreadedObject (see https://root.cern/doc/master/mt201__parallelHistoFill_8C.html). This was a rudimental building block, which needed the user to asynchronously invoke a method. I see this functionality as something quite interesting. In general, ""callbacks""/""hooks"" of different sorts are a fundamental piece of data processing frameworks of which TDF is de facto an example. I welcome this feature warmly, also when thinking about the direction we have taken with the datasource, which consists in giving users the possibility to customise the usage of TDF according to their needs - we provide a rocksolid platform to solve their problems in an optimised way. A Crazy (?) example: right now we would be able to:. - Write a datasource that reads measurements coming from an oscilloscope/simple detector. - TDF loops and processes these measurements. - Histograms are produced, among other kind of data, and shown while refreshing in real time. - A file with the data acquired and manipulated is produced",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:15,modifiability,concern,concerned,15,"As far as I am concerned, this is ready to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:15,testability,concern,concerned,15,"As far as I am concerned, this is ready to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:606,availability,slo,slot,606,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:714,availability,Slo,Slot,714,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:777,availability,slo,slot,777,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:803,integrability,event,event,803,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:253,interoperability,specif,specified,253,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:447,interoperability,specif,specified,447,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:682,modifiability,paramet,parameter,682,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:358,performance,concurren,concurrently,358,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:545,performance,concurren,concurrently,545,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:606,reliability,slo,slot,606,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:714,reliability,Slo,Slot,714,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:777,reliability,slo,slot,777,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:93,testability,simpl,simpler,93,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:33,usability,feedback,feedback,33,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:57,usability,behavi,behaviour,57,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:93,usability,simpl,simpler,93,"Thanks everyone for the valuable feedback! I changed the behaviour of the feature to make it simpler to use correctly, and also added one or two perks:. * `OnParameterUpdate` (was `RegisterCallback`) now takes a callable that will be invoked once every specified number of entries on a partial result in _one_ of the worker threads. It will never be invoked concurrently. * `OnParameterUpdateSlot` takes a callable that will be invoked once every specified number of entries on a partial result in each of the worker threads. It will be invoked concurrently, and will also take as argument the ""processing slot"" number the partial result belongs to. * passing `0` as `everyNEvents` parameter to `OnParameterUpdate[Slot]` makes it so that the callback is invoked just once [per slot] before starting the event loop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:294,deployability,Updat,Update,294,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:374,deployability,updat,updates,374,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1084,deployability,Updat,Update,1084,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1458,deployability,contain,contained,1458,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:33,energy efficiency,draw,drawing,33,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:140,energy efficiency,Draw,Draw,140,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:283,energy efficiency,Draw,Draw,283,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:633,energy efficiency,cool,cool,633,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:661,energy efficiency,current,current,661,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:180,integrability,event,events,180,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:212,integrability,event,event,212,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:392,integrability,event,event,392,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:500,integrability,event,event,500,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:844,integrability,event,event,844,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1114,integrability,event,events,1114,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1845,modifiability,extens,extension,1845,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:94,performance,multi-thread,multi-thread,94,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1050,performance,multi-thread,multi-thread,1050,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1812,reliability,doe,does,1812,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:294,safety,Updat,Update,294,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:374,safety,updat,updates,374,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1022,safety,safe,safe,1022,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1084,safety,Updat,Update,1084,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:294,security,Updat,Update,294,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:374,security,updat,updates,374,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1084,security,Updat,Update,1084,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:12,usability,user,users,12,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:329,usability,user,users,329,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:864,usability,user,users,864,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:873,usability,navigat,navigate,873,"@pcanal now users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1027,usability,progress,progress,1027,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1091,usability,progress,progress,1091,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1134,usability,progress,progress,1134,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1207,usability,progress,progress,1207,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1305,usability,progress,progress,1305,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1384,usability,progress,progress,1384,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:1936,usability,help,helper,1936,"ow users can register a drawing of a result histogram in the same way in single- and multi-thread analysis, like this:. ```c++. // Draw partial result on canvas every 500 events. TCanvas c(""c"", ""Running event loop..."");. h.OnPartialResult(100, [&c](TH1D &h_) {. c.cd();. h_.Draw();. c.Update();. });. ```. @Axel-Naumann users can open a `TBrowser` and check result updates while the event loop is running quite easily:. ```c++. // create ""TDFResults"" directory in TBrowser. TBrowser b(""b"", ""event loop peeper"");. TMemFile m(""TDFResults"", ""RECREATE"");. // add partial result to the ""TDFResults"". m.Browse(&b); // it would be cool if we could change the current directory in the TBrowser to `TDFResults` here. h.OnPartialResult(decltype(h)::kOnce, [&m](TH1D &h_) { m.Add(&h_); });. // call ProcessEvents every once in a while during the event loop to allow users to navigate the TBrowser. h.OnPartialResult(50, [](TH1D &hist) { gSystem->ProcessEvents(); });. ```. @peremato here is how one would implement a thread-safe progress bar for a TDF multi-thread analysis. ```c++. // Update progress bar every 100 events. std::string progress;. std::mutex bar_mutex;. c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &c_) {. std::lock_guard<std::mutex> lg(bar_mutex);. progress.push_back('#');. std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;. });. ```. Here are the corresponding self-contained, fully working code examples:. [draw_partial_result.txt](https://github.com/root-project/root/files/1327464/draw_partial_result.txt). [inspect_analysis.txt](https://github.com/root-project/root/files/1327466/inspect_analysis.txt). [progress_bar.txt](https://github.com/root-project/root/files/1327469/progress_bar.txt). (for some reason github does not allow files with `.cpp` extension :man_shrugging: ). For common-enough callbacks one can always imagine to provide helper functions of course. I like this feature a lot. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:4,availability,failur,failure,4,The failure in `test_misc` is fixed by PR #1046 and a similar PR to roottest,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:4,deployability,fail,failure,4,The failure in `test_misc` is fixed by PR #1046 and a similar PR to roottest,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:4,performance,failur,failure,4,The failure in `test_misc` is fixed by PR #1046 and a similar PR to roottest,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:4,reliability,fail,failure,4,The failure in `test_misc` is fixed by PR #1046 and a similar PR to roottest,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:75,energy efficiency,green,green,75,Rebased on master now that #1046 has been merged. Tests are expected to be green now (although more testing of the callback registration has to be added).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:124,interoperability,registr,registration,124,Rebased on master now that #1046 has been merged. Tests are expected to be green now (although more testing of the callback registration has to be added).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:50,safety,Test,Tests,50,Rebased on master now that #1046 has been merged. Tests are expected to be green now (although more testing of the callback registration has to be added).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:100,safety,test,testing,100,Rebased on master now that #1046 has been merged. Tests are expected to be green now (although more testing of the callback registration has to be added).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:50,testability,Test,Tests,50,Rebased on master now that #1046 has been merged. Tests are expected to be green now (although more testing of the callback registration has to be added).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:100,testability,test,testing,100,Rebased on master now that #1046 has been merged. Tests are expected to be green now (although more testing of the callback registration has to be added).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:57,energy efficiency,profil,profiling,57,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:105,energy efficiency,measur,measure,105,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:209,integrability,event,event,209,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:57,performance,profil,profiling,57,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:74,performance,perform,performed,74,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:113,performance,time,time,113,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:119,performance,memor,memory,119,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:127,performance,cach,cache,127,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:163,safety,compl,complete,163,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:163,security,compl,complete,163,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:234,testability,instrument,instrumentation,234,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:74,usability,perform,performed,74,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:119,usability,memor,memory,119,"By the way, the callbacks can also become a way in which profiling can be performed. For example, we can measure time, memory, cache misses or dump something more complete (e.g. an igprof report) *during* the event loop. This kind of instrumentation will be very useful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:139,energy efficiency,green,green,139,Rebased on master to fix conflicts. I will definitely add more multi-thread tests but I think this can be safely merged if jenkins returns green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:25,interoperability,conflict,conflicts,25,Rebased on master to fix conflicts. I will definitely add more multi-thread tests but I think this can be safely merged if jenkins returns green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:63,performance,multi-thread,multi-thread,63,Rebased on master to fix conflicts. I will definitely add more multi-thread tests but I think this can be safely merged if jenkins returns green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:76,safety,test,tests,76,Rebased on master to fix conflicts. I will definitely add more multi-thread tests but I think this can be safely merged if jenkins returns green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:106,safety,safe,safely,106,Rebased on master to fix conflicts. I will definitely add more multi-thread tests but I think this can be safely merged if jenkins returns green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:76,testability,test,tests,76,Rebased on master to fix conflicts. I will definitely add more multi-thread tests but I think this can be safely merged if jenkins returns green.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:41,availability,failur,failures,41,"I'll have to check what is causing these failures on mac, re-adding ""do not merge"" label :sweat:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:41,deployability,fail,failures,41,"I'll have to check what is causing these failures on mac, re-adding ""do not merge"" label :sweat:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:41,performance,failur,failures,41,"I'll have to check what is causing these failures on mac, re-adding ""do not merge"" label :sweat:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:41,reliability,fail,failures,41,"I'll have to check what is causing these failures on mac, re-adding ""do not merge"" label :sweat:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:247,availability,error,error,247,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:420,availability,Failur,Failure,420,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:307,deployability,build,build,307,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:349,deployability,build,build,349,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:420,deployability,Fail,Failure,420,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:539,deployability,FAIL,FAILED,539,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:660,deployability,log,logic,660,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:247,performance,error,error,247,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:420,performance,Failur,Failure,420,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:420,reliability,Fail,Failure,420,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:539,reliability,FAIL,FAILED,539,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:247,safety,error,error,247,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:376,safety,test,test,376,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:660,safety,log,logic,660,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:660,security,log,logic,660,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:376,testability,test,test,376,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:660,testability,log,logic,660,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:247,usability,error,error,247,"Uhm....so this gtest:. ```c++. auto m = tdf.Min<double>(""x"");. double runningMin = std::numeric_limits<double>::max();. m.OnPartialResult(2, [&runningMin](double x) {. runningMin = x;. });. EXPECT_DOUBLE_EQ(runningMin, *m); . ```. results in this error:. ```. [ RUN ] TDFCallbacks.Min. /Volumes/MacintoshHD/build/jenkins/workspace/root-pullrequests-build/root/tree/treeplayer/test/dataframe/dataframe_callbacks.cxx:126: Failure. Expected: runningMin. Which is: 1.7976931348623157e+308. To be equal to: *m. Which is: -3.0919523479251314. [ FAILED ] TDFCallbacks.Min (0 ms). ```. only on mac1012 and only for `Min` and `Max` which have the same kind of callback logic. Do lambda captures work differently on mac? I'm stumped.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1039:10,availability,failur,failures,10,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:10,deployability,fail,failures,10,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:29,deployability,infrastructur,infrastructure,29,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:10,performance,failur,failures,10,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:10,reliability,fail,failures,10,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:5,safety,test,test,5,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:0,testability,Unit,Unit,0,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:5,testability,test,test,5,Unit test failures look like infrastructure issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:7,usability,close,close,7,Can we close this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1040:122,deployability,version,version,122,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:122,integrability,version,version,122,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:92,interoperability,standard,standard,92,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:122,modifiability,version,version,122,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:33,safety,review,review,33,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:248,security,access,access,248,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:33,testability,review,review,33,"Hmm, why can't I reply to Pere's review? I have the impression that CMAKE_CXX_STANDARD is a standard way of selecting c++ version (the other being by CMAKE_CXX_EXTENSIONS). As @amadio pointed out this is a bad approach since I didn't find a way to access the resulting flag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:310,deployability,version,version,310,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:164,integrability,topic,topic,164,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:310,integrability,version,version,310,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:310,modifiability,version,version,310,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:88,performance,parallel,parallelforall,88,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:182,safety,test,test-cu-std-c-,182,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:182,testability,test,test-cu-std-c-,182,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:281,testability,simpl,simply,281,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:28,usability,support,supports,28,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:281,usability,simpl,simply,281,"I don't think nvcc actually supports C++14 before CUDA 9.0. https://devblogs.nvidia.com/parallelforall/cuda-9-features-revealed. https://devtalk.nvidia.com/default/topic/985604/nvcc-test-cu-std-c-11-xcompiler-quot-std-c-14-quot-/?offset=2. So, I believe the easiest thing to do is simply to check for the CUDA version and require 9.0 or later. As for the host compiler, if we use `CMAKE_CXX_STANDARD`, CMake should take care of it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:0,deployability,Updat,Updated,0,Updated according to @amadio's comments.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:0,safety,Updat,Updated,0,Updated according to @amadio's comments.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:0,security,Updat,Updated,0,Updated according to @amadio's comments.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:11,deployability,build,build,11,@phsft-bot build with flags -Dtmva=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1042:38,reliability,pra,pragma,38,I am guessing that the switch from ```pragma class``` to ```pragma namespace``` prevents the autoparsing of TClassEdit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:60,reliability,pra,pragma,60,I am guessing that the switch from ```pragma class``` to ```pragma namespace``` prevents the autoparsing of TClassEdit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:80,safety,prevent,prevents,80,I am guessing that the switch from ```pragma class``` to ```pragma namespace``` prevents the autoparsing of TClassEdit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:80,security,preven,prevents,80,I am guessing that the switch from ```pragma class``` to ```pragma namespace``` prevents the autoparsing of TClassEdit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:188,energy efficiency,load,loaded,188,TClassEdit was selected as class which does not have any effect. A more radical approach would be to remove this completely since the header is in the pch and by definition libCore always loaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:188,performance,load,loaded,188,TClassEdit was selected as class which does not have any effect. A more radical approach would be to remove this completely since the header is in the pch and by definition libCore always loaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:39,reliability,doe,does,39,TClassEdit was selected as class which does not have any effect. A more radical approach would be to remove this completely since the header is in the pch and by definition libCore always loaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:113,safety,compl,completely,113,TClassEdit was selected as class which does not have any effect. A more radical approach would be to remove this completely since the header is in the pch and by definition libCore always loaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:113,security,compl,completely,113,TClassEdit was selected as class which does not have any effect. A more radical approach would be to remove this completely since the header is in the pch and by definition libCore always loaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:139,deployability,fail,fail,139,> TClassEdit was selected as class which does not have any effect. . humm ... so I don't understand why the test works without this PR but fail with this PR ... I am confused ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:41,reliability,doe,does,41,> TClassEdit was selected as class which does not have any effect. . humm ... so I don't understand why the test works without this PR but fail with this PR ... I am confused ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:139,reliability,fail,fail,139,> TClassEdit was selected as class which does not have any effect. . humm ... so I don't understand why the test works without this PR but fail with this PR ... I am confused ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:108,safety,test,test,108,> TClassEdit was selected as class which does not have any effect. . humm ... so I don't understand why the test works without this PR but fail with this PR ... I am confused ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:89,testability,understand,understand,89,> TClassEdit was selected as class which does not have any effect. . humm ... so I don't understand why the test works without this PR but fail with this PR ... I am confused ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:108,testability,test,test,108,> TClassEdit was selected as class which does not have any effect. . humm ... so I don't understand why the test works without this PR but fail with this PR ... I am confused ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:10,deployability,fail,fail,10,"The tests fail because of the mistake above. I am about to make this right and add everything to the PCH, including TClassEdit (as it was done before).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:10,reliability,fail,fail,10,"The tests fail because of the mistake above. I am about to make this right and add everything to the PCH, including TClassEdit (as it was done before).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:4,safety,test,tests,4,"The tests fail because of the mistake above. I am about to make this right and add everything to the PCH, including TClassEdit (as it was done before).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1042:4,testability,test,tests,4,"The tests fail because of the mistake above. I am about to make this right and add everything to the PCH, including TClassEdit (as it was done before).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1042
https://github.com/root-project/root/pull/1043:19,deployability,fail,fails,19,"I see clang format fails, but I just added `.Data()` in three places and stripped a couple of extra white spaces, how can that be wrong?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:84,integrability,coupl,couple,84,"I see clang format fails, but I just added `.Data()` in three places and stripped a couple of extra white spaces, how can that be wrong?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:12,interoperability,format,format,12,"I see clang format fails, but I just added `.Data()` in three places and stripped a couple of extra white spaces, how can that be wrong?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:84,modifiability,coupl,couple,84,"I see clang format fails, but I just added `.Data()` in three places and stripped a couple of extra white spaces, how can that be wrong?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:19,reliability,fail,fails,19,"I see clang format fails, but I just added `.Data()` in three places and stripped a couple of extra white spaces, how can that be wrong?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:84,testability,coupl,couple,84,"I see clang format fails, but I just added `.Data()` in three places and stripped a couple of extra white spaces, how can that be wrong?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:58,interoperability,format,formatting,58,> how can that be wrong? This is because the inforcing of formatting is new and some of the code does not comply.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:97,reliability,doe,does,97,> how can that be wrong? This is because the inforcing of formatting is new and some of the code does not comply.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:106,safety,compl,comply,106,> how can that be wrong? This is because the inforcing of formatting is new and some of the code does not comply.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1043:106,security,compl,comply,106,> how can that be wrong? This is because the inforcing of formatting is new and some of the code does not comply.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1043
https://github.com/root-project/root/pull/1044:124,testability,simpl,simple,124,"I wonder if this shouldn't be a contribution to VDT (https://github.com/dpiparo/vdt , which can be activated in ROOT with a simple ""-DVDT=ON"" and can be easily defaulted to ON given its size starting from 6.12), leaving aside the vectorclass. The implementation looks like autovectorisable with little effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:124,usability,simpl,simple,124,"I wonder if this shouldn't be a contribution to VDT (https://github.com/dpiparo/vdt , which can be activated in ROOT with a simple ""-DVDT=ON"" and can be easily defaulted to ON given its size starting from 6.12), leaving aside the vectorclass. The implementation looks like autovectorisable with little effort.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:41,usability,clear,clear,41,"Hi @pseyfert , thanks. What is needed is clear - we'll figure out the best way to provide the functionality.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:16,performance,content,content,16,A PR similar in content has been merged in VDT https://github.com/dpiparo/vdt/commit/4172388498923c38cae997f581be9c51c84b6ea4,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:118,usability,close,close,118,"Hi, quoting @dpiparo from above ""I wonder if this shouldn't be a contribution to VDT"". Since it's now in vdt we could close here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1046:0,availability,Failur,Failures,0,Failures in `test_misc` are expected and are corrected by [PR 90](https://github.com/root-project/roottest/pull/90) in roottest.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:0,deployability,Fail,Failures,0,Failures in `test_misc` are expected and are corrected by [PR 90](https://github.com/root-project/roottest/pull/90) in roottest.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:0,performance,Failur,Failures,0,Failures in `test_misc` are expected and are corrected by [PR 90](https://github.com/root-project/roottest/pull/90) in roottest.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:0,reliability,Fail,Failures,0,Failures in `test_misc` are expected and are corrected by [PR 90](https://github.com/root-project/roottest/pull/90) in roottest.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:153,performance,time,time,153,"If you merge that without this one, incrementals are going to break :sweat_smile: the two PRs go hand in hand but I think both can be merged at the same time as soon as you want, unless @dpiparo says otherwise",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:87,safety,safe,safely,87,"Ok, I'll leave this to @dpiparo then. I think the changes are simple enough and can be safely merged, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:62,testability,simpl,simple,62,"Ok, I'll leave this to @dpiparo then. I think the changes are simple enough and can be safely merged, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:62,usability,simpl,simple,62,"Ok, I'll leave this to @dpiparo then. I think the changes are simple enough and can be safely merged, though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1048:52,interoperability,format,formatting,52,All changes addressed. Checking again the tests and formatting...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:42,safety,test,tests,42,All changes addressed. Checking again the tests and formatting...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:42,testability,test,tests,42,All changes addressed. Checking again the tests and formatting...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1049:57,safety,test,tests,57,Do not merge because this is obviously mostly to discuss/tests things.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:57,testability,test,tests,57,Do not merge because this is obviously mostly to discuss/tests things.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:11,deployability,build,build,11,@phsft-bot build. and don't crash pls,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:11,deployability,build,build,11,@phsft-bot build just on slc6/gcc62 with flags -Druntime_cxxmodules=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1050:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:11,deployability,build,build,11,@phsft-bot build with flags -Dclingtest=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:125,interoperability,format,format,125,"It looks like we silently broke an autoloading use-case which is outside of the scope of this PR. And, for some reason clang-format picks up the ROOT formatting style instead of the one of cling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:150,interoperability,format,formatting,150,"It looks like we silently broke an autoloading use-case which is outside of the scope of this PR. And, for some reason clang-format picks up the ROOT formatting style instead of the one of cling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1051:17,safety,test,tested,17,"@Axel-Naumann, I tested and it finally works! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1051
https://github.com/root-project/root/pull/1051:17,testability,test,tested,17,"@Axel-Naumann, I tested and it finally works! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1051
https://github.com/root-project/root/pull/1052:47,deployability,patch,patches,47,@amadio Could you backport this PR to v6-10-00-patches? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:47,safety,patch,patches,47,@amadio Could you backport this PR to v6-10-00-patches? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:47,security,patch,patches,47,@amadio Could you backport this PR to v6-10-00-patches? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:84,deployability,releas,release,84,"We should not backport new features, unless an experiment really needs it. The next release is the right place for new features. But @pcanal told me CMS needs it, so please backport whatever is needed and reasonable (esp wrt stability and backward compatibility) to get this into v6-10 - your call!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:248,interoperability,compatib,compatibility,248,"We should not backport new features, unless an experiment really needs it. The next release is the right place for new features. But @pcanal told me CMS needs it, so please backport whatever is needed and reasonable (esp wrt stability and backward compatibility) to get this into v6-10 - your call!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:225,reliability,stabil,stability,225,"We should not backport new features, unless an experiment really needs it. The next release is the right place for new features. But @pcanal told me CMS needs it, so please backport whatever is needed and reasonable (esp wrt stability and backward compatibility) to get this into v6-10 - your call!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1053:99,deployability,build,build,99,I will look at it. @pcanal @bbockelm what is the common way to develop software in MacOS? Should I build ROOT on my laptop? or use some virtual machine with MacOS installed?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:163,deployability,instal,installed,163,I will look at it. @pcanal @bbockelm what is the common way to develop software in MacOS? Should I build ROOT on my laptop? or use some virtual machine with MacOS installed?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:20,deployability,build,build,20,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:54,deployability,version,version,54,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:71,deployability,instal,installed,71,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:54,integrability,version,version,54,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:54,modifiability,version,version,54,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:82,usability,command,command,82,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:95,usability,tool,tools,95,"@zzxuanyuan You can build on MacOS if you have a full version of XCode installed (command line tools only are not enough). If you have CVMFS, you can get some of the externals from there too. Just let me know and I'll show you how to do it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:18,deployability,updat,updates,18,@zzxuanyuan - any updates on getting this to work on OS X?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:18,safety,updat,updates,18,@zzxuanyuan - any updates on getting this to work on OS X?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:18,security,updat,updates,18,@zzxuanyuan - any updates on getting this to work on OS X?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:16,deployability,updat,updates,16,@zzxuanyuan any updates on this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:16,safety,updat,updates,16,@zzxuanyuan any updates on this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:16,security,updat,updates,16,@zzxuanyuan any updates on this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:21,deployability,updat,update,21,@pcanal Is there any update on signal handler on MacOS? Do I still need to work on this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:21,safety,updat,update,21,@pcanal Is there any update on signal handler on MacOS? Do I still need to work on this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:21,security,updat,update,21,@pcanal Is there any update on signal handler on MacOS? Do I still need to work on this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:31,security,sign,signal,31,@pcanal Is there any update on signal handler on MacOS? Do I still need to work on this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1054:15,safety,test,test,15,"Have to make a test, so DNM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:15,testability,test,test,15,"Have to make a test, so DNM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:19,safety,test,tests,19,Let's postpone the tests until ROOT compiles and I can actually run the tests...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:72,safety,test,tests,72,Let's postpone the tests until ROOT compiles and I can actually run the tests...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:19,testability,test,tests,19,Let's postpone the tests until ROOT compiles and I can actually run the tests...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:72,testability,test,tests,72,Let's postpone the tests until ROOT compiles and I can actually run the tests...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1056:11,deployability,build,build,11,@phsft-bot build?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:401,availability,consist,consist,401,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:595,deployability,contain,container,595,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:631,deployability,contain,containers,631,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:722,deployability,contain,contained,722,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:206,energy efficiency,optim,optimisation,206,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:264,integrability,transform,transformations,264,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:738,integrability,wrap,wrapping,738,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:264,interoperability,transform,transformations,264,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:21,performance,Cach,Cache,21,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:69,performance,cach,caching,69,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:79,performance,cach,cached,79,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:142,performance,cach,cache,142,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:155,performance,cach,cached,155,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:336,performance,cach,caching,336,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:657,performance,cach,cache,657,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:439,reliability,doe,does,439,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:314,safety,test,testing,314,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:503,safety,compl,completely,503,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:503,security,compl,completely,503,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:683,security,access,access,683,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:314,testability,test,testing,314,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:401,usability,consist,consist,401,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:514,usability,clear,clear,514,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:668,usability,support,support,668,"The functionality of Cache is all there. The only issue remaining is caching a cached TDF (let's call this latter ""A"") without destroying the cache of the cached (meaning ""A""). This is a side effect of the optimisation in place to deliver data with zero-copies to transformations and actions requesting it. As for testing, checking the caching works with IMT on needs to be done. The extra mile would consist in checking statically that T does not have a copy constructor and react. How to react is not completely clear to me yet. There are two ways perhaps to solve this problem: 1. Act on the container, keeping in mind that the containers which form the cache must support random access for MT execution. 2. Act on the contained type, wrapping objects in some way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1058:85,safety,review,review,85,"As I said in the description on my pull request, this is work in progress and I will review the changes and break the commit up into several pieces. Once I do that, than we can discuss the code. For now, I just want to run the tests on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:227,safety,test,tests,227,"As I said in the description on my pull request, this is work in progress and I will review the changes and break the commit up into several pieces. Once I do that, than we can discuss the code. For now, I just want to run the tests on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:85,testability,review,review,85,"As I said in the description on my pull request, this is work in progress and I will review the changes and break the commit up into several pieces. Once I do that, than we can discuss the code. For now, I just want to run the tests on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:227,testability,test,tests,227,"As I said in the description on my pull request, this is work in progress and I will review the changes and break the commit up into several pieces. Once I do that, than we can discuss the code. For now, I just want to run the tests on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:65,usability,progress,progress,65,"As I said in the description on my pull request, this is work in progress and I will review the changes and break the commit up into several pieces. Once I do that, than we can discuss the code. For now, I just want to run the tests on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:183,availability,operat,operations,183,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:531,availability,error,errors,531,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:23,deployability,version,version,23,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:81,deployability,version,version,81,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:176,deployability,modul,modulo,176,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:836,deployability,continu,continue,836,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:878,deployability,automat,automatic,878,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:73,energy efficiency,current,current,73,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:819,energy efficiency,current,current,819,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:863,energy efficiency,Current,Currently,863,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:23,integrability,version,version,23,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:81,integrability,version,version,81,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:23,modifiability,version,version,23,"Alright, with this new version all tests pass on my machine. I think the current version is essentially equivalent to what we already have now, except for the avoidance of the modulo operations in the beginning. I also have a last commit to add, but even though it's a bug fix, some tests do not work because of it, so I want to merge it separately. Here is the diff in any case:. ```diff. commit 02e4b62489d8764ef1b3c243183d8cf2f745979b (fill). Author: Guilherme Amadio <amadio@cern.ch>. Date: Wed Sep 27 15:01:38 2017 +0200. Fix errors that are not reported when fDirectory == nullptr. diff --git a/tree/tree/src/TTree.cxx b/tree/tree/src/TTree.cxx. index bc23e6ef82..7bb57aa8e8 100644. --- a/tree/tree/src/TTree.cxx. +++ b/tree/tree/src/TTree.cxx. @@ -4564,18 +4564,12 @@ Int_t TTree::Fill(). // If above, close the current file and continue on a new file. // Currently, the automatic change of file is restricted. // to the case where the tree is in the top level directory. - if (!fDirectory). - return nbytes;. + if (fDirectory). + if (TFile *file = fDirectory->GetFile()). + if ((TDirectory *)file == fDirectory && (file->GetEND() > fgMaxTreeSize)). + ChangeFile(file);. . - TFile* file = fDirectory->GetFile();. - if (file && (file->GetEND() > fgMaxTreeSize)). - if (fDirectory == (TDirectory *)file). - ChangeFile(file);. -. - if (nerror). - return -1;. -. - return nbytes;. + return nerror ? -1 : nbytes;. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
