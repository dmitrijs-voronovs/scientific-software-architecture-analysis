id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/2220:168,deployability,build,build,168,hoverxref/code source links will not work until this gets merged because the 1) the pr build docs are not hosted on the readthedocs domain and two for codelinks the pr build adds a weird nonexistent tag. But I confirmed this all works for scvi-tools,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:210,usability,confirm,confirmed,210,hoverxref/code source links will not work until this gets merged because the 1) the pr build docs are not hosted on the readthedocs domain and two for codelinks the pr build adds a weird nonexistent tag. But I confirmed this all works for scvi-tools,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:244,usability,tool,tools,244,hoverxref/code source links will not work until this gets merged because the 1) the pr build docs are not hosted on the readthedocs domain and two for codelinks the pr build adds a weird nonexistent tag. But I confirmed this all works for scvi-tools,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:15,deployability,fail,failing,15,It's currently failing now due to it trying to render tutorials in the tutorials repo that aren't actually used (pbmc5k) but the link at in the first comment still shows the last successful build.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:190,deployability,build,build,190,It's currently failing now due to it trying to render tutorials in the tutorials repo that aren't actually used (pbmc5k) but the link at in the first comment still shows the last successful build.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:5,energy efficiency,current,currently,5,It's currently failing now due to it trying to render tutorials in the tutorials repo that aren't actually used (pbmc5k) but the link at in the first comment still shows the last successful build.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:15,reliability,fail,failing,15,It's currently failing now due to it trying to render tutorials in the tutorials repo that aren't actually used (pbmc5k) but the link at in the first comment still shows the last successful build.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:90,usability,tool,tools,90,@Zethson this is pretty much good to go and follows almost exactly how we have it in scvi tools,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:62,deployability,build,build,62,"@Zethson docs are built in the CI rtd, not sure why you can't build it locally",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:136,modifiability,maintain,maintain,136,Thank you @adamgayoso ! We should consider removing the ecosystem page in favor our scverse ecosystem page in the future to not have to maintain both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:136,safety,maintain,maintain,136,Thank you @adamgayoso ! We should consider removing the ecosystem page in favor our scverse ecosystem page in the future to not have to maintain both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/issues/2225:62,deployability,depend,dependencies,62,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:62,integrability,depend,dependencies,62,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:38,modifiability,pac,package,38,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:62,modifiability,depend,dependencies,62,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:62,safety,depend,dependencies,62,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:198,safety,test,test,198,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:62,testability,depend,dependencies,62,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:198,testability,test,test,198,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:149,safety,test,testing,149,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:294,safety,test,tests,294,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:449,safety,test,test,449,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:504,safety,test,test,504,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:522,security,ident,identical,522,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:542,security,hack,hacked,542,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:149,testability,test,testing,149,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:294,testability,test,tests,294,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:449,testability,test,test,449,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:504,testability,test,test,504,"Most things? - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing. - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly! They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:6,interoperability,specif,specifically,6,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:39,modifiability,pac,package,39,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:98,reliability,doe,does,98,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:26,safety,test,tests,26,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:48,safety,test,tests,48,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:90,safety,test,test,90,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:26,testability,test,tests,26,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:48,testability,test,tests,48,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:90,testability,test,test,90,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:58,modifiability,pac,package,58,As said:. > Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:101,modifiability,pac,package,101,As said:. > Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:270,deployability,modul,modules,270,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:212,integrability,discover,discovery,212,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:212,interoperability,discover,discovery,212,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:270,modifiability,modul,modules,270,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:36,safety,test,testing,36,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:207,safety,test,test,207,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:270,safety,modul,modules,270,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:281,safety,test,test,281,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:316,safety,test,testing,316,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:337,safety,test,testing,337,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:362,safety,test,testing,362,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:36,testability,test,testing,36,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:65,testability,emul,emulate,65,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:207,testability,test,test,207,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:281,testability,test,test,281,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:316,testability,test,testing,316,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:337,testability,test,testing,337,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:362,testability,test,testing,362,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:212,usability,discov,discovery,212,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:375,energy efficiency,draw,drawback-less,375,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:41,integrability,discover,discovery,41,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:295,integrability,sub,submodules,295,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:41,interoperability,discover,discovery,41,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:164,performance,time,time,164,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:36,safety,test,test,36,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:124,safety,test,testing,124,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:149,safety,test,tests,149,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:216,safety,test,tests,216,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:271,safety,test,test,271,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:317,safety,test,testing,317,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:421,safety,test,test,421,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:523,safety,test,tests,523,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:36,testability,test,test,36,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:124,testability,test,testing,124,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:149,testability,test,tests,149,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:216,testability,test,tests,216,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:254,testability,simpl,simply,254,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:271,testability,test,test,271,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:317,testability,test,testing,317,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:421,testability,test,test,421,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:523,testability,test,tests,523,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:41,usability,discov,discovery,41,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:254,usability,simpl,simply,254,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`? Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:803,deployability,version,versions,803,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:886,deployability,releas,releases,886,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:896,deployability,depend,depending,896,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1077,deployability,releas,releases,1077,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:690,energy efficiency,draw,drawback-less,690,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:795,energy efficiency,Current,Current,795,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:450,integrability,sub,submodules,450,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:803,integrability,version,versions,803,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:896,integrability,depend,depending,896,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:19,modifiability,pac,package,19,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:803,modifiability,version,versions,803,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:896,modifiability,depend,depending,896,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:33,safety,test,test,33,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:70,safety,test,tests,70,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:426,safety,test,test,426,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:471,safety,test,testing,471,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:896,safety,depend,depending,896,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:33,testability,test,test,33,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:70,testability,test,tests,70,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:79,testability,emul,emulate,79,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:266,testability,emul,emulate,266,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:409,testability,simpl,simply,409,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:426,testability,test,test,426,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:471,testability,test,testing,471,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:896,testability,depend,depending,896,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:123,usability,navigat,navigate,123,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:149,usability,prefer,prefer,149,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:409,usability,simpl,simply,409,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:909,usability,feedback,feedback,909,"Can you point to a package whose test organization you would like our tests to emulate? I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib? Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2252,availability,down,down,2252,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1814,deployability,modul,module,1814,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1925,deployability,modul,modules,1925,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2024,deployability,modul,modules,2024,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2141,deployability,modul,module,2141,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2183,deployability,modul,modules,2183,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1360,integrability,configur,configured,1360," it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reaso",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:667,interoperability,specif,specifically,667,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2110,interoperability,plug,plugins,2110,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:21,modifiability,pac,package,21,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:261,modifiability,pac,package,261,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:726,modifiability,variab,variables,726,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1360,modifiability,configur,configured,1360," it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reaso",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1814,modifiability,modul,module,1814,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1916,modifiability,pac,packages,1916,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1925,modifiability,modul,modules,1925,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2024,modifiability,modul,modules,2024,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2141,modifiability,modul,module,2141,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2183,modifiability,modul,modules,2183,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:35,safety,test,test,35,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:72,safety,test,tests,72,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:147,safety,test,testing,147,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:219,safety,test,tests,219,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:248,safety,test,tests,248,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:318,safety,test,tests,318,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:845,safety,compl,complete,845,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:854,safety,test,test,854,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:913,safety,test,tests,913,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1325,safety,test,tests,1325,"ctory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. ac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1814,safety,modul,module,1814,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1925,safety,modul,modules,1925,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2019,safety,test,test,2019,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2024,safety,modul,modules,2024,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2136,safety,test,test,2136,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2141,safety,modul,module,2141,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2168,safety,test,tests,2168,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2183,safety,modul,modules,2183,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2297,safety,test,test,2297,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2319,safety,test,tests,2319,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2381,safety,test,test,2381,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:845,security,compl,complete,845,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1360,security,configur,configured,1360," it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reaso",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:35,testability,test,test,35,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:72,testability,test,tests,72,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:81,testability,emul,emulate,81,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:147,testability,test,testing,147,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:219,testability,test,tests,219,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:248,testability,test,tests,248,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:318,testability,test,tests,318,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:510,testability,emul,emulate,510,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:854,testability,test,test,854,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:913,testability,test,tests,913,"> Can you point to a package whose test organization you would like our tests to emulate? - pytest: https://github.com/pytest-dev/pytest/tree/main/testing. - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1265,testability,hook,hookspec,1265," and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures acc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1325,testability,test,tests,1325,"ctory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. ac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1991,testability,simpl,simple,1991,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2019,testability,test,test,2019,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2136,testability,test,test,2136,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2168,testability,test,tests,2168,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2297,testability,test,test,2297,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2319,testability,test,tests,2319,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:2381,testability,test,test,2381,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1730,usability,clear,clear,1730,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:1991,usability,simpl,simple,1991,"s setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically? Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module. 2. it collects all tests in those modules and checks which fixtures they need. 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:724,availability,slo,slow,724,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:729,availability,down,down,729,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:689,deployability,modul,module,689,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:689,modifiability,modul,module,689,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:724,reliability,slo,slow,724,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:303,safety,test,testing,303,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:354,safety,test,tests,354,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:684,safety,test,test,684,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:689,safety,modul,module,689,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:737,safety,prevent,prevent,737,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:824,safety,test,tests,824,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:947,safety,test,test,947,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:737,security,preven,prevent,737,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:303,testability,test,testing,303,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:354,testability,test,tests,354,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:684,testability,test,test,684,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:824,testability,test,tests,824,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:947,testability,test,test,947,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof. >. > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode. * Changing organization of tests. * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2229:95,availability,error,error,95,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think? In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example? ```python. VALID_LEGENDLOCS = {. 'none',. 'right margin',. 'on data',. 'on data export',. 'best',. 'upper right',. 'upper left',. 'lower left',. 'lower right',. 'right',. 'center left',. 'center right',. 'lower center',. 'upper center',. 'center',. }. ```. Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/issues/2229:423,integrability,event,eventually,423,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think? In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example? ```python. VALID_LEGENDLOCS = {. 'none',. 'right margin',. 'on data',. 'on data export',. 'best',. 'upper right',. 'upper left',. 'lower left',. 'lower right',. 'right',. 'center left',. 'center right',. 'lower center',. 'upper center',. 'center',. }. ```. Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/issues/2229:95,performance,error,error,95,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think? In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example? ```python. VALID_LEGENDLOCS = {. 'none',. 'right margin',. 'on data',. 'on data export',. 'best',. 'upper right',. 'upper left',. 'lower left',. 'lower right',. 'right',. 'center left',. 'center right',. 'lower center',. 'upper center',. 'center',. }. ```. Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/issues/2229:95,safety,error,error,95,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think? In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example? ```python. VALID_LEGENDLOCS = {. 'none',. 'right margin',. 'on data',. 'on data export',. 'best',. 'upper right',. 'upper left',. 'lower left',. 'lower right',. 'right',. 'center left',. 'center right',. 'lower center',. 'upper center',. 'center',. }. ```. Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/issues/2229:70,usability,document,documentation,70,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think? In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example? ```python. VALID_LEGENDLOCS = {. 'none',. 'right margin',. 'on data',. 'on data export',. 'best',. 'upper right',. 'upper left',. 'lower left',. 'lower right',. 'right',. 'center left',. 'center right',. 'lower center',. 'upper center',. 'center',. }. ```. Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/issues/2229:95,usability,error,error,95,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think? In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example? ```python. VALID_LEGENDLOCS = {. 'none',. 'right margin',. 'on data',. 'on data export',. 'best',. 'upper right',. 'upper left',. 'lower left',. 'lower right',. 'right',. 'center left',. 'center right',. 'lower center',. 'upper center',. 'center',. }. ```. Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/pull/2231:105,usability,close,close,105,Just noticed this is almost an exact duplicate of #1985 (check the issues but not PRs 🤦🏻 ). Feel free to close this if you want to keep the older one open.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:278,safety,test,test,278,@lazappi you are now the chosen one :). Think that using the size attribute like in https://github.com/scverse/scanpy/pull/1985/files is maybe nicer and more explicit. `len()` could technically be overwritten and return anything. It's less explicit. Could you maybe add a quick test which covers this case? Thank you very much!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:278,testability,test,test,278,@lazappi you are now the chosen one :). Think that using the size attribute like in https://github.com/scverse/scanpy/pull/1985/files is maybe nicer and more explicit. `len()` could technically be overwritten and return anything. It's less explicit. Could you maybe add a quick test which covers this case? Thank you very much!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:36,safety,test,test,36,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:76,safety,test,test,76,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:36,testability,test,test,36,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:76,testability,test,test,76,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:70,availability,error,errors,70,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:70,performance,error,errors,70,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:70,safety,error,errors,70,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:70,usability,error,errors,70,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:84,availability,failur,failures,84,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:105,availability,fault,faults,105,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:84,deployability,fail,failures,84,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:154,deployability,fail,fails,154,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:105,energy efficiency,fault,faults,105,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:122,integrability,sub,submitting,122,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:84,performance,failur,failures,84,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:105,performance,fault,faults,105,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:84,reliability,fail,failures,84,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:105,reliability,fault,faults,105,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:154,reliability,fail,fails,154,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:105,safety,fault,faults,105,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:40,availability,Error,Error,40,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:75,availability,error,error,75,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:40,performance,Error,Error,40,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:75,performance,error,error,75,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:40,safety,Error,Error,40,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:75,safety,error,error,75,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:128,safety,test,tests,128,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:24,testability,Assert,AssertionError,24,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:128,testability,test,tests,128,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:40,usability,Error,Error,40,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:75,usability,error,error,75,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:67,deployability,releas,release,67,"@ivirshup this one should be good to go now, right? Do you require release notes for such small things or do you manually add those later?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:19,safety,review,reviewed,19,"@Zethson, have you reviewed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:19,testability,review,reviewed,19,"@Zethson, have you reviewed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/pull/2231:30,deployability,releas,release,30,"And yes, should get a bug fix release note.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231
https://github.com/scverse/scanpy/issues/2234:126,deployability,scale,scale,126,@Intron7 said he had experience with this and it’s a really good way to do things fast with dask etc. - works well in dask. - scale is a good example how to do it. - can’t do in 3rd party like PCA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:126,energy efficiency,scale,scale,126,@Intron7 said he had experience with this and it’s a really good way to do things fast with dask etc. - works well in dask. - scale is a good example how to do it. - can’t do in 3rd party like PCA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:126,modifiability,scal,scale,126,@Intron7 said he had experience with this and it’s a really good way to do things fast with dask etc. - works well in dask. - scale is a good example how to do it. - can’t do in 3rd party like PCA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:126,performance,scale,scale,126,@Intron7 said he had experience with this and it’s a really good way to do things fast with dask etc. - works well in dask. - scale is a good example how to do it. - can’t do in 3rd party like PCA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:21,usability,experien,experience,21,@Intron7 said he had experience with this and it’s a really good way to do things fast with dask etc. - works well in dask. - scale is a good example how to do it. - can’t do in 3rd party like PCA,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:28,availability,mask,mask,28,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:252,availability,mask,masks,252,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:44,modifiability,scal,scaling,44,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:131,performance,perform,performed,131,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:77,usability,effectiv,effective,77,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:91,usability,indicat,indicating,91,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:131,usability,perform,performed,131,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:204,usability,clear,clear,204,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/pull/2235:19,availability,failur,failures,19,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:19,deployability,fail,failures,19,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:61,modifiability,refact,refactoring,61,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:19,performance,failur,failures,19,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:61,performance,refactor,refactoring,61,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:19,reliability,fail,failures,19,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:14,safety,test,test,14,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:78,safety,test,tests,78,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:154,safety,test,test,154,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:38,security,expos,exposed,38,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:14,testability,test,test,14,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:78,testability,test,tests,78,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:154,testability,test,test,154,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:172,usability,help,help,172,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:39,deployability,updat,updates,39,"@flying-sheep, I see you're doing some updates here. Are you doing anything to narrow the scope of the PR as requested last go-around?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:39,safety,updat,updates,39,"@flying-sheep, I see you're doing some updates here. Are you doing anything to narrow the scope of the PR as requested last go-around?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:39,security,updat,updates,39,"@flying-sheep, I see you're doing some updates here. Are you doing anything to narrow the scope of the PR as requested last go-around?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:225,safety,test,test,225,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669. - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:240,safety,test,tests,240,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669. - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:225,testability,test,test,225,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669. - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:240,testability,test,tests,240,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669. - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:387,testability,understand,understand,387,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669. - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:32,safety,test,tests,32,"It’s connected because the paga tests don’t `copy` the objects and therefore run sequentially, but I can extract it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:32,testability,test,tests,32,"It’s connected because the paga tests don’t `copy` the objects and therefore run sequentially, but I can extract it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:57,deployability,fail,fail,57,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:105,deployability,updat,update,105,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:57,reliability,fail,fail,57,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:49,safety,test,test,49,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:105,safety,updat,update,105,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:105,security,updat,update,105,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:49,testability,test,test,49,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:55,modifiability,paramet,parametrized,55,"OK, everything done as we agreed on yesterday:. - only parametrized datasets are fixtures. - the skip mark is now a single function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/issues/2236:80,availability,consist,consists,80,I have encountered this issue and found that it occurs when one or more batches consists of only a single cell.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:72,integrability,batch,batches,72,I have encountered this issue and found that it occurs when one or more batches consists of only a single cell.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:72,performance,batch,batches,72,I have encountered this issue and found that it occurs when one or more batches consists of only a single cell.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:80,usability,consist,consists,80,I have encountered this issue and found that it occurs when one or more batches consists of only a single cell.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:70,integrability,batch,batches,70,"Hi, you can of course circumvent the problem by removing all 1-sample batches before calculating HVG, but I have a fix coming.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:70,performance,batch,batches,70,"Hi, you can of course circumvent the problem by removing all 1-sample batches before calculating HVG, but I have a fix coming.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2237:22,deployability,instal,install,22,You should be able to install an experimental m1 native numba here:. https://numba.discourse.group/t/wheels-for-apple-silicon-m1/1282,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2237
https://github.com/scverse/scanpy/issues/2239:5,availability,error,error,5,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1878,deployability,log,logical,1878,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1932,deployability,updat,updated,1932,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:303,energy efficiency,cloud,cloudpickle,303,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1886,energy efficiency,CPU,CPU,1886,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1890,energy efficiency,core,cores,1890,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:435,modifiability,deco,decorator,435,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:841,modifiability,pac,packaging,841,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1746,modifiability,pac,packaged,1746,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,performance,error,error,5,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1886,performance,CPU,CPU,1886,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,safety,error,error,5,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1878,safety,log,logical,1878,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1932,safety,updat,updated,1932,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1878,security,log,logical,1878,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1912,security,Session,Session,1912,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1932,security,updat,updated,1932,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1362,testability,spy,spyder,1362,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1398,testability,spy,spydercustomize,1398,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1878,testability,log,logical,1878,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,usability,error,error,5,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1517,usability,tool,toolz,1517,"Same error here...any ideas? ```. -----. anndata 0.8.0. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.0.1. PyQt5 NA. anndata 0.8.0. anndata2ri 0.0.0. atomicwrites 1.4.0. autoreload NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. bs4 4.10.0. cached_property 1.5.2. cffi 1.15.0. chardet 4.0.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.2. dask 2022.02.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dunamai 1.10.0. entrypoints 0.4. fsspec 2022.02.0. get_version 3.5.4. h5py 3.6.0. igraph 0.9.9. ipykernel 6.9.1. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.0. matplotlib 3.5.1. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. packaging 21.3. pandas 1.3.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. rpy2 3.4.2. scanpy 1.8.2. scipy 1.7.3. seaborn 0.11.2. setuptools 59.8.0. sinfo 0.3.1. sip NA. six 1.16.0. sklearn 1.0.2. soupsieve 2.3.1. sphinxcontrib NA. spyder 5.2.2. spyder_kernels 2.2.1. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tables 3.7.0. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 7.32.0. jupyter_client 7.1.2. jupyter_core 4.9.2. -----. Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]. Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid. 16 logical CPU cores, x86_64. -----. Session information updated at 2022-04-20 18:16. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:85,performance,time,time,85,"Thank you @auesro! For now, I use the line `adata.uns['log1p'][""base""] = None` every time after reading a h5ad file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:64,availability,error,error,64,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:155,integrability,batch,batch,155,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:94,modifiability,variab,variable,94,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:64,performance,error,error,64,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:155,performance,batch,batch,155,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:64,safety,error,error,64,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:64,usability,error,error,64,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:695,energy efficiency,load,loading,695,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:304,integrability,wrap,wrapping,304,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:826,integrability,wrap,wrapping,826,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:695,performance,load,loading,695,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:507,testability,simpl,simplicity,507,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:599,testability,simpl,simplicity,599,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1000,testability,simpl,simplicity,1000,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1092,testability,simpl,simplicity,1092,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:507,usability,simpl,simplicity,507,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:599,usability,simpl,simplicity,599,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1000,usability,simpl,simplicity,1000,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1092,usability,simpl,simplicity,1092,"Trying out the tutorials these days and it seems this issue still persists. ---. Here is what I got from running the tutorial `pbmc3k.ipynb`:. Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph). - Inside `adata.uns`:. ```. OverloadedDict, wrapping:. 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)})]). With overloaded keys:. 	['neighbors']. ```. ---. After loading the matrix from the `.h5ad` file:. - Inside `adata.uns`, the `log1p` key became an empty dictionary:. ```. OverloadedDict, wrapping:. 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],. dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],. dtype=float32)}}. With overloaded keys:. 	['neighbors']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:134,deployability,log,logfoldchange,134,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:134,safety,log,logfoldchange,134,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:134,security,log,logfoldchange,134,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:134,testability,log,logfoldchange,134,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:60,availability,error,error,60,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. . I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:60,performance,error,error,60,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. . I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:60,safety,error,error,60,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. . I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:60,usability,error,error,60,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. . I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:73,security,team,team,73,@LuckyMD requires attentions to several of the threads above from Scanpy team. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,availability,error,error,5,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,performance,error,error,5,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,safety,error,error,5,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:5,usability,error,error,5,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/pull/2241:50,deployability,Updat,Update,50,"Hi,. thank you for your PR. Could you please:. 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things. 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no? 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/pull/2241:242,energy efficiency,core,core,242,"Hi,. thank you for your PR. Could you please:. 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things. 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no? 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/pull/2241:50,safety,Updat,Update,50,"Hi,. thank you for your PR. Could you please:. 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things. 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no? 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/pull/2241:50,security,Updat,Update,50,"Hi,. thank you for your PR. Could you please:. 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things. 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no? 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/pull/2241:288,security,hardcod,hardcode,288,"Hi,. thank you for your PR. Could you please:. 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things. 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no? 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/issues/2242:82,deployability,log,log-transformed,82,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:183,deployability,log,logarithmized,183,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:86,integrability,transform,transformed,86,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:86,interoperability,transform,transformed,86,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:409,interoperability,format,format,409,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:47,modifiability,variab,variable,47,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:82,safety,log,log-transformed,82,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:183,safety,log,logarithmized,183,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:203,safety,except,except,203,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:82,security,log,log-transformed,82,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:183,security,log,logarithmized,183,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:82,testability,log,log-transformed,82,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:183,testability,log,logarithmized,183,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:158,usability,document,documentation,158,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:. `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`. The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:76,usability,close,close,76,"Just came across this, as we haven't heard back after the follow-up we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:137,usability,behavi,behaviour,137,"Just came across this, as we haven't heard back after the follow-up we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2245:24,deployability,version,versions,24,"You can store different versions of coordinates in adata like so before you overwrite it. ```python. adata.obsm['X_umap_mod'] = adata.obsm['X_umap'].copy(). ```. And then use `pl.embedding` to plot the embedding by specifying the new name:. ```python. sc.pl.embedding(adata, basis='X_umap_mod'). ```. Edit: it is necessary to use `copy()` otherwise changing values of one obsm would affect the other.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2245:24,integrability,version,versions,24,"You can store different versions of coordinates in adata like so before you overwrite it. ```python. adata.obsm['X_umap_mod'] = adata.obsm['X_umap'].copy(). ```. And then use `pl.embedding` to plot the embedding by specifying the new name:. ```python. sc.pl.embedding(adata, basis='X_umap_mod'). ```. Edit: it is necessary to use `copy()` otherwise changing values of one obsm would affect the other.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2245:36,interoperability,coordinat,coordinates,36,"You can store different versions of coordinates in adata like so before you overwrite it. ```python. adata.obsm['X_umap_mod'] = adata.obsm['X_umap'].copy(). ```. And then use `pl.embedding` to plot the embedding by specifying the new name:. ```python. sc.pl.embedding(adata, basis='X_umap_mod'). ```. Edit: it is necessary to use `copy()` otherwise changing values of one obsm would affect the other.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2245:215,interoperability,specif,specifying,215,"You can store different versions of coordinates in adata like so before you overwrite it. ```python. adata.obsm['X_umap_mod'] = adata.obsm['X_umap'].copy(). ```. And then use `pl.embedding` to plot the embedding by specifying the new name:. ```python. sc.pl.embedding(adata, basis='X_umap_mod'). ```. Edit: it is necessary to use `copy()` otherwise changing values of one obsm would affect the other.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2245:24,modifiability,version,versions,24,"You can store different versions of coordinates in adata like so before you overwrite it. ```python. adata.obsm['X_umap_mod'] = adata.obsm['X_umap'].copy(). ```. And then use `pl.embedding` to plot the embedding by specifying the new name:. ```python. sc.pl.embedding(adata, basis='X_umap_mod'). ```. Edit: it is necessary to use `copy()` otherwise changing values of one obsm would affect the other.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2245:203,energy efficiency,cool,cool,203,"You are right, still I think this could be done in a more elegant way. . For example the `sc.tl.leiden(adata,neighbors_key = ""some_key"")` stores the computed values with the name of the key. It would be cool to just add this to pl.umap(). As you can already refer to the `neighbors_key`, why not add the `x_umap` as `x_umap_neighbors_key`? Edit:. The same holds for computing the `leiden` obs information, which is always stored as `leiden` and not `leiden_neighbors_key`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2246:138,modifiability,refact,refactor,138,It seems like `_read_legacy_10x_h5()` invokes ` _collect_datasets()` without taking `genome` into account? Perhaps this was lost during a refactor? https://github.com/scverse/scanpy/blob/bd06cc3d1e0bd990f6994e54414512fa0b25fea0/scanpy/readwrite.py#L222,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:138,performance,refactor,refactor,138,It seems like `_read_legacy_10x_h5()` invokes ` _collect_datasets()` without taking `genome` into account? Perhaps this was lost during a refactor? https://github.com/scverse/scanpy/blob/bd06cc3d1e0bd990f6994e54414512fa0b25fea0/scanpy/readwrite.py#L222,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:129,integrability,coupl,couple,129,"Yes, I think line 222 should be . ```python. _collect_datasets(dsets, f[genome]). ```. I will make a PR, and I will try to add a couple of tests to highlight this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:129,modifiability,coupl,couple,129,"Yes, I think line 222 should be . ```python. _collect_datasets(dsets, f[genome]). ```. I will make a PR, and I will try to add a couple of tests to highlight this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:139,safety,test,tests,139,"Yes, I think line 222 should be . ```python. _collect_datasets(dsets, f[genome]). ```. I will make a PR, and I will try to add a couple of tests to highlight this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:129,testability,coupl,couple,129,"Yes, I think line 222 should be . ```python. _collect_datasets(dsets, f[genome]). ```. I will make a PR, and I will try to add a couple of tests to highlight this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:139,testability,test,tests,139,"Yes, I think line 222 should be . ```python. _collect_datasets(dsets, f[genome]). ```. I will make a PR, and I will try to add a couple of tests to highlight this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:179,deployability,releas,release,179,"@ivirshup or @flying-sheep or any other active maintainers, if you get a chance, could you consider the associated PR for this issue? It'd be great to have this fixed in a future release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:47,modifiability,maintain,maintainers,47,"@ivirshup or @flying-sheep or any other active maintainers, if you get a chance, could you consider the associated PR for this issue? It'd be great to have this fixed in a future release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:47,safety,maintain,maintainers,47,"@ivirshup or @flying-sheep or any other active maintainers, if you get a chance, could you consider the associated PR for this issue? It'd be great to have this fixed in a future release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:111,availability,state,stated,111,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:190,availability,error,error-in-scanpy-,190,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:384,availability,error,error,384,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:516,availability,Avail,Available,516,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:680,availability,avail,available,680,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:799,availability,error,error,799,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:871,availability,Avail,Available,871,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:995,availability,error,error,995,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:404,deployability,contain,contains,404,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:16,energy efficiency,current,currently,16,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:63,energy efficiency,load,load,63,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:111,integrability,state,stated,111,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:308,interoperability,format,format,308,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:468,interoperability,specif,specify,468,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:546,modifiability,layer,layers,546,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:901,modifiability,layer,layers,901,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:63,performance,load,load,63,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:190,performance,error,error-in-scanpy-,190,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:384,performance,error,error,384,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:799,performance,error,error,799,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:995,performance,error,error,995,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:516,reliability,Availab,Available,516,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:680,reliability,availab,available,680,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:871,reliability,Availab,Available,871,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:92,safety,input,input,92,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:190,safety,error,error-in-scanpy-,190,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:384,safety,error,error,384,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:394,safety,test,test,394,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:516,safety,Avail,Available,516,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:680,safety,avail,available,680,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:739,safety,test,test,739,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:763,safety,test,test,763,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:799,safety,error,error,799,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:859,safety,test,test,859,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:871,safety,Avail,Available,871,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:995,safety,error,error,995,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:516,security,Availab,Available,516,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:680,security,availab,available,680,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:871,security,Availab,Available,871,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:394,testability,test,test,394,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:739,testability,test,test,739,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:763,testability,test,test,763,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:859,testability,test,test,859,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:92,usability,input,input,92,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:190,usability,error,error-in-scanpy-,190,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:384,usability,error,error,384,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:731,usability,command,command,731,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:799,usability,error,error,799,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:995,usability,error,error,995,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error . **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again . **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:89,energy efficiency,load,load,89,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:197,interoperability,format,format,197,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:89,performance,load,load,89,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:22,safety,test,test,22,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:163,safety,test,test,163,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:22,testability,test,test,22,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:163,testability,test,test,163,"@karenlawwc . For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2247:143,deployability,log,log,143,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:371,deployability,log,logfoldchanges,371,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:143,safety,log,log,143,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:371,safety,log,logfoldchanges,371,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:143,security,log,log,143,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:371,security,log,logfoldchanges,371,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:143,testability,log,log,143,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:371,testability,log,logfoldchanges,371,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. . If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function. ```python. df = sc.get.rank_genes_groups_df(adata, group=""1""). df_sorted = df.sort_values('logfoldchanges', ascending=False). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/pull/2248:0,energy efficiency,Cool,Cool,0,"Cool ! . in order to load legacy h5, I had to freeze scanpy==1.8.2. now I included this fix in a scanpy fork. I hope it gets merged soon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248
https://github.com/scverse/scanpy/pull/2248:21,energy efficiency,load,load,21,"Cool ! . in order to load legacy h5, I had to freeze scanpy==1.8.2. now I included this fix in a scanpy fork. I hope it gets merged soon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248
https://github.com/scverse/scanpy/pull/2248:21,performance,load,load,21,"Cool ! . in order to load legacy h5, I had to freeze scanpy==1.8.2. now I included this fix in a scanpy fork. I hope it gets merged soon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248
https://github.com/scverse/scanpy/issues/2250:55,availability,state,stated,55,Could you please provide a minimal working example? As stated: `Minimal code sample (that we can copy&paste without having any data)`. This would help us examine the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:55,integrability,state,stated,55,Could you please provide a minimal working example? As stated: `Minimal code sample (that we can copy&paste without having any data)`. This would help us examine the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:27,usability,minim,minimal,27,Could you please provide a minimal working example? As stated: `Minimal code sample (that we can copy&paste without having any data)`. This would help us examine the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:64,usability,Minim,Minimal,64,Could you please provide a minimal working example? As stated: `Minimal code sample (that we can copy&paste without having any data)`. This would help us examine the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:146,usability,help,help,146,Could you please provide a minimal working example? As stated: `Minimal code sample (that we can copy&paste without having any data)`. This would help us examine the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:383,availability,error,error,383,"```py. adata = sc.datasets.pbmc68k_reduced(). markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. categories_order=['0','1','9','8','2','5','4','7','3','6','10']. sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order). ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:383,performance,error,error,383,"```py. adata = sc.datasets.pbmc68k_reduced(). markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. categories_order=['0','1','9','8','2','5','4','7','3','6','10']. sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order). ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:383,safety,error,error,383,"```py. adata = sc.datasets.pbmc68k_reduced(). markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. categories_order=['0','1','9','8','2','5','4','7','3','6','10']. sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order). ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:383,usability,error,error,383,"```py. adata = sc.datasets.pbmc68k_reduced(). markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. categories_order=['0','1','9','8','2','5','4','7','3','6','10']. sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order). ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:17,usability,user,user-images,17,![image](https://user-images.githubusercontent.com/50618480/168198347-5ae66930-2386-4cfd-9be1-7a0cdc9707ac.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:61,availability,state,state,61,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:61,integrability,state,state,61,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:82,interoperability,format,format,82,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:53,reliability,doe,doesn,53,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:76,safety,input,input,76,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:31,usability,document,documentation,31,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:76,usability,input,input,76,"I also have this issue. In the documentation it also doesn't state what the input format should by, I tried as a list (similar to order in violin plot) but I get no change...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:165,deployability,api,api,165,I don’t think it’s currently supported for heatmap and tracksplot. Have you tried using [`col.cat.reorder_categories(...)`](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html) on the column?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:19,energy efficiency,current,currently,19,I don’t think it’s currently supported for heatmap and tracksplot. Have you tried using [`col.cat.reorder_categories(...)`](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html) on the column?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:43,energy efficiency,heat,heatmap,43,I don’t think it’s currently supported for heatmap and tracksplot. Have you tried using [`col.cat.reorder_categories(...)`](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html) on the column?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:165,integrability,api,api,165,I don’t think it’s currently supported for heatmap and tracksplot. Have you tried using [`col.cat.reorder_categories(...)`](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html) on the column?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:165,interoperability,api,api,165,I don’t think it’s currently supported for heatmap and tracksplot. Have you tried using [`col.cat.reorder_categories(...)`](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html) on the column?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:29,usability,support,supported,29,I don’t think it’s currently supported for heatmap and tracksplot. Have you tried using [`col.cat.reorder_categories(...)`](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.categories.html) on the column?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2252:19,usability,help,helped,19,Check this out. It helped me a lot. . https://github.com/Teichlab/limbcellatlas/issues/1#issuecomment-1146685471,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2252:261,availability,ping,ping,261,"hi @MertDemirdizen @sophieRAIBAUD . sorry for late reply. This type of functionality is planned to be added to squidpy (there is an issue also there discussing the same). I'd close this here since the scanpy spatial plot will be deprecated, feel free to reopen/ping me in the squidpy repo directly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2252:88,testability,plan,planned,88,"hi @MertDemirdizen @sophieRAIBAUD . sorry for late reply. This type of functionality is planned to be added to squidpy (there is an issue also there discussing the same). I'd close this here since the scanpy spatial plot will be deprecated, feel free to reopen/ping me in the squidpy repo directly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2252:175,usability,close,close,175,"hi @MertDemirdizen @sophieRAIBAUD . sorry for late reply. This type of functionality is planned to be added to squidpy (there is an issue also there discussing the same). I'd close this here since the scanpy spatial plot will be deprecated, feel free to reopen/ping me in the squidpy repo directly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2252:30,testability,plan,plan,30,OK thanks. @giovp when do you plan to add this new fonctionnality ? @MertDemirdizen : I don't understand how to add the intensity according to the post (https://github.com/Teichlab/limbcellatlas/issues/1#issuecomment-1146685471). could you help me ? many thanks !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2252:94,testability,understand,understand,94,OK thanks. @giovp when do you plan to add this new fonctionnality ? @MertDemirdizen : I don't understand how to add the intensity according to the post (https://github.com/Teichlab/limbcellatlas/issues/1#issuecomment-1146685471). could you help me ? many thanks !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2252:240,usability,help,help,240,OK thanks. @giovp when do you plan to add this new fonctionnality ? @MertDemirdizen : I don't understand how to add the intensity according to the post (https://github.com/Teichlab/limbcellatlas/issues/1#issuecomment-1146685471). could you help me ? many thanks !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2253:188,deployability,api,api,188,"in adata.obsm[""spatial""], I'd suggest to plot these type of issues directly on squidpy, see this function for read visium. there this is explained https://squidpy.readthedocs.io/en/latest/api/squidpy.read.visium.html#squidpy.read.visium",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2253
https://github.com/scverse/scanpy/issues/2253:188,integrability,api,api,188,"in adata.obsm[""spatial""], I'd suggest to plot these type of issues directly on squidpy, see this function for read visium. there this is explained https://squidpy.readthedocs.io/en/latest/api/squidpy.read.visium.html#squidpy.read.visium",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2253
https://github.com/scverse/scanpy/issues/2253:188,interoperability,api,api,188,"in adata.obsm[""spatial""], I'd suggest to plot these type of issues directly on squidpy, see this function for read visium. there this is explained https://squidpy.readthedocs.io/en/latest/api/squidpy.read.visium.html#squidpy.read.visium",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2253
https://github.com/scverse/scanpy/issues/2254:141,testability,understand,understanding,141,@Koncopd do you have any insight on this post? https://discourse.scverse.org/t/how-to-interpret-diffusion-maps/2224. I'm having some trouble understanding how to interpret certain parts of the diffusion maps.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254
https://github.com/scverse/scanpy/pull/2255:54,safety,review,review,54,"@Koncopd can you get the CI to pass, please? Happy to review then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:54,testability,review,review,54,"@Koncopd can you get the CI to pass, please? Happy to review then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:29,deployability,releas,release,29,"@Koncopd, there was a bugged release of pip. I think this should work now that there has been a bugfix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:43,deployability,fail,fails,43,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:43,reliability,fail,fails,43,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:38,safety,test,test,38,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:38,testability,test,test,38,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:27,availability,toler,tolerance,27,"ah it seems a really minor tolerance thingy, try to increase it to 16 should be fine. ```. save_and_compare_images = image_comparer(ROOT, FIGS, tol=15). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:27,reliability,toleran,tolerance,27,"ah it seems a really minor tolerance thingy, try to increase it to 16 should be fine. ```. save_and_compare_images = image_comparer(ROOT, FIGS, tol=15). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/pull/2255:125,usability,close,close,125,@ivirshup is this the accepted solution for https://github.com/scverse/scanpy/pull/2280? Just trying to figure out if we can close the PR and fix the bug.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255
https://github.com/scverse/scanpy/issues/2256:83,availability,error,error,83,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:558,deployability,releas,release,558,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:566,deployability,version,versions,566,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:10,energy efficiency,current,currently,10,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:551,integrability,coupl,couple,551,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:566,integrability,version,versions,566,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:158,modifiability,paramet,parameter,158,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:199,modifiability,paramet,parameter,199,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:440,modifiability,paramet,parameter,440,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:551,modifiability,coupl,couple,551,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:566,modifiability,version,versions,566,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:83,performance,error,error,83,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:320,performance,content,content,320,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:83,safety,error,error,83,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:551,testability,coupl,couple,551,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:83,usability,error,error,83,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:243,interoperability,specif,specific,243,"> try passing to `gene_symbol` a _list_ object of the `var_names` you want to plot. The ""gene_symbols"" param for `rank_gene_groups_violin()` takes a key from `adata.var` though. The ""gene_names"" field allows for a list object, but this is for specific genes rather than the top N genes from `rank_genes_groups`. . https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.rank_genes_groups_violin.html#scanpy.pl.rank_genes_groups_violin. I guess I could just map the top N genes from `rank_genes_groups` on my own and pass that to the ""gene_names"" parameter. However, I feel that the function (either `rank_genes_groups_violin` setting ""_gene_names"" or `sc.get.obs_df` renaming the ""keys"" based on the ""gene_symbols"" param) should handle the `adata.uns[""rank_genes_groups""][""names""]` mapping to `adata.var[<gene_symbols_key>]` behind the scenes. At least the ""gene_symbols"" param definition for `rank_genes_groups_violin` implies that it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:550,modifiability,paramet,parameter,550,"> try passing to `gene_symbol` a _list_ object of the `var_names` you want to plot. The ""gene_symbols"" param for `rank_gene_groups_violin()` takes a key from `adata.var` though. The ""gene_names"" field allows for a list object, but this is for specific genes rather than the top N genes from `rank_genes_groups`. . https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.rank_genes_groups_violin.html#scanpy.pl.rank_genes_groups_violin. I guess I could just map the top N genes from `rank_genes_groups` on my own and pass that to the ""gene_names"" parameter. However, I feel that the function (either `rank_genes_groups_violin` setting ""_gene_names"" or `sc.get.obs_df` renaming the ""keys"" based on the ""gene_symbols"" param) should handle the `adata.uns[""rank_genes_groups""][""names""]` mapping to `adata.var[<gene_symbols_key>]` behind the scenes. At least the ""gene_symbols"" param definition for `rank_genes_groups_violin` implies that it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:940,reliability,doe,does,940,"> try passing to `gene_symbol` a _list_ object of the `var_names` you want to plot. The ""gene_symbols"" param for `rank_gene_groups_violin()` takes a key from `adata.var` though. The ""gene_names"" field allows for a list object, but this is for specific genes rather than the top N genes from `rank_genes_groups`. . https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.rank_genes_groups_violin.html#scanpy.pl.rank_genes_groups_violin. I guess I could just map the top N genes from `rank_genes_groups` on my own and pass that to the ""gene_names"" parameter. However, I feel that the function (either `rank_genes_groups_violin` setting ""_gene_names"" or `sc.get.obs_df` renaming the ""keys"" based on the ""gene_symbols"" param) should handle the `adata.uns[""rank_genes_groups""][""names""]` mapping to `adata.var[<gene_symbols_key>]` behind the scenes. At least the ""gene_symbols"" param definition for `rank_genes_groups_violin` implies that it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:28,availability,sli,slightly,28,I think my issue is ever-so-slightly different enough that I am going to create a new ticket instead. (#2258),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2256:28,reliability,sli,slightly,28,I think my issue is ever-so-slightly different enough that I am going to create a new ticket instead. (#2258),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2257:146,availability,cluster,clustering,146,"Hey! You can colour a umap plot with covariate `'key'` via `sc.pl.umap(adata, color='key')`. Here `'key'` can be anything from a gene name or the clustering covariate. Is that what you are looking for?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:146,deployability,cluster,clustering,146,"Hey! You can colour a umap plot with covariate `'key'` via `sc.pl.umap(adata, color='key')`. Here `'key'` can be anything from a gene name or the clustering covariate. Is that what you are looking for?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:108,security,Ident,Idents,108,Nope what I am looking for is Featureplot functionality of Seurat in scanpy where you can label the UMAP by Idents like shown in the attached figure. ![umap 50 0 7 colorby UMI lab Cycling 220501](https://user-images.githubusercontent.com/6811915/169171370-a6609896-d96e-49c1-913b-82b92e99141f.jpg).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:204,usability,user,user-images,204,Nope what I am looking for is Featureplot functionality of Seurat in scanpy where you can label the UMAP by Idents like shown in the attached figure. ![umap 50 0 7 colorby UMI lab Cycling 220501](https://user-images.githubusercontent.com/6811915/169171370-a6609896-d96e-49c1-913b-82b92e99141f.jpg).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:41,availability,cluster,clustering,41,"Here the Ident is set to be a particular clustering resolution and we are visualizing nCount on the UMAP. So basically what I am looking for is ""Color by Key"" and label by idents.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:41,deployability,cluster,clustering,41,"Here the Ident is set to be a particular clustering resolution and we are visualizing nCount on the UMAP. So basically what I am looking for is ""Color by Key"" and label by idents.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:9,security,Ident,Ident,9,"Here the Ident is set to be a particular clustering resolution and we are visualizing nCount on the UMAP. So basically what I am looking for is ""Color by Key"" and label by idents.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:172,security,ident,idents,172,"Here the Ident is set to be a particular clustering resolution and we are visualizing nCount on the UMAP. So basically what I am looking for is ""Color by Key"" and label by idents.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:74,usability,visual,visualizing,74,"Here the Ident is set to be a particular clustering resolution and we are visualizing nCount on the UMAP. So basically what I am looking for is ""Color by Key"" and label by idents.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:200,availability,cluster,clusters,200,"I guess that's not strictly necessary for interpretation. If you plot only gene expression on a UMAP, you are interpreting regions of that plot. This is at least a bit better in that you can focus on clusters after your first overlayed plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2257:200,deployability,cluster,clusters,200,"I guess that's not strictly necessary for interpretation. If you plot only gene expression on a UMAP, you are interpreting regions of that plot. This is at least a bit better in that you can focus on clusters after your first overlayed plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2257
https://github.com/scverse/scanpy/issues/2258:1802,availability,down,downstream,1802,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:68,deployability,updat,updates,68,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:185,deployability,updat,updated,185,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:334,deployability,version,version,334,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:371,deployability,version,version,371,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:495,deployability,version,versions,495,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:334,integrability,version,version,334,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:371,integrability,version,version,371,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:495,integrability,version,versions,495,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:211,interoperability,platform,platform,211,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:334,modifiability,version,version,334,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:371,modifiability,version,version,371,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:495,modifiability,version,versions,495,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:1774,modifiability,paramet,parameter,1774,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:1356,reliability,doe,doesn,1356,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:68,safety,updat,updates,68,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:185,safety,updat,updated,185,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:431,safety,except,except,431,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:1322,safety,except,except,1322,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:68,security,updat,updates,68,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:185,security,updat,updated,185,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3. """""". One of the scanpy versions introduced a bug that was recently fixed, . where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. . I believe it is because adata.var.index is being stored as the . adata.uns ""gene_symbol"" output for tl.rank_genes_groups, . and pl.rank_genes_groups correctly looks for the adata.var.index, . but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2. """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],. gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:. # Try 1.7.2 way first. ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""). except:. # Use gene names if that doesn't work. gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(). ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,. gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:283,deployability,resourc,resources,283,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:283,energy efficiency,resourc,resources,283,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:62,performance,cach,cache,62,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:283,performance,resourc,resources,283,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:30,safety,test,test,30,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:283,safety,resourc,resources,283,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:157,security,ssl,ssl,157,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:193,security,ssl,ssl,193,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:30,testability,test,test,30,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2258:283,testability,resourc,resources,283,"OK, reproducible with smaller test data:. ```py. adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad"". if not Path(adata_file).exists():. ssl._create_default_https_context = ssl._create_unverified_context. urllib.request.urlretrieve(. ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file. ). adata_full = sc.read_h5ad(adata_file). adata = ad.concat([. adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],. adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],. ], merge='unique'). adata.write(data_path / 't-cells.h5ad'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258
https://github.com/scverse/scanpy/issues/2259:65,energy efficiency,current,current,65,IMHO you can only do it by fitting a UMAP object separately. The current implementation does only return the embedding given a certain knn graph (also built with UMAP).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:88,reliability,doe,does,88,IMHO you can only do it by fitting a UMAP object separately. The current implementation does only return the embedding given a certain knn graph (also built with UMAP).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:24,modifiability,exten,extended,24,"Yes, then this could be extended in scanpy. I imagine this would be very useful for reference mapping visualisations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:102,usability,visual,visualisations,102,"Yes, then this could be extended in scanpy. I imagine this would be very useful for reference mapping visualisations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:153,energy efficiency,load,loadings,153,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:137,integrability,compon,components,137,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:137,interoperability,compon,components,137,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:114,modifiability,deco,decomposed,114,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:137,modifiability,compon,components,137,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:153,performance,load,loadings,153,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:182,security,sign,sign,182,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,deployability,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:37,energy efficiency,current,current,37,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,integrability,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,interoperability,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,modifiability,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,reliability,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,security,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:129,testability,integr,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:107,usability,user,user,107,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,deployability,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,integrability,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:327,integrability,transform,transform,327,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,interoperability,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:327,interoperability,transform,transform,327,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,modifiability,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:127,performance,time,time,127,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:245,performance,time,time,245,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,reliability,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,security,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:174,testability,integr,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,deployability,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,deployability,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,integrability,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:212,integrability,transform,transform,212,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:252,integrability,transform,transform,252,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:360,integrability,batch,batch,360,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,integrability,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,interoperability,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:212,interoperability,transform,transform,212,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:252,interoperability,transform,transform,252,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,interoperability,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,modifiability,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,modifiability,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:85,performance,time,time,85,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:360,performance,batch,batch,360,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,reliability,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,reliability,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,security,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,security,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:14,testability,integr,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:413,testability,integr,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:262,usability,visual,visualization,262,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:82,energy efficiency,model,model,82,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:126,energy efficiency,model,model,126,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:265,energy efficiency,model,models,265,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:181,integrability,transform,transformed,181,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:221,integrability,transform,transform,221,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:181,interoperability,transform,transformed,181,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:221,interoperability,transform,transform,221,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:82,security,model,model,82,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:126,security,model,model,126,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:265,security,model,models,265,"Right, but don't such methods require the same genes to be used so that a trained model (e.g. a VAE) can be applied? Once the model generates the new embedding, those can surely be transformed using the same UMAP. . UMAP.transform() can only be used (as all fitted models) if the feature set of new data matches the ones used for UMAP.fit().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:308,availability,avail,available,308,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:139,deployability,contain,contains,139,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,deployability,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:482,energy efficiency,current,currently,482,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,integrability,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:298,integrability,transform,transform,298,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,interoperability,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:298,interoperability,transform,transform,298,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,modifiability,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,reliability,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:308,reliability,availab,available,308,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:392,reliability,doe,does,392,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:308,safety,avail,available,308,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,security,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:308,security,availab,available,308,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:154,testability,integr,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2260:61,security,team,team,61,I have the same question. Would someone from the development team help take a look at this issue? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2260:66,usability,help,help,66,I have the same question. Would someone from the development team help take a look at this issue? Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2260:164,integrability,filter,filtering,164,"> @Zethson, do you think we should move those to scverse? Do you mean to this page? https://scverse.org/learn/. Or generally all of them? We might require stronger filtering options then because with all tools combined we would have a lot of vignettes. Edit oh wait: I had no idea that we had this scanpy_usage repository. My answer is yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2260:311,integrability,repositor,repository,311,"> @Zethson, do you think we should move those to scverse? Do you mean to this page? https://scverse.org/learn/. Or generally all of them? We might require stronger filtering options then because with all tools combined we would have a lot of vignettes. Edit oh wait: I had no idea that we had this scanpy_usage repository. My answer is yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2260:311,interoperability,repositor,repository,311,"> @Zethson, do you think we should move those to scverse? Do you mean to this page? https://scverse.org/learn/. Or generally all of them? We might require stronger filtering options then because with all tools combined we would have a lot of vignettes. Edit oh wait: I had no idea that we had this scanpy_usage repository. My answer is yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2260:104,usability,learn,learn,104,"> @Zethson, do you think we should move those to scverse? Do you mean to this page? https://scverse.org/learn/. Or generally all of them? We might require stronger filtering options then because with all tools combined we would have a lot of vignettes. Edit oh wait: I had no idea that we had this scanpy_usage repository. My answer is yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2260:204,usability,tool,tools,204,"> @Zethson, do you think we should move those to scverse? Do you mean to this page? https://scverse.org/learn/. Or generally all of them? We might require stronger filtering options then because with all tools combined we would have a lot of vignettes. Edit oh wait: I had no idea that we had this scanpy_usage repository. My answer is yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260
https://github.com/scverse/scanpy/issues/2261:39,modifiability,layer,layers,39,"before normolization, you can do adata.layers['counts']=adata.X.copy() to add the counts of all genes to the layers.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:109,modifiability,layer,layers,109,"before normolization, you can do adata.layers['counts']=adata.X.copy() to add the counts of all genes to the layers.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:138,deployability,API,API,138,"@gtca has wanted this too (e.g. https://github.com/scverse/anndata/issues/706). @gtca, we've talked about implementing this, and what the API could look like. Did we write more than the referenced issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:138,integrability,API,API,138,"@gtca has wanted this too (e.g. https://github.com/scverse/anndata/issues/706). @gtca, we've talked about implementing this, and what the API could look like. Did we write more than the referenced issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:138,interoperability,API,API,138,"@gtca has wanted this too (e.g. https://github.com/scverse/anndata/issues/706). @gtca, we've talked about implementing this, and what the API could look like. Did we write more than the referenced issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:698,deployability,log,lognorm,698,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;. - [ ] use `.X` to reference `.layers[._X_layer]`;. - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;. - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. . The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:255,modifiability,layer,layer,255,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;. - [ ] use `.X` to reference `.layers[._X_layer]`;. - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;. - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. . The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:309,modifiability,layer,layers,309,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;. - [ ] use `.X` to reference `.layers[._X_layer]`;. - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;. - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. . The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:698,safety,log,lognorm,698,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;. - [ ] use `.X` to reference `.layers[._X_layer]`;. - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;. - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. . The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:698,security,log,lognorm,698,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;. - [ ] use `.X` to reference `.layers[._X_layer]`;. - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;. - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. . The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:698,testability,log,lognorm,698,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;. - [ ] use `.X` to reference `.layers[._X_layer]`;. - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;. - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. . The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:49,modifiability,layer,layers,49,Related question - is it necessary to do. `adata.layers['counts']=adata.X.copy()`. or is:. `adata.layers['counts']=adata.X` sufficient?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:98,modifiability,layer,layers,98,Related question - is it necessary to do. `adata.layers['counts']=adata.X.copy()`. or is:. `adata.layers['counts']=adata.X` sufficient?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:331,modifiability,layer,layers,331,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:360,modifiability,layer,layers,360,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:399,modifiability,layer,layer,399,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:435,modifiability,layer,layer,435,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:455,modifiability,layer,layers,455,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:462,modifiability,layer,layer,462,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:581,modifiability,layer,layer,581,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:617,modifiability,layer,layer,617,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:634,modifiability,layer,layers,634,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:641,modifiability,layer,layer,641,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py. import numpy as np. from anndata import AnnData. from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)). # => 5393766064. adata.layers[""X""] = adata.X. adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):. print(f""{layer}: "", id(adata.layers[layer])). # => X: 5393766064. # => X_copy: 5393773552. print(adata.X[0, 0]). # => -1.5721827. adata.X[0, 0] = 0.0. for layer in (""X"", ""X_copy""):. print(f""{layer}: "", adata.layers[layer][0, 0]). # => X: 0.0. # => X_copy: -1.5721827. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:34,availability,down,downstream,34,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:45,availability,operat,operations,45,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:185,deployability,log,log,185,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:69,modifiability,layer,layers,69,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:227,modifiability,layer,layers,227,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:278,modifiability,layer,layers,278,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:185,safety,log,log,185,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:149,security,modif,modified,149,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:185,security,log,log,185,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:298,security,ident,identically,298,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:185,testability,log,log,185,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:413,usability,behavi,behavior,413,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:228,integrability,messag,message,228,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:22,interoperability,specif,specific,22,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:228,interoperability,messag,message,228,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:96,modifiability,layer,layers,96,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:147,modifiability,layer,layers,147,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:167,security,ident,identically,167,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:250,testability,understand,understand,250,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:44,usability,behavi,behavior,44,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:239,usability,help,helpful,239,"@cdpolt, is there are specific change (""new behavior"") you're referring to? > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:53,safety,prevent,preventing,53,"@gtca Yes I now see the point about explicit copying preventing the further modification, thanks, that's perfect",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:53,security,preven,preventing,53,"@gtca Yes I now see the point about explicit copying preventing the further modification, thanks, that's perfect",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2261:76,security,modif,modification,76,"@gtca Yes I now see the point about explicit copying preventing the further modification, thanks, that's perfect",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261
https://github.com/scverse/scanpy/issues/2265:2,deployability,instal,installed,2,I installed the latest Scanpy 1.9.1 `conda install -c conda-forge scanpy python-igraph leidenalg`. And the bug was gone!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:43,deployability,instal,install,43,I installed the latest Scanpy 1.9.1 `conda install -c conda-forge scanpy python-igraph leidenalg`. And the bug was gone!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2266:51,interoperability,format,formatting,51,@wubaosheng could you please ensure that the issue formatting is right? Then things are easier for us to read and discuss. Do you have more details about the dataset? Is there a way to provide it to us?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2266
https://github.com/scverse/scanpy/issues/2270:8,interoperability,share,share,8,Can you share some plots of what you're generating? I can't reproduce what you're describing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2270
https://github.com/scverse/scanpy/pull/2272:288,integrability,messag,message,288,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2272:288,interoperability,messag,message,288,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2272:335,reliability,doe,doesn,335,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2272:311,safety,test,tests,311,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2272:358,safety,test,tests,358,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2272:311,testability,test,tests,311,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2272:358,testability,test,tests,358,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff. -X_pca = np.zeros((X.shape[0], n_comps), X.dtype). +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype). ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2274:5,availability,cluster,clustering,5,"Some clustering results are changing, but I can't reproduce locally 😢. So I'm going to chuck a bandaid on it, since I expect default clustering results to change when we use igraph leiden.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:133,availability,cluster,clustering,133,"Some clustering results are changing, but I can't reproduce locally 😢. So I'm going to chuck a bandaid on it, since I expect default clustering results to change when we use igraph leiden.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:5,deployability,cluster,clustering,5,"Some clustering results are changing, but I can't reproduce locally 😢. So I'm going to chuck a bandaid on it, since I expect default clustering results to change when we use igraph leiden.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:133,deployability,cluster,clustering,133,"Some clustering results are changing, but I can't reproduce locally 😢. So I'm going to chuck a bandaid on it, since I expect default clustering results to change when we use igraph leiden.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2277:272,deployability,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:272,integrability,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:272,interoperability,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:272,modifiability,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:272,reliability,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:111,safety,hot,hotfix,111,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:272,security,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2277:272,testability,integr,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2280:36,usability,close,closed,36,@ivirshup what's needed to get this closed? Can I help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280
https://github.com/scverse/scanpy/pull/2280:50,usability,help,help,50,@ivirshup what's needed to get this closed? Can I help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280
https://github.com/scverse/scanpy/pull/2280:24,safety,test,test,24,I think it just needs a test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280
https://github.com/scverse/scanpy/pull/2280:24,testability,test,test,24,I think it just needs a test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280
https://github.com/scverse/scanpy/issues/2281:157,modifiability,pac,package,157,"People outside of biology have used anndata, so we don't want to tie it to bioconda. Could one point whatever generates the bioconda images at a conda-forge package?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:226,deployability,version,version,226,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:301,deployability,version,version,301,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:319,deployability,instal,installed,319,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:347,deployability,version,version,347,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:226,integrability,version,version,226,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:301,integrability,version,version,301,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:347,integrability,version,version,347,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:226,modifiability,version,version,226,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:301,modifiability,version,version,301,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:347,modifiability,version,version,347,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:219,deployability,contain,container,219,"> I'm afraid it's the bioconda CI that generates them. AFAICT it's using [`mulled`](https://github.com/BioContainers/mulled), so it should be very straight forward. galaxy also uses this, so there's probably an anndata container being generated there. Also there is [no mention of `singularity` in the bioconda docs](https://bioconda.github.io/search.html?q=singularity).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:49,deployability,contain,containers,49,"tbh, I don't know what generates the singularity containers, but as far as I can tell they are a mirror of the biocontainers: https://depot.galaxyproject.org/singularity/. The latest versions of scanpy and anndata there are the same as on bioconda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:183,deployability,version,versions,183,"tbh, I don't know what generates the singularity containers, but as far as I can tell they are a mirror of the biocontainers: https://depot.galaxyproject.org/singularity/. The latest versions of scanpy and anndata there are the same as on bioconda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:183,integrability,version,versions,183,"tbh, I don't know what generates the singularity containers, but as far as I can tell they are a mirror of the biocontainers: https://depot.galaxyproject.org/singularity/. The latest versions of scanpy and anndata there are the same as on bioconda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:183,modifiability,version,versions,183,"tbh, I don't know what generates the singularity containers, but as far as I can tell they are a mirror of the biocontainers: https://depot.galaxyproject.org/singularity/. The latest versions of scanpy and anndata there are the same as on bioconda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:881,availability,mainten,maintenance,881,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:42,deployability,version,version,42,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:60,deployability,instal,installed,60,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:343,deployability,automat,automation,343,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:437,deployability,build,build-bot,437,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:518,deployability,version,versions,518,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:688,deployability,automat,automation,688,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:843,deployability,contain,container,843,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:659,energy efficiency,core,core,659,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:42,integrability,version,version,42,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:518,integrability,version,versions,518,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:800,integrability,coupl,couple,800,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:168,interoperability,specif,specified,168,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:751,interoperability,standard,standardised,751,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:42,modifiability,version,version,42,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:518,modifiability,version,versions,518,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:800,modifiability,coupl,couple,800,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:893,performance,overhead,overhead,893,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:881,reliability,mainten,maintenance,881,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:569,safety,primary channel,primary channel,569,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:343,testability,automat,automation,343,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:688,testability,automat,automation,688,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:800,testability,coupl,couple,800,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:609,usability,tool,tools,609,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:764,usability,workflow,workflows,764,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1013,usability,help,help,1013,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:. https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:101,deployability,contain,containers,101,I'm pretty against moving back to bioconda. I would be more up for adding a job somewhere that makes containers for various scverse tools. It looks like BioContainers would make sense as a place for this? In theory it could just be adding lines to `packages.tsv` in [BioContainers/mulled](https://github.com/BioContainers/mulled). Maybe we should ask someone over there how this could be done?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:249,modifiability,pac,packages,249,I'm pretty against moving back to bioconda. I would be more up for adding a job somewhere that makes containers for various scverse tools. It looks like BioContainers would make sense as a place for this? In theory it could just be adding lines to `packages.tsv` in [BioContainers/mulled](https://github.com/BioContainers/mulled). Maybe we should ask someone over there how this could be done?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:132,usability,tool,tools,132,I'm pretty against moving back to bioconda. I would be more up for adding a job somewhere that makes containers for various scverse tools. It looks like BioContainers would make sense as a place for this? In theory it could just be adding lines to `packages.tsv` in [BioContainers/mulled](https://github.com/BioContainers/mulled). Maybe we should ask someone over there how this could be done?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:17,deployability,build,build,17,"Btw. ```. mulled-build build --singularity 'anndata=0.8.0,scanpy=1.9.1'. ```. Seems to work fine",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:23,deployability,build,build,23,"Btw. ```. mulled-build build --singularity 'anndata=0.8.0,scanpy=1.9.1'. ```. Seems to work fine",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:38,deployability,contain,container,38,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:106,deployability,contain,containers,106,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:165,deployability,contain,containers,165,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:296,deployability,contain,container,296,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:483,deployability,contain,containers,483,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:519,deployability,updat,updates,519,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:612,deployability,updat,updated,612,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:601,integrability,event,eventually,601,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:98,modifiability,pac,package-containers,98,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:157,modifiability,pac,package-containers,157,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:590,modifiability,pac,package,590,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:624,modifiability,maintain,maintained,624,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:519,safety,updat,updates,519,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:612,safety,updat,updated,612,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:624,safety,maintain,maintained,624,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:519,security,updat,updates,519,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:612,security,updat,updated,612,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:720,security,control,control,720,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:720,testability,control,control,720,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:20,usability,tool,tools,20,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:680,usability,tool,tools,680,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:795,usability,tool,tool,795,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1212,availability,mainten,maintenance,1212,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:40,deployability,contain,container,40,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:108,deployability,contain,containers,108,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:167,deployability,contain,containers,167,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:213,deployability,depend,dependencies,213,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:487,deployability,releas,release,487,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:510,deployability,releas,release,510,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:521,deployability,automat,automatically,521,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:570,deployability,depend,depend,570,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:687,deployability,depend,dependents,687,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:790,deployability,depend,dependencies,790,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1381,deployability,instal,install,1381,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1488,deployability,build,build,1488,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1545,deployability,build,build,1545,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1803,deployability,build,building,1803,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1685,energy efficiency,model,model,1685,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:213,integrability,depend,dependencies,213,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:570,integrability,depend,depend,570,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:687,integrability,depend,dependents,687,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:790,integrability,depend,dependencies,790,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:944,interoperability,registr,registries,944,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1273,interoperability,registr,registry,1273,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1347,interoperability,registr,registries,1347,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1817,interoperability,distribut,distributing,1817,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:100,modifiability,pac,package-containers,100,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:159,modifiability,pac,package-containers,159,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:213,modifiability,depend,dependencies,213,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:557,modifiability,pac,packages,557,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:570,modifiability,depend,depend,570,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:592,modifiability,pac,packages,592,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:687,modifiability,depend,dependents,687,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:790,modifiability,depend,dependencies,790,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:936,modifiability,pac,package,936,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1179,modifiability,pac,packages,1179,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1830,modifiability,pac,packages,1830,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:340,reliability,Pra,Practically,340,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1212,reliability,mainten,maintenance,1212,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:213,safety,depend,dependencies,213,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:570,safety,depend,depend,570,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:687,safety,depend,dependents,687,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:790,safety,depend,dependencies,790,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1685,security,model,model,1685,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1756,security,sign,significantly,1756,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:213,testability,depend,dependencies,213,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:521,testability,automat,automatically,521,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:570,testability,depend,depend,570,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:687,testability,depend,dependents,687,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:790,testability,depend,dependencies,790,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:22,usability,tool,tools,22,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:359,usability,document,documentation,359,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1044,usability,tool,tooling,1044,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1203,usability,tool,tooling,1203,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1306,usability,clear,clear,1306,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1779,usability,tool,tooling,1779,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome? ### Practically. * The documentation for bioconda has been incomplete and out of date for years. * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*. * All of our dependencies are on conda-forge. * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:42,deployability,contain,container,42,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:110,deployability,contain,containers,110,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:169,deployability,contain,containers,169,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:220,deployability,depend,dependencies,220,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:349,deployability,contain,containers,349,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:220,integrability,depend,dependencies,220,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:102,modifiability,pac,package-containers,102,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:161,modifiability,pac,package-containers,161,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:220,modifiability,depend,dependencies,220,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:341,modifiability,pac,package-containers,341,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:220,safety,depend,dependencies,220,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:220,testability,depend,dependencies,220,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:24,usability,tool,tools,24,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). >. > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:499,availability,down,downside,499,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:468,deployability,contain,containers,468,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:535,deployability,updat,update,535,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:571,deployability,releas,release,571,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:88,interoperability,specif,specific,88,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:280,interoperability,registr,registries,280,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:272,modifiability,pac,package,272,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:460,modifiability,pac,package-containers,460,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:535,safety,updat,update,535,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:535,security,updat,update,535,"At this point I'm not a big fan of moving back to bioconda either. * anndata is not bio-specific and should go to conda-forge anyway. * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else? probably because bioconda predates conda-forge? . > Just saw there's already a pr for this! > . > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:112,deployability,contain,containers,112,> Just saw there's already a pr for this! > . > * [adding scanpy conda-forge mulled BioContainers/multi-package-containers#2209](https://github.com/BioContainers/multi-package-containers/pull/2209). I’ve opened it earlier today as a workaround. But don’t know if the file is properly defined.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:176,deployability,contain,containers,176,> Just saw there's already a pr for this! > . > * [adding scanpy conda-forge mulled BioContainers/multi-package-containers#2209](https://github.com/BioContainers/multi-package-containers/pull/2209). I’ve opened it earlier today as a workaround. But don’t know if the file is properly defined.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:104,modifiability,pac,package-containers,104,> Just saw there's already a pr for this! > . > * [adding scanpy conda-forge mulled BioContainers/multi-package-containers#2209](https://github.com/BioContainers/multi-package-containers/pull/2209). I’ve opened it earlier today as a workaround. But don’t know if the file is properly defined.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:168,modifiability,pac,package-containers,168,> Just saw there's already a pr for this! > . > * [adding scanpy conda-forge mulled BioContainers/multi-package-containers#2209](https://github.com/BioContainers/multi-package-containers/pull/2209). I’ve opened it earlier today as a workaround. But don’t know if the file is properly defined.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:156,deployability,contain,containers,156,"@bgruening, is there any recommended way to generate Biocontainers for packages that are only on conda-forge? . Would it be ok to hijack the `multi-package-containers` for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:71,modifiability,pac,packages,71,"@bgruening, is there any recommended way to generate Biocontainers for packages that are only on conda-forge? . Would it be ok to hijack the `multi-package-containers` for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:148,modifiability,pac,package-containers,148,"@bgruening, is there any recommended way to generate Biocontainers for packages that are only on conda-forge? . Would it be ok to hijack the `multi-package-containers` for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:343,availability,down,downside,343,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:379,deployability,updat,update,379,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:415,deployability,releas,release,415,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:30,interoperability,registr,registries,30,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:199,interoperability,registr,registry,199,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:22,modifiability,pac,package,22,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:297,modifiability,design decis,design decisions,297,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:379,safety,updat,update,379,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:379,security,updat,update,379,> > Why have separate package registries for biology vs everything else? >. > probably because bioconda predates conda-forge? That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:73,deployability,contain,containers,73,"@grst yes it is ok to use https://github.com/BioContainers/multi-package-containers/ for conda-forge packages, many people do this. There is some misinformation in this thread, let me know if there is interest in resolving them. . My short comment here as conda-forge and bioconda admin is: use conda-forge whenever you (the community) can justify the extra efforts, it has the cleaner but is more ""expensive"" build-system.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:410,deployability,build,build-system,410,"@grst yes it is ok to use https://github.com/BioContainers/multi-package-containers/ for conda-forge packages, many people do this. There is some misinformation in this thread, let me know if there is interest in resolving them. . My short comment here as conda-forge and bioconda admin is: use conda-forge whenever you (the community) can justify the extra efforts, it has the cleaner but is more ""expensive"" build-system.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:65,modifiability,pac,package-containers,65,"@grst yes it is ok to use https://github.com/BioContainers/multi-package-containers/ for conda-forge packages, many people do this. There is some misinformation in this thread, let me know if there is interest in resolving them. . My short comment here as conda-forge and bioconda admin is: use conda-forge whenever you (the community) can justify the extra efforts, it has the cleaner but is more ""expensive"" build-system.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:101,modifiability,pac,packages,101,"@grst yes it is ok to use https://github.com/BioContainers/multi-package-containers/ for conda-forge packages, many people do this. There is some misinformation in this thread, let me know if there is interest in resolving them. . My short comment here as conda-forge and bioconda admin is: use conda-forge whenever you (the community) can justify the extra efforts, it has the cleaner but is more ""expensive"" build-system.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:215,deployability,releas,release,215,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:180,performance,memor,memories,180,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:326,reliability,doe,does,326,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:180,usability,memor,memories,180,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:274,usability,experien,experience,274,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:362,integrability,Messag,Message,362,". No worries, feel free to rename :) Monday, 20 June 2022, 09:11PM +02:00 from Isaac Virshup ***@***.*** :. ***@***.*** , would it be fair to retitle this something like ""Generate BioContainer images"", or should that be a separate issue? >—. >Reply to this email directly, view it on GitHub , or unsubscribe . >You are receiving this because you were mentioned. Message ID: @ github . com>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:362,interoperability,Messag,Message,362,". No worries, feel free to rename :) Monday, 20 June 2022, 09:11PM +02:00 from Isaac Virshup ***@***.*** :. ***@***.*** , would it be fair to retitle this something like ""Generate BioContainer images"", or should that be a separate issue? >—. >Reply to this email directly, view it on GitHub , or unsubscribe . >You are receiving this because you were mentioned. Message ID: @ github . com>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:901,deployability,releas,release,901,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:924,deployability,releas,release,924,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:935,deployability,automat,automatically,935,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1024,deployability,depend,depend,1024,"really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1142,deployability,depend,dependents,1142,"ew recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1487,deployability,version,versions,1487,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1640,deployability,depend,dependencies,1640,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1930,deployability,depend,dependencies,1930,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1024,integrability,depend,depend,1024,"really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1142,integrability,depend,dependents,1142,"ew recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1487,integrability,version,versions,1487,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1640,integrability,depend,dependencies,1640,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1930,integrability,depend,dependencies,1930,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:2187,integrability,topic,topic,2187,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:346,interoperability,specif,specific,346,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:84,modifiability,maintain,maintain,84,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:180,modifiability,concern,concerns,180,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:525,modifiability,maintain,maintain,525,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1011,modifiability,pac,packages,1011,"ce, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1024,modifiability,depend,depend,1024,"really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1046,modifiability,pac,packages,1046,"forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1142,modifiability,depend,dependents,1142,"ew recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1487,modifiability,version,versions,1487,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1499,modifiability,pac,packages,1499,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1640,modifiability,depend,dependencies,1640,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1930,modifiability,depend,dependencies,1930,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:270,performance,memor,memorizing,270,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:409,reliability,doe,does,409,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:973,reliability,doe,does,973,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:69,safety,compl,complicated,69,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:84,safety,maintain,maintain,84,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:525,safety,maintain,maintain,525,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:767,safety,valid,valid,767,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1024,safety,depend,depend,1024,"really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1142,safety,depend,dependents,1142,"ew recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1640,safety,depend,dependencies,1640,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1930,safety,depend,dependencies,1930,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:69,security,compl,complicated,69,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:180,testability,concern,concerns,180,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:935,testability,automat,automatically,935,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1024,testability,depend,depend,1024,"really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1142,testability,depend,dependents,1142,"ew recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1640,testability,depend,dependencies,1640,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1930,testability,depend,dependencies,1930,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:7,usability,experien,experience,7,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:270,usability,memor,memorizing,270,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:640,usability,document,documentation,640,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:787,usability,help,help,787,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1712,usability,tool,tools,1712,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1749,usability,tool,tools,1749,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1841,usability,help,help,1841,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:1973,usability,tool,tool,1973,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:2117,usability,learn,learning,2117,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda. Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2282:17,deployability,instal,installation,17,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:76,deployability,instal,installation,76,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:149,deployability,instal,installed,149,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:171,deployability,instal,install,171,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:110,interoperability,distribut,distributed,110,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2284:278,deployability,api,api,278,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:383,deployability,api,api,383,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:278,integrability,api,api,278,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:383,integrability,api,api,383,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:278,interoperability,api,api,278,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:383,interoperability,api,api,383,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:531,usability,close,close,531,"what do you mean superimposed? Noevertheless, I'd suggest you to take a look at squidpy functionality: . here: [squidpy.readthedocs.io/en/latest/examples.html#plotting](https://squidpy.readthedocs.io/en/latest/examples.html#plotting) and here: [squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter](https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter). feel free to open an issue directly in squidpy for spatial plotting requests. I'll close this now for the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2286:50,availability,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,performance,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,safety,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,usability,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,availability,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,performance,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,safety,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:50,usability,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:19,usability,help,help,19,"Please go here for help with your problem https://github.com/bhargavchippada/forceatlas2/issues/32. We can‘t help you here, as we aren’t the `forceatlas2` developers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2286:109,usability,help,help,109,"Please go here for help with your problem https://github.com/bhargavchippada/forceatlas2/issues/32. We can‘t help you here, as we aren’t the `forceatlas2` developers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2288:58,usability,behavi,behavior,58,Would you be interested in filing up a PR to improve this behavior? I'd encourage you to do so. Thank you!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288
https://github.com/scverse/scanpy/issues/2288:33,availability,ping,ping,33,"Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288
https://github.com/scverse/scanpy/issues/2290:490,usability,user,user-images,490,"You can actually already do this by changing the order of your categorical, e.g.:. ```python. adata = sc.datasets.pbmc3k_processed(). # plot default:. sc.pl.umap(adata, color=""louvain""). # reorder categories alphabetically. adata.obs.louvain = adata.obs.louvain.cat.reorder_categories(. sorted(adata.obs.louvain.cat.categories). ). # plot with new category order:. sc.pl.umap(adata, color=""louvain""). ```. Which gives:. <img width=""390"" alt=""Screenshot 2022-09-24 at 19 07 31"" src=""https://user-images.githubusercontent.com/32548783/192110283-af0d14c5-0d79-4ecd-96ff-c079f5743887.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:142,reliability,doe,does,142,"We could add it to the function docstring, not sure where would be best. `color` or `legend_loc` @Zethson ? Or better to add an argument that does the reordering for you ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:701,energy efficiency,load,loading,701,"> You can actually already do this by changing the order of your categorical, e.g.:. > . > ```python. > adata = sc.datasets.pbmc3k_processed(). > # plot default:. > sc.pl.umap(adata, color=""louvain""). > # reorder categories alphabetically. > adata.obs.louvain = adata.obs.louvain.cat.reorder_categories(. > sorted(adata.obs.louvain.cat.categories). > ). > # plot with new category order:. > sc.pl.umap(adata, color=""louvain""). > ```. > . > Which gives: <img alt=""Screenshot 2022-09-24 at 19 07 31"" width=""390"" src=""https://user-images.githubusercontent.com/32548783/192110283-af0d14c5-0d79-4ecd-96ff-c079f5743887.png"">. Thanks for your replay. Here, I changed the order of categorical as below:. # 0. loading data. adata = sc.datasets.pbmc3k_processed(). # 1. plot default:. sc.pl.umap(adata, color=""louvain""). # 2. show the default order of categories:. adata.obs['louvain'].cat.categories. # **Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 3. reorder categories as customize. adata.obs['batch_3rd'].cat.reorder_categories(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], inplace=True, ordered=True). adata.obs['batch_3rd'].cat.categories. # **Index(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 4. plot with new category order:. sc.pl.umap(adata, color=""louvain"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:701,performance,load,loading,701,"> You can actually already do this by changing the order of your categorical, e.g.:. > . > ```python. > adata = sc.datasets.pbmc3k_processed(). > # plot default:. > sc.pl.umap(adata, color=""louvain""). > # reorder categories alphabetically. > adata.obs.louvain = adata.obs.louvain.cat.reorder_categories(. > sorted(adata.obs.louvain.cat.categories). > ). > # plot with new category order:. > sc.pl.umap(adata, color=""louvain""). > ```. > . > Which gives: <img alt=""Screenshot 2022-09-24 at 19 07 31"" width=""390"" src=""https://user-images.githubusercontent.com/32548783/192110283-af0d14c5-0d79-4ecd-96ff-c079f5743887.png"">. Thanks for your replay. Here, I changed the order of categorical as below:. # 0. loading data. adata = sc.datasets.pbmc3k_processed(). # 1. plot default:. sc.pl.umap(adata, color=""louvain""). # 2. show the default order of categories:. adata.obs['louvain'].cat.categories. # **Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 3. reorder categories as customize. adata.obs['batch_3rd'].cat.reorder_categories(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], inplace=True, ordered=True). adata.obs['batch_3rd'].cat.categories. # **Index(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 4. plot with new category order:. sc.pl.umap(adata, color=""louvain"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:523,usability,user,user-images,523,"> You can actually already do this by changing the order of your categorical, e.g.:. > . > ```python. > adata = sc.datasets.pbmc3k_processed(). > # plot default:. > sc.pl.umap(adata, color=""louvain""). > # reorder categories alphabetically. > adata.obs.louvain = adata.obs.louvain.cat.reorder_categories(. > sorted(adata.obs.louvain.cat.categories). > ). > # plot with new category order:. > sc.pl.umap(adata, color=""louvain""). > ```. > . > Which gives: <img alt=""Screenshot 2022-09-24 at 19 07 31"" width=""390"" src=""https://user-images.githubusercontent.com/32548783/192110283-af0d14c5-0d79-4ecd-96ff-c079f5743887.png"">. Thanks for your replay. Here, I changed the order of categorical as below:. # 0. loading data. adata = sc.datasets.pbmc3k_processed(). # 1. plot default:. sc.pl.umap(adata, color=""louvain""). # 2. show the default order of categories:. adata.obs['louvain'].cat.categories. # **Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 3. reorder categories as customize. adata.obs['batch_3rd'].cat.reorder_categories(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], inplace=True, ordered=True). adata.obs['batch_3rd'].cat.categories. # **Index(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 4. plot with new category order:. sc.pl.umap(adata, color=""louvain"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:1080,usability,custom,customize,1080,"> You can actually already do this by changing the order of your categorical, e.g.:. > . > ```python. > adata = sc.datasets.pbmc3k_processed(). > # plot default:. > sc.pl.umap(adata, color=""louvain""). > # reorder categories alphabetically. > adata.obs.louvain = adata.obs.louvain.cat.reorder_categories(. > sorted(adata.obs.louvain.cat.categories). > ). > # plot with new category order:. > sc.pl.umap(adata, color=""louvain""). > ```. > . > Which gives: <img alt=""Screenshot 2022-09-24 at 19 07 31"" width=""390"" src=""https://user-images.githubusercontent.com/32548783/192110283-af0d14c5-0d79-4ecd-96ff-c079f5743887.png"">. Thanks for your replay. Here, I changed the order of categorical as below:. # 0. loading data. adata = sc.datasets.pbmc3k_processed(). # 1. plot default:. sc.pl.umap(adata, color=""louvain""). # 2. show the default order of categories:. adata.obs['louvain'].cat.categories. # **Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 3. reorder categories as customize. adata.obs['batch_3rd'].cat.reorder_categories(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], inplace=True, ordered=True). adata.obs['batch_3rd'].cat.categories. # **Index(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 4. plot with new category order:. sc.pl.umap(adata, color=""louvain"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:144,reliability,doe,does,144,"> We could add it to the function docstring, not sure where would be best. `color` or `legend_loc` @Zethson ? Or better to add an argument that does the reordering for you ? I think `legend_loc` would be better. @Zethson",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:209,availability,state,statement,209,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:209,integrability,state,statement,209,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:509,integrability,sub,submit,509,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:53,modifiability,paramet,parameter,53,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:81,usability,interact,interacting,81,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:306,usability,custom,customize,306,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:396,usability,document,documentation,396,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2290:549,usability,guidanc,guidance,549,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:. 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order. 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290
https://github.com/scverse/scanpy/issues/2291:44,usability,help,help,44,"Hi @lingxincheng08,. did the above solution help you resolve the issue? :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2291
https://github.com/scverse/scanpy/issues/2291:8,usability,close,close,8,"We will close the issue for now, hopefully you obtained the expected behaviour :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2291
https://github.com/scverse/scanpy/issues/2291:69,usability,behavi,behaviour,69,"We will close the issue for now, hopefully you obtained the expected behaviour :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2291
https://github.com/scverse/scanpy/issues/2292:88,availability,cluster,clusters,88,"I have found the issue, or at least the reason why the nodes don't appear. . Within the clusters that do not show up, there is at least one cell that has a value of np.Inf in the column ""dpt_pseudotime"". As a results the mean (in this case ""dpt_pseudotime"") value across the cluster is also np.Inf. . So as a related question would be: is it normal/expected to have np.Inf values from the scanpy pseudotime analysis?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2292:275,availability,cluster,cluster,275,"I have found the issue, or at least the reason why the nodes don't appear. . Within the clusters that do not show up, there is at least one cell that has a value of np.Inf in the column ""dpt_pseudotime"". As a results the mean (in this case ""dpt_pseudotime"") value across the cluster is also np.Inf. . So as a related question would be: is it normal/expected to have np.Inf values from the scanpy pseudotime analysis?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2292:88,deployability,cluster,clusters,88,"I have found the issue, or at least the reason why the nodes don't appear. . Within the clusters that do not show up, there is at least one cell that has a value of np.Inf in the column ""dpt_pseudotime"". As a results the mean (in this case ""dpt_pseudotime"") value across the cluster is also np.Inf. . So as a related question would be: is it normal/expected to have np.Inf values from the scanpy pseudotime analysis?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2292:275,deployability,cluster,cluster,275,"I have found the issue, or at least the reason why the nodes don't appear. . Within the clusters that do not show up, there is at least one cell that has a value of np.Inf in the column ""dpt_pseudotime"". As a results the mean (in this case ""dpt_pseudotime"") value across the cluster is also np.Inf. . So as a related question would be: is it normal/expected to have np.Inf values from the scanpy pseudotime analysis?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2293:25,integrability,sub,subset,25,Could you please paste a subset of the file? The header + 2 lines or so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2293
https://github.com/scverse/scanpy/issues/2293:8,usability,close,close,8,"We will close the issue for now, hopefully you obtained the expected behaviour :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2293
https://github.com/scverse/scanpy/issues/2293:69,usability,behavi,behaviour,69,"We will close the issue for now, hopefully you obtained the expected behaviour :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2293
https://github.com/scverse/scanpy/pull/2294:136,usability,close,close,136,@ivirshup I just noticed that you opened https://github.com/scverse/scanpy/pull/2283 to solve this issue. Let me know if you want me to close this one.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2294
https://github.com/scverse/scanpy/pull/2295:389,availability,error,error,389,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:1246,integrability,Messag,Message,1246,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:129,interoperability,compatib,compatible,129,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:417,interoperability,compatib,compatible,417,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:445,interoperability,format,format,445,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:1246,interoperability,Messag,Message,1246,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:77,modifiability,variab,variable,77,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:389,performance,error,error,389,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:534,reliability,doe,does,534,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:389,safety,error,error,389,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:1133,security,auth,auth,1133,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:1226,security,auth,authored,1226,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:389,usability,error,error,389,"Hi,. The issues I was mostly running into were that when saving the anndata. variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this. action. So, I had to either remove pheno_jaccard_ig from the anndata object. and then save it as h5ad or convert it to a sparse matrix. This also. happened with a few other functions I tried on the anndata object, and I. kept getting the error ""this function is not compatible with COO matrix. format"", always talking about pheno_jaccard_ig. Therefore, since a sparse. matrix object does not have any problems with the functions I was running. on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes. sense to circumvent any of those issues I was getting before. I hope this makes sense. Thank you,. Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>. wrote:. > Hi,. >. > could you please provide more details? What issues did you run into? >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>. > . > You are receiving this because you authored the thread.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2296:337,deployability,releas,release,337,"@giovp looking at this again, it seems you drop the mixed up columns anyway (https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:289,usability,clarit,clarity,289,"@giovp looking at this again, it seems you drop the mixed up columns anyway (https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:301,usability,help,help,301,"@giovp looking at this again, it seems you drop the mixed up columns anyway (https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:395,deployability,releas,release,395,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:583,deployability,version,version,583,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:583,integrability,version,version,583,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:485,interoperability,coordinat,coordinates,485,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:583,modifiability,version,version,583,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:347,usability,clarit,clarity,347,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:359,usability,help,help,359,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:131,deployability,releas,release,131,"> @giovp, should this change happen in scanpy or squidpy? I would make it happen in both and deprecate this function from the next release (as well as all the other spatial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:397,deployability,releas,release,397,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:601,deployability,version,version,601,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:601,integrability,version,version,601,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:499,interoperability,coordinat,coordinates,499,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:601,modifiability,version,version,601,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:349,usability,clarit,clarity,349,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:361,usability,help,help,361,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. > . > Hi @stephenwilliams22 ,. > . > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. > . > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:21,deployability,updat,update,21,@giovp do we have an update on merging this yet? Anything left on my end?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:21,safety,updat,update,21,@giovp do we have an update on merging this yet? Anything left on my end?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:21,security,updat,update,21,@giovp do we have an update on merging this yet? Anything left on my end?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:79,safety,test,tests,79,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:174,safety,test,test,174,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:79,testability,test,tests,79,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:174,testability,test,test,174,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:177,deployability,version,version,177,"from discussing with @stephenwilliams22 this made me think there shouldn't be changes with column names yet it seems like it is, . > > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? > . > Yes, this is correct. we actually might have had similar reports in squidpy as well, let me ask @LLehren for support, will probably have to fix it in squidpy side as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:177,integrability,version,version,177,"from discussing with @stephenwilliams22 this made me think there shouldn't be changes with column names yet it seems like it is, . > > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? > . > Yes, this is correct. we actually might have had similar reports in squidpy as well, let me ask @LLehren for support, will probably have to fix it in squidpy side as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:177,modifiability,version,version,177,"from discussing with @stephenwilliams22 this made me think there shouldn't be changes with column names yet it seems like it is, . > > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? > . > Yes, this is correct. we actually might have had similar reports in squidpy as well, let me ask @LLehren for support, will probably have to fix it in squidpy side as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:396,usability,support,support,396,"from discussing with @stephenwilliams22 this made me think there shouldn't be changes with column names yet it seems like it is, . > > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same? > . > Yes, this is correct. we actually might have had similar reports in squidpy as well, let me ask @LLehren for support, will probably have to fix it in squidpy side as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/issues/2297:22,availability,error,error,22,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:29,deployability,Updat,Updating,29,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:22,performance,error,error,22,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:22,safety,error,error,22,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:29,safety,Updat,Updating,29,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:29,security,Updat,Updating,29,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:22,usability,error,error,22,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:59,usability,help,help,59,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,deployability,updat,update,39,I was having the same problem. **conda update anndata** solved my problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,safety,updat,update,39,I was having the same problem. **conda update anndata** solved my problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,security,updat,update,39,I was having the same problem. **conda update anndata** solved my problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:24,availability,error,error,24,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:31,deployability,Updat,Updating,31,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:24,performance,error,error,24,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:24,safety,error,error,24,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:31,safety,Updat,Updating,31,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:31,security,Updat,Updating,31,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:24,usability,error,error,24,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:61,usability,help,help,61,> Encountering the same error. Updating h5py did not seem to help. Any advice on this? This might be useful to you:. https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:136,availability,error,error,136,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:77,deployability,upgrad,upgrade,77,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:142,integrability,messag,message,142,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:142,interoperability,messag,message,142,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:77,modifiability,upgrad,upgrade,77,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:136,performance,error,error,136,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:136,safety,error,error,136,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:136,usability,error,error,136,@brianpenghe Hi may I consult how you resolved the problem? The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:9,availability,reboot,rebooted,9,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:77,availability,error,error,77,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:170,availability,error,error,170,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:392,availability,error,errors,392,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:35,deployability,updat,updating,35,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:267,deployability,updat,updated,267,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:362,deployability,manag,managed,362,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:420,deployability,updat,updating,420,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:156,energy efficiency,load,loading,156,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:362,energy efficiency,manag,managed,362,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:117,interoperability,share,share,117,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:255,modifiability,pac,package,255,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:77,performance,error,error,77,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:156,performance,load,loading,156,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:170,performance,error,error,170,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:392,performance,error,errors,392,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:35,safety,updat,updating,35,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:77,safety,error,error,77,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:170,safety,error,error,170,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:267,safety,updat,updated,267,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:362,safety,manag,managed,362,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:392,safety,error,errors,392,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:420,safety,updat,updating,420,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:35,security,updat,updating,35,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:267,security,updat,updated,267,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:420,security,updat,updating,420,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:77,usability,error,error,77,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:170,usability,error,error,170,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:392,usability,error,errors,392,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading? OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:165,availability,error,error,165,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:45,deployability,instal,installed,45,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:179,deployability,instal,install,179,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:252,deployability,updat,updated,252,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:283,interoperability,conflict,conflict,283,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:195,modifiability,pac,package,195,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:244,modifiability,pac,package,244,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:165,performance,error,error,165,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:165,safety,error,error,165,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:252,safety,updat,updated,252,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:252,security,updat,updated,252,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:165,usability,error,error,165,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:126,availability,down,download,126,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:47,deployability,version,version,47,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:139,deployability,instal,install,139,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:47,integrability,version,version,47,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:47,modifiability,version,version,47,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:167,availability,error,error,167,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:47,deployability,instal,installed,47,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:181,deployability,instal,install,181,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:254,deployability,updat,updated,254,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:285,interoperability,conflict,conflict,285,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:197,modifiability,pac,package,197,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:246,modifiability,pac,package,246,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:167,performance,error,error,167,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:167,safety,error,error,167,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:254,safety,updat,updated,254,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:254,security,updat,updated,254,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:167,usability,error,error,167,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:53,availability,error,error,53,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:358,availability,Error,Error,358,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:391,availability,error,error,391,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:53,performance,error,error,53,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:358,performance,Error,Error,358,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:391,performance,error,error,391,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:53,safety,error,error,53,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:358,safety,Error,Error,358,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:391,safety,error,error,391,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:53,usability,error,error,53,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:240,usability,learn,learn,240,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:358,usability,Error,Error,358,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:391,usability,error,error,391,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`. Error:. `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:158,availability,error,error,158,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:158,performance,error,error,158,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:164,reliability,doe,does,164,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:158,safety,error,error,158,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:158,usability,error,error,158,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:72,deployability,version,version,72,> anndata==0.9.2. Anndata is currently at 0.10.4. Please use the newest version if you want to check if a bug still exists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:29,energy efficiency,current,currently,29,> anndata==0.9.2. Anndata is currently at 0.10.4. Please use the newest version if you want to check if a bug still exists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:72,integrability,version,version,72,> anndata==0.9.2. Anndata is currently at 0.10.4. Please use the newest version if you want to check if a bug still exists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:72,modifiability,version,version,72,> anndata==0.9.2. Anndata is currently at 0.10.4. Please use the newest version if you want to check if a bug still exists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,availability,error,error,39,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:689,availability,error,error,689,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:45,integrability,messag,message,45,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:695,integrability,messag,message,695,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:45,interoperability,messag,message,45,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:73,interoperability,mismatch,mismatch,73,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:499,interoperability,mismatch,mismatch,499,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:695,interoperability,messag,message,695,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:720,interoperability,mismatch,mismatch,720,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:842,interoperability,mismatch,mismatch,842,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1115,interoperability,mismatch,mismatch,1115,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,performance,error,error,39,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:689,performance,error,error,689,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,safety,error,error,39,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:689,safety,error,error,689,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1091,safety,except,exception,1091,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:39,usability,error,error,39,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:238,usability,hint,hint,238,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:689,usability,error,error,689,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1140,usability,user,users,1140,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python. ### Have a look at the indices. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. print(key). print(obs_matrix.index). print(adata.obs_names). print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:. for key, obs_matrix in adata.obsm.items():. if hasattr(obs_matrix, ""index""):. obs_matrix.index = adata.obs_names. ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:52,deployability,version,version,52,@edoumazane this can no longer happen in the newest version: https://github.com/scverse/anndata/blob/0024b82c0f161daed3b40b4712c2ab13d84e5804/src/anndata/_io/specs/methods.py#L848-L852,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:52,integrability,version,version,52,@edoumazane this can no longer happen in the newest version: https://github.com/scverse/anndata/blob/0024b82c0f161daed3b40b4712c2ab13d84e5804/src/anndata/_io/specs/methods.py#L848-L852,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:52,modifiability,version,version,52,@edoumazane this can no longer happen in the newest version: https://github.com/scverse/anndata/blob/0024b82c0f161daed3b40b4712c2ab13d84e5804/src/anndata/_io/specs/methods.py#L848-L852,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2301:154,deployability,updat,updated,154,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:84,integrability,sub,submit,84,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:154,safety,updat,updated,154,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:154,security,updat,updated,154,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:38,usability,feedback,feedback,38,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:122,usability,document,documentations,122,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:172,usability,support,support,172,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:196,usability,help,help,196,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:226,availability,state,states,226,There is also a small typo in the [`tl.tsne`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.tsne.html) documentation. I think the return type should be. `X_tsne np.ndarray (adata.obsm dtype float)`. right now it states that the array is stored at adata.obs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:226,integrability,state,states,226,There is also a small typo in the [`tl.tsne`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.tsne.html) documentation. I think the return type should be. `X_tsne np.ndarray (adata.obsm dtype float)`. right now it states that the array is stored at adata.obs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:117,usability,document,documentation,117,There is also a small typo in the [`tl.tsne`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.tsne.html) documentation. I think the return type should be. `X_tsne np.ndarray (adata.obsm dtype float)`. right now it states that the array is stored at adata.obs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:261,availability,ping,ping,261,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:162,deployability,updat,updated,162,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:92,integrability,sub,submit,92,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:162,safety,updat,updated,162,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:162,security,updat,updated,162,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:46,usability,feedback,feedback,46,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:130,usability,document,documentations,130,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:180,usability,support,support,180,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:204,usability,help,help,204,"> hi @yotamcons ,. > . > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. > . > Thank you! Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2305:36,deployability,version,version,36,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:73,deployability,updat,update,73,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:90,deployability,version,version,90,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:36,integrability,version,version,36,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:90,integrability,version,version,90,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:4,modifiability,pac,pacificoceanmist,4,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:36,modifiability,version,version,36,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:90,modifiability,version,version,90,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:73,safety,updat,update,73,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:73,security,updat,update,73,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:8,usability,close,close,8,"We will close the issue for now, hopefully you obtained the expected behaviour :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:69,usability,behavi,behaviour,69,"We will close the issue for now, hopefully you obtained the expected behaviour :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2306:19,deployability,instal,install,19,hi @dm8000 did you install it with pip or conda? I would try to re installl with either of the two methods.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:67,deployability,instal,installl,67,hi @dm8000 did you install it with pip or conda? I would try to re installl with either of the two methods.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:33,deployability,instal,installation,33,Hello @giovp. I used pip for the installation,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:121,deployability,version,version,121,"Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:121,integrability,version,version,121,"Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:121,modifiability,version,version,121,"Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:123,deployability,version,version,123,"> Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version? the version would be 3.9.2. and I did try importing it on clean environment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:136,deployability,version,version,136,"> Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version? the version would be 3.9.2. and I did try importing it on clean environment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:123,integrability,version,version,123,"> Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version? the version would be 3.9.2. and I did try importing it on clean environment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:136,integrability,version,version,136,"> Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version? the version would be 3.9.2. and I did try importing it on clean environment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:123,modifiability,version,version,123,"> Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version? the version would be 3.9.2. and I did try importing it on clean environment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:136,modifiability,version,version,136,"> Could you please ensure that you are attempting to import scanpy in a fresh, clean environment? Also, what's your Python version? the version would be 3.9.2. and I did try importing it on clean environment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:8,reliability,doe,does,8,"@dm8000 does this issue still persist? If yes, please reopen. I'd then also like to see the full `pip list` output",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2309:112,interoperability,coordinat,coordinates,112,What would the purpose be there? To set the order of the cell type labels in the legend? Or to manually set the coordinates of the labels in the plot?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:100,integrability,sub,subplots,100,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:232,integrability,sub,subplots,232,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:458,integrability,sub,subplots,458,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:119,interoperability,specif,specify,119,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:420,interoperability,specif,specify,420,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:136,modifiability,variab,variables,136,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2309:369,modifiability,variab,variable,369,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309
https://github.com/scverse/scanpy/issues/2310:55,deployability,version,versions,55,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:151,deployability,upgrad,upgrade,151,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:163,deployability,version,version,163,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:55,integrability,version,versions,55,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:163,integrability,version,version,163,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:55,modifiability,version,versions,55,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:151,modifiability,upgrad,upgrade,151,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:163,modifiability,version,version,163,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best. Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2311:161,modifiability,variab,variable,161,"Thanks for your comment Jason! Don't you think the sentence before the one you quoted:. ""If None, mpl.rcParams[""axes.prop_cycle""] is used unless the categorical variable already has colors stored in adata.uns[""{var}_colors""]."". in combination with the default being ""None"" would make this clear?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:289,usability,clear,clear,289,"Thanks for your comment Jason! Don't you think the sentence before the one you quoted:. ""If None, mpl.rcParams[""axes.prop_cycle""] is used unless the categorical variable already has colors stored in adata.uns[""{var}_colors""]."". in combination with the default being ""None"" would make this clear?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:112,interoperability,specif,specified,112,"Hey Lisa! I think I can see that connection now. But I had initially interpreted the ""If provided"" to mean if I specified, but seems like it also applies to the case where `mpl.rcParams[""axes.prop_cycle""]` is provided for me. Instead of ""If provided, values of adata.uns[""{var}_colors""] will be set."" I would find it more clear to say something like ""adata.uns[""{var}_colors""] will be set if not already stored""",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:322,usability,clear,clear,322,"Hey Lisa! I think I can see that connection now. But I had initially interpreted the ""If provided"" to mean if I specified, but seems like it also applies to the case where `mpl.rcParams[""axes.prop_cycle""]` is provided for me. Instead of ""If provided, values of adata.uns[""{var}_colors""] will be set."" I would find it more clear to say something like ""adata.uns[""{var}_colors""] will be set if not already stored""",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2313:293,availability,cluster,clusters,293,"Hi @alexlenail,. The issue here is that colour maps with this amount of distinct colours just don't really exist. They could be created, but even if created you would not be able to distinguish the colours by eye. A solution that I have used in this scenario is to colour only a subset of the clusters in any single plot and label the rest as ""other"". You can do that by just making new `adata.obs` columns with the new label. Something like (untested code):. ```. list_of_cts = ['Exc L5-6 FEZF2 CFTR', 'Exc L5-6 FEZF2 FILIP1L', 'Exc L5-6 FEZF2 IFNG-AS1']. adata.obs['ct_group1'] = [ct if ct in list_of_cts else ""Other"" for ct in adata.obs['Spearman_BICCN_M1_classification']]. sc.pl.umap(adata, 'ct_group1'). ```. You could just add a loop around that with the cell types you want to colour together. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:293,deployability,cluster,clusters,293,"Hi @alexlenail,. The issue here is that colour maps with this amount of distinct colours just don't really exist. They could be created, but even if created you would not be able to distinguish the colours by eye. A solution that I have used in this scenario is to colour only a subset of the clusters in any single plot and label the rest as ""other"". You can do that by just making new `adata.obs` columns with the new label. Something like (untested code):. ```. list_of_cts = ['Exc L5-6 FEZF2 CFTR', 'Exc L5-6 FEZF2 FILIP1L', 'Exc L5-6 FEZF2 IFNG-AS1']. adata.obs['ct_group1'] = [ct if ct in list_of_cts else ""Other"" for ct in adata.obs['Spearman_BICCN_M1_classification']]. sc.pl.umap(adata, 'ct_group1'). ```. You could just add a loop around that with the cell types you want to colour together. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:279,integrability,sub,subset,279,"Hi @alexlenail,. The issue here is that colour maps with this amount of distinct colours just don't really exist. They could be created, but even if created you would not be able to distinguish the colours by eye. A solution that I have used in this scenario is to colour only a subset of the clusters in any single plot and label the rest as ""other"". You can do that by just making new `adata.obs` columns with the new label. Something like (untested code):. ```. list_of_cts = ['Exc L5-6 FEZF2 CFTR', 'Exc L5-6 FEZF2 FILIP1L', 'Exc L5-6 FEZF2 IFNG-AS1']. adata.obs['ct_group1'] = [ct if ct in list_of_cts else ""Other"" for ct in adata.obs['Spearman_BICCN_M1_classification']]. sc.pl.umap(adata, 'ct_group1'). ```. You could just add a loop around that with the cell types you want to colour together. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:250,modifiability,scenario,scenario,250,"Hi @alexlenail,. The issue here is that colour maps with this amount of distinct colours just don't really exist. They could be created, but even if created you would not be able to distinguish the colours by eye. A solution that I have used in this scenario is to colour only a subset of the clusters in any single plot and label the rest as ""other"". You can do that by just making new `adata.obs` columns with the new label. Something like (untested code):. ```. list_of_cts = ['Exc L5-6 FEZF2 CFTR', 'Exc L5-6 FEZF2 FILIP1L', 'Exc L5-6 FEZF2 IFNG-AS1']. adata.obs['ct_group1'] = [ct if ct in list_of_cts else ""Other"" for ct in adata.obs['Spearman_BICCN_M1_classification']]. sc.pl.umap(adata, 'ct_group1'). ```. You could just add a loop around that with the cell types you want to colour together. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:812,usability,help,helps,812,"Hi @alexlenail,. The issue here is that colour maps with this amount of distinct colours just don't really exist. They could be created, but even if created you would not be able to distinguish the colours by eye. A solution that I have used in this scenario is to colour only a subset of the clusters in any single plot and label the rest as ""other"". You can do that by just making new `adata.obs` columns with the new label. Something like (untested code):. ```. list_of_cts = ['Exc L5-6 FEZF2 CFTR', 'Exc L5-6 FEZF2 FILIP1L', 'Exc L5-6 FEZF2 IFNG-AS1']. adata.obs['ct_group1'] = [ct if ct in list_of_cts else ""Other"" for ct in adata.obs['Spearman_BICCN_M1_classification']]. sc.pl.umap(adata, 'ct_group1'). ```. You could just add a loop around that with the cell types you want to colour together. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:143,availability,cluster,clusters,143,"Hi @LuckyMD . I don't think the colors don't need to each be too distinguishable from one another, just so long as there aren't two contiguous clusters with indistinguishable colors. As an analogy, geographic maps often only use a few colors, but no two sides of a border are ever colored the same. I think scanpy should provide this feature, perhaps with a warning. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:143,deployability,cluster,clusters,143,"Hi @LuckyMD . I don't think the colors don't need to each be too distinguishable from one another, just so long as there aren't two contiguous clusters with indistinguishable colors. As an analogy, geographic maps often only use a few colors, but no two sides of a border are ever colored the same. I think scanpy should provide this feature, perhaps with a warning. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:311,modifiability,maintain,maintained,311,"Some thoughts on implementation:. This refers to the graph colouring problem. We could implement something like this in scanpy. We'd need a graph that represents ""neighbouring"" in the UMAP. An (imperfect) approximation of this could be a PAGA graph. I quickly found a few bits of code, but not really in a nice maintained library as far as I can tell:. * code snippet for greedy graph colouring: https://python.plainenglish.io/solve-graph-coloring-problem-with-greedy-algorithm-and-python-6661ab4154bd. * [This](https://github.com/stefanutti/maps-coloring-python) is a map colouring algorithm, which would require graphs that can be put into a 2D layout (which should be the case for UMAPs, but not necessarily for PAGA graphs): blog intro: https://four-color-theorem.org/introduction/. Overall... ideally we'd have a well maintained library for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:823,modifiability,maintain,maintained,823,"Some thoughts on implementation:. This refers to the graph colouring problem. We could implement something like this in scanpy. We'd need a graph that represents ""neighbouring"" in the UMAP. An (imperfect) approximation of this could be a PAGA graph. I quickly found a few bits of code, but not really in a nice maintained library as far as I can tell:. * code snippet for greedy graph colouring: https://python.plainenglish.io/solve-graph-coloring-problem-with-greedy-algorithm-and-python-6661ab4154bd. * [This](https://github.com/stefanutti/maps-coloring-python) is a map colouring algorithm, which would require graphs that can be put into a 2D layout (which should be the case for UMAPs, but not necessarily for PAGA graphs): blog intro: https://four-color-theorem.org/introduction/. Overall... ideally we'd have a well maintained library for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:311,safety,maintain,maintained,311,"Some thoughts on implementation:. This refers to the graph colouring problem. We could implement something like this in scanpy. We'd need a graph that represents ""neighbouring"" in the UMAP. An (imperfect) approximation of this could be a PAGA graph. I quickly found a few bits of code, but not really in a nice maintained library as far as I can tell:. * code snippet for greedy graph colouring: https://python.plainenglish.io/solve-graph-coloring-problem-with-greedy-algorithm-and-python-6661ab4154bd. * [This](https://github.com/stefanutti/maps-coloring-python) is a map colouring algorithm, which would require graphs that can be put into a 2D layout (which should be the case for UMAPs, but not necessarily for PAGA graphs): blog intro: https://four-color-theorem.org/introduction/. Overall... ideally we'd have a well maintained library for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:823,safety,maintain,maintained,823,"Some thoughts on implementation:. This refers to the graph colouring problem. We could implement something like this in scanpy. We'd need a graph that represents ""neighbouring"" in the UMAP. An (imperfect) approximation of this could be a PAGA graph. I quickly found a few bits of code, but not really in a nice maintained library as far as I can tell:. * code snippet for greedy graph colouring: https://python.plainenglish.io/solve-graph-coloring-problem-with-greedy-algorithm-and-python-6661ab4154bd. * [This](https://github.com/stefanutti/maps-coloring-python) is a map colouring algorithm, which would require graphs that can be put into a 2D layout (which should be the case for UMAPs, but not necessarily for PAGA graphs): blog intro: https://four-color-theorem.org/introduction/. Overall... ideally we'd have a well maintained library for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:214,deployability,depend,dependency,214,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:214,integrability,depend,dependency,214,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:214,modifiability,depend,dependency,214,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:29,performance,network,networkx,29,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:94,performance,network,networkx,94,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:141,performance,network,networkx,141,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:203,performance,Network,Networkx,203,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:214,safety,depend,dependency,214,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:29,security,network,networkx,29,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:94,security,network,networkx,94,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:141,security,network,networkx,141,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:203,security,Network,Networkx,203,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:214,testability,depend,dependency,214,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:42,usability,document,documentation,42,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:161,availability,cluster,clusters,161,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:313,availability,down,down,313,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:161,deployability,cluster,clusters,161,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:252,usability,support,support,252,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:82,availability,cluster,clusters,82,150 colours will not help imo. Typically very large colour maps make neighbouring clusters indistinguishable...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:82,deployability,cluster,clusters,82,150 colours will not help imo. Typically very large colour maps make neighbouring clusters indistinguishable...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:21,usability,help,help,21,150 colours will not help imo. Typically very large colour maps make neighbouring clusters indistinguishable...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:185,availability,cluster,clusters,185,"Hi @alexlenail . Re . > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray. ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:285,availability,cluster,clusters,285,"Hi @alexlenail . Re . > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray. ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:185,deployability,cluster,clusters,185,"Hi @alexlenail . Re . > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray. ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:285,deployability,cluster,clusters,285,"Hi @alexlenail . Re . > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray. ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:241,security,access,access,241,"Hi @alexlenail . Re . > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray. ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2314:98,integrability,compon,components,98,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:147,integrability,batch,batch,147,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:98,interoperability,compon,components,98,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:370,interoperability,interoperab,interoperable,370,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:98,modifiability,compon,components,98,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:370,modifiability,interop,interoperable,370,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:147,performance,batch,batch,147,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:12,reliability,doe,does,12,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:112,safety,input,input,112,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:168,security,modif,modified,168,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:112,usability,input,input,112,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:130,energy efficiency,load,loadings,130,Thanks for getting back @esrice! . I think I see now -- does that mean I should multiply the `X_pca_harmony` by the _original_ PC loadings to get the imputed counts?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:130,performance,load,loadings,130,Thanks for getting back @esrice! . I think I see now -- does that mean I should multiply the `X_pca_harmony` by the _original_ PC loadings to get the imputed counts?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:56,reliability,doe,does,56,Thanks for getting back @esrice! . I think I see now -- does that mean I should multiply the `X_pca_harmony` by the _original_ PC loadings to get the imputed counts?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:165,availability,down,downstream,165,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:121,integrability,compon,components,121,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:121,interoperability,compon,components,121,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:121,modifiability,compon,components,121,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,deployability,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,integrability,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,interoperability,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,modifiability,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,reliability,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,security,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:37,testability,integr,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2315:170,deployability,continu,continuous,170,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:41,modifiability,variab,variable,41,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:181,modifiability,variab,variables,181,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:64,performance,time,time,64,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:215,reliability,doe,does,215,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:144,security,modif,modifying,144,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:316,deployability,observ,observations,316,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:63,integrability,messag,message,63,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:143,integrability,Filter,Filtering,143,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:63,interoperability,messag,message,63,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:265,performance,memor,memory,265,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:397,performance,memor,memory,397,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:433,safety,compl,complete,433,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:433,security,compl,complete,433,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:316,testability,observ,observations,316,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:199,usability,prefer,prefer,199,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:265,usability,memor,memory,265,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:397,usability,memor,memory,397,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:. - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations. - Creating a copy so that I don't use a view. Same issue about the memory. - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2316:200,deployability,api,api,200,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:281,deployability,updat,updated,281,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:289,deployability,version,version,289,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:200,integrability,api,api,200,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:289,integrability,version,version,289,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:200,interoperability,api,api,200,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:289,modifiability,version,version,289,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:281,safety,updat,updated,281,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:281,security,updat,updated,281,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:360,usability,close,close,360,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter. they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2317:296,safety,test,testing,296,"Hey Simon,. Thanks for your suggestions. I agree that 1 would be very useful indeed and would be worth implementing.. this is not in the making yet is it @ivirshup ? As to point 2, this would statistically be difficult as you're comparing a group to itself, which I think should not be done when testing differences between two groups.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:296,testability,test,testing,296,"Hey Simon,. Thanks for your suggestions. I agree that 1 would be very useful indeed and would be worth implementing.. this is not in the making yet is it @ivirshup ? As to point 2, this would statistically be difficult as you're comparing a group to itself, which I think should not be done when testing differences between two groups.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2318:98,deployability,updat,update,98,"I just encountered the same issue, using scanpy 1.9.1 and matplotlib 3.5.3. I think it's a recent update to matbplotlib which broke something here. When I rolled back matplotlib to 3.5.2, it ran fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:155,deployability,roll,rolled,155,"I just encountered the same issue, using scanpy 1.9.1 and matplotlib 3.5.3. I think it's a recent update to matbplotlib which broke something here. When I rolled back matplotlib to 3.5.2, it ran fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:98,safety,updat,update,98,"I just encountered the same issue, using scanpy 1.9.1 and matplotlib 3.5.3. I think it's a recent update to matbplotlib which broke something here. When I rolled back matplotlib to 3.5.2, it ran fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:98,security,updat,update,98,"I just encountered the same issue, using scanpy 1.9.1 and matplotlib 3.5.3. I think it's a recent update to matbplotlib which broke something here. When I rolled back matplotlib to 3.5.2, it ran fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:51,reliability,doe,does,51,I tried matplotlib 3.5.2 but didn't work but 3.1.3 does but doesn't put out multiple plot in one go,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:60,reliability,doe,doesn,60,I tried matplotlib 3.5.2 but didn't work but 3.1.3 does but doesn't put out multiple plot in one go,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3617,deployability,updat,updated,3617,"sSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:6084,deployability,updat,updated,6084,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:4074,energy efficiency,cloud,cloudpickle,4074,".py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:1044,integrability,compon,components,1044," issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3120,integrability,wrap,wrapper,3120,", 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3204,integrability,messag,message,3204," k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:1044,interoperability,compon,components,1044," issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3120,interoperability,wrapper,wrapper,3120,", 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3204,interoperability,messag,message,3204," k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:422,modifiability,pac,packages,422,"Hi Any suggestions on this? I am getting the same issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:845,modifiability,pac,packages,845,"Hi Any suggestions on this? I am getting the same issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:1044,modifiability,compon,components,1044," issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:1068,modifiability,layer,layer,1068,"r 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax, use_gridspec, **kw). ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:1729,modifiability,pac,packages,1729,". 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2340 NON_COLORBAR_KEYS = ['fraction', 'pad', 'shrink', 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:1970,modifiability,pac,packages,1970,"edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2340 NON_COLORBAR_KEYS = ['fraction', 'pad', 'shrink', 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:2399,modifiability,pac,packages,2399,"ical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2340 NON_COLORBAR_KEYS = ['fraction', 'pad', 'shrink', 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""para",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:2742,modifiability,pac,packages,2742,"ib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:2343, in Figure.colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2340 NON_COLORBAR_KEYS = ['fraction', 'pad', 'shrink', 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3043,modifiability,pac,packages,3043,"x, use_gridspec, **kw). 2340 NON_COLORBAR_KEYS = ['fraction', 'pad', 'shrink', 'aspect', 'anchor',. 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2345 self.sca(current_ax). 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_norm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3322,modifiability,paramet,parameter,3322,"46 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3399,modifiability,paramet,parameter,3399,"ges/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs). 1729 cb = ColorbarPatch(cax, mappable, **kwargs). 1730 else:. -> 1731 cb = Colorbar(cax, mappable, **kwargs). 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:4222,modifiability,deco,decorator,4222,"name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:4883,modifiability,pac,packaging,4883,. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:5938,modifiability,pac,packaged,5938,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:218,safety,Input,Input,218,"Hi Any suggestions on this? I am getting the same issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3617,safety,updat,updated,3617,"sSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:6084,safety,updat,updated,6084,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3617,security,updat,updated,3617,"sSM.connect('changed', cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:4002,security,certif,certifi,4002,"nda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psuti",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:5477,security,soc,socks,5477,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:6064,security,Session,Session,6064,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:6084,security,updat,updated,6084,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:183,testability,Trace,Traceback,183,"Hi Any suggestions on this? I am getting the same issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:218,usability,Input,Input,218,"Hi Any suggestions on this? I am getting the same issue scanpy 1.9.2 (or 1.9.1): . Thanks. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [7], in <cell line: 1>(). ----> 1 sc.pl.umap(adata,color=['EPCAM', 'CD79A', 'CD3D', 'NKG7', 'VFW', 'ACTB', 'ACTA2', 'TPSAB1', 'CD68'], size=12). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:669, in umap(adata, **kwargs). 610 @_wraps_plot_scatter. 611 @_doc_params(. 612 adata_color_etc=doc_adata_color_etc,. (...). 616 ). 617 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:. 618 """"""\. 619 Scatter plot in UMAP basis. 620 . (...). 667 tl.umap. 668 """""". --> 669 return embedding(adata, 'umap', **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py:452, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 438 _add_categorical_legend(. 439 ax,. 440 color_source_vector,. (...). 449 multi_panel=bool(grid),. 450 ). 451 elif colorbar_loc is not None:. --> 452 pl.colorbar(. 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 456 if return_fig is True:. 457 return fig. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/pyplot.py:2194, in colorbar(mappable, cax, ax, **kw). 2192 if ax is None:. 2193 ax = gca(). -> 2194 ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kw). 2195 return ret. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/figure.py:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3638,usability,confirm,confirm,3638,", cb.update_normal). 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:3764,usability,learn,learn,3764,"bar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs). 1223 if isinstance(mappable, martist.Artist):. 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs). 445 if len(args) > idx:. 446 warn_deprecated(. 447 since, message=""Passing the %(name)s %(obj_type)s "". 448 ""positionally is deprecated since Matplotlib %(since)s; the "". 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'. ```. I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged. ```. scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6. -----. anndata 0.8.0. scanpy 1.9.2. -----. PIL 9.0.1. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.06.15. cffi 1.14.5. charset_normalizer 2.0.12. chex 0.1.5. cloudpickle 2.2.0. colorama 0.4.4. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:5616,usability,tool,toolz,5616,"ib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2022.11.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. executing 0.8.3. flax 0.6.1. fsspec 2022.11.0. google NA. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.9. ipykernel 6.9.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.24. jaxlib 0.3.24. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. kiwisolver 1.3.2. leidenalg 0.8.9. llvmlite 0.38.0. louvain 0.7.1. markupsafe 2.1.1. matplotlib 3.3.2. matplotlib_inline NA. ml_collections NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numexpr 2.8.0. numpy 1.21.5. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.27. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2021.3. requests 2.27.1. rich NA. scipy 1.8.0. scrublet NA. scvi 0.19.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.9.3. setuptools_scm NA. six 1.16.0. sklearn 0.23.2. socks 1.7.1. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tensorboard 2.10.1. texttable 1.6.4. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.11.0. torchmetrics 0.10.2. torchvision 0.12.0. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. umap 0.5.2. urllib3 1.26.8. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 22.3.0. -----. IPython 8.1.1. jupyter_client 7.1.2. jupyter_core 4.9.2. notebook 6.4.9. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.4.0-139-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-02-26 19:13. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2321:75,integrability,filter,filtering,75,I have also seen this issue. It occurs when trying to save an object after filtering the rank_genes_groups results. I usually have to remove the filtered results for the anndata object to save properly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:145,integrability,filter,filtered,145,I have also seen this issue. It occurs when trying to save an object after filtering the rank_genes_groups results. I usually have to remove the filtered results for the anndata object to save properly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:223,integrability,sub,submit,223,This happens after using anndata.concat if I remember correctly @Mari123i ? Then better to check out the [anndata GitHub](https://github.com/scverse/anndata/blob/dbe85e55012d5d5204ab34f6d885c8964d36414d/docs/index.rst) and submit your issue there,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:45,safety,reme,remember,45,This happens after using anndata.concat if I remember correctly @Mari123i ? Then better to check out the [anndata GitHub](https://github.com/scverse/anndata/blob/dbe85e55012d5d5204ab34f6d885c8964d36414d/docs/index.rst) and submit your issue there,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:74,integrability,filter,filtering,74,@a-munoz-rojas that's solution for me! not sure what's the issue with the filtering step,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2322:36,reliability,doe,doesn,36,It seems like the relevant function doesn't include a conditional branch for this case: https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_tools/scatterplots.py#L1069,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2324:47,energy efficiency,current,current,47,@scverse/scanpy thoughts? I also feel like the current behavior is not obvious and wouldn't mind changing it to something more explicit.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:55,usability,behavi,behavior,55,@scverse/scanpy thoughts? I also feel like the current behavior is not obvious and wouldn't mind changing it to something more explicit.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:26,usability,behavi,behaviour,26,"Well, I actually like the behaviour, but I agree that setting the figure directory and file naming is not straight forward.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/pull/2326:39,modifiability,extens,extension,39,we should change to sphinx contrib bib extension,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2326
https://github.com/scverse/scanpy/pull/2326:130,energy efficiency,current,current,130,"We should switch to the sphinx bibtex thing, but IIRC I ran into difficulty here since there wasn't a standardized format for the current reference set.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2326
https://github.com/scverse/scanpy/pull/2326:102,integrability,standardiz,standardized,102,"We should switch to the sphinx bibtex thing, but IIRC I ran into difficulty here since there wasn't a standardized format for the current reference set.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2326
https://github.com/scverse/scanpy/pull/2326:102,interoperability,standard,standardized,102,"We should switch to the sphinx bibtex thing, but IIRC I ran into difficulty here since there wasn't a standardized format for the current reference set.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2326
https://github.com/scverse/scanpy/pull/2326:115,interoperability,format,format,115,"We should switch to the sphinx bibtex thing, but IIRC I ran into difficulty here since there wasn't a standardized format for the current reference set.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2326
https://github.com/scverse/scanpy/issues/2327:57,modifiability,paramet,parameter,57,"Hi @LeonHafner ,. In case you still need it, try passing parameter figsize `sc.pl.dotplot(..., figsize=(X,Y))`. It worked for me with Scanpy v1.9.6. Cheers.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2330:22,availability,down,down,22,"I've been able to pin down the culprit. Excluding this line ```adata = adata[:, adata.var.highly_variable]``` allows Leiden clustering to populate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:124,availability,cluster,clustering,124,"I've been able to pin down the culprit. Excluding this line ```adata = adata[:, adata.var.highly_variable]``` allows Leiden clustering to populate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:124,deployability,cluster,clustering,124,"I've been able to pin down the culprit. Excluding this line ```adata = adata[:, adata.var.highly_variable]``` allows Leiden clustering to populate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:815,availability,error,error,815,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:321,deployability,scale,scale,321,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:650,deployability,fail,fails,650,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:321,energy efficiency,scale,scale,321,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:260,integrability,batch,batch,260,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:321,modifiability,scal,scale,321,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:668,modifiability,paramet,parameters,668,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:260,performance,batch,batch,260,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:321,performance,scale,scale,321,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:815,performance,error,error,815,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:650,reliability,fail,fails,650,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:815,safety,error,error,815,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:815,usability,error,error,815,"This is what I'm running. ```. bcType = 'NobatchCorr'. sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'). sc.pp.log1p(adata). adata.raw = adata. sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'). #adata = adata[:, adata.var.highly_variable]. sc.pp.scale(adata, max_value=10). sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10). sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10). sc.tl.umap(adata, random_state=10). sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10). ```. The code never fails, but Leiden parameters are not present in the adata as it should. Running. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:163,integrability,sub,subsequent,163,"hi @julie-jch , . it could be the reason is that the anndata is a view. Try with . ```. adata = adata[:, adata.var.highly_variable].copy(). ```. but also, for the subsequent functions you don't need to subset by high var genes since they have arguments taht specificy whether to use them or not. E.g. pca uses it by default: . https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html#scanpy.pp.pca.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:202,integrability,sub,subset,202,"hi @julie-jch , . it could be the reason is that the anndata is a view. Try with . ```. adata = adata[:, adata.var.highly_variable].copy(). ```. but also, for the subsequent functions you don't need to subset by high var genes since they have arguments taht specificy whether to use them or not. E.g. pca uses it by default: . https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html#scanpy.pp.pca.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:258,interoperability,specif,specificy,258,"hi @julie-jch , . it could be the reason is that the anndata is a view. Try with . ```. adata = adata[:, adata.var.highly_variable].copy(). ```. but also, for the subsequent functions you don't need to subset by high var genes since they have arguments taht specificy whether to use them or not. E.g. pca uses it by default: . https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html#scanpy.pp.pca.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2331:121,energy efficiency,core,core,121,I would like to second this. I think that it makes sense that we don't duplicate functionality and responsibility of our core tools. People shouldn't be looking for spatial stuff in scanpy nor be confused if they suddenly see spatial tooling in the scanpy docs. We should always point them to the awesome squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:99,modifiability,responsibil,responsibility,99,I would like to second this. I think that it makes sense that we don't duplicate functionality and responsibility of our core tools. People shouldn't be looking for spatial stuff in scanpy nor be confused if they suddenly see spatial tooling in the scanpy docs. We should always point them to the awesome squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:126,usability,tool,tools,126,I would like to second this. I think that it makes sense that we don't duplicate functionality and responsibility of our core tools. People shouldn't be looking for spatial stuff in scanpy nor be confused if they suddenly see spatial tooling in the scanpy docs. We should always point them to the awesome squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:234,usability,tool,tooling,234,I would like to second this. I think that it makes sense that we don't duplicate functionality and responsibility of our core tools. People shouldn't be looking for spatial stuff in scanpy nor be confused if they suddenly see spatial tooling in the scanpy docs. We should always point them to the awesome squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:177,modifiability,maintain,maintained,177,I just had issues using `sc.pl.spatial` after reading spaceranger2.0.0 outputs using `sc.read_visium`. Although the issue is resolved. I am wondering if these functions are not maintained anymore. I am not familiar with Squidpy. But it seems to use these functions in its package. I would very much appreciate any clarification here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:272,modifiability,pac,package,272,I just had issues using `sc.pl.spatial` after reading spaceranger2.0.0 outputs using `sc.read_visium`. Although the issue is resolved. I am wondering if these functions are not maintained anymore. I am not familiar with Squidpy. But it seems to use these functions in its package. I would very much appreciate any clarification here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:177,safety,maintain,maintained,177,I just had issues using `sc.pl.spatial` after reading spaceranger2.0.0 outputs using `sc.read_visium`. Although the issue is resolved. I am wondering if these functions are not maintained anymore. I am not familiar with Squidpy. But it seems to use these functions in its package. I would very much appreciate any clarification here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2332:36,availability,down,downgraded,36,I just had the same issue because I downgraded my matplotlib elsewhere. So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:97,deployability,upgrad,upgrade,97,I just had the same issue because I downgraded my matplotlib elsewhere. So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:97,modifiability,upgrad,upgrade,97,I just had the same issue because I downgraded my matplotlib elsewhere. So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:69,availability,error,error,69,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:69,performance,error,error,69,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:69,safety,error,error,69,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:69,usability,error,error,69,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:103,deployability,version,version,103,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:142,deployability,upgrad,upgraded,142,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:164,deployability,version,version,164,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:103,integrability,version,version,103,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:164,integrability,version,version,164,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:103,modifiability,version,version,103,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:142,modifiability,upgrad,upgraded,142,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:164,modifiability,version,version,164,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2333:290,integrability,sub,subplots,290,"Feel free to use it. ```. import scanpy as sc. import matplotlib.pyplot as plt. import numpy as np. def split_umap(adata, split_by, ncol=2, nrow=None, **kwargs):. categories = adata.obs[split_by].cat.categories. if nrow is None:. nrow = int(np.ceil(len(categories) / ncol)). fig, axs = plt.subplots(nrow, ncol, figsize=(5*ncol, 4*nrow)). axs = axs.flatten(). for i, cat in enumerate(categories):. ax = axs[i]. sc.pl.umap(adata[adata.obs[split_by] == cat], ax=ax, show=False, title=cat, **kwargs). plt.tight_layout(). ```. `split_umap(adata, color = ['n_genes_by_counts'], split_by='type',legend_loc = ""right margin"")`. ![image](https://github.com/scverse/scanpy/assets/113491969/ecd7ec43-50af-403f-8614-27c827a0868e).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/pull/2334:0,availability,Sli,Slightly,0,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:47,deployability,API,API,47,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:135,deployability,api,api,135,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:47,integrability,API,API,47,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:135,integrability,api,api,135,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:47,interoperability,API,API,47,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:135,interoperability,api,api,135,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:0,reliability,Sli,Slightly,0,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:177,safety,compl,complete,177,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:177,security,compl,complete,177,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:19,usability,feedback,feedback,19,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:51,usability,document,documentation,51,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:104,usability,tool,tools,104,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:144,usability,tool,tools,144,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:214,usability,tool,tool,214,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:88,modifiability,pac,packages,88,"I'm just going to merge this for now, though we might just point to https://scverse.org/packages/#ecosystem in the future",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/issues/2337:105,modifiability,paramet,parameter,105,"I just encountered this as well. It seems like it's not running UMAP at all unless I give it a `maxiter` parameter. Not clear why that is, but passing an argument there worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:120,usability,clear,clear,120,"I just encountered this as well. It seems like it's not running UMAP at all unless I give it a `maxiter` parameter. Not clear why that is, but passing an argument there worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:127,deployability,instal,installation,127,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:280,deployability,version,version,280,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:372,deployability,version,versions,372,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:514,deployability,instal,installation,514,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:280,integrability,version,version,280,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:372,integrability,version,versions,372,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:280,modifiability,version,version,280,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:372,modifiability,version,versions,372,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:102,security,access,access,102,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:274,usability,learn,learn,274,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:389,usability,learn,learn,389,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2337:536,usability,learn,learn,536,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2338:25,deployability,log,logFoldChange,25,Any one can help? All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:25,safety,log,logFoldChange,25,Any one can help? All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:25,security,log,logFoldChange,25,Any one can help? All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:25,testability,log,logFoldChange,25,Any one can help? All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:12,usability,help,help,12,Any one can help? All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2339:51,availability,Down,Downgrading,51,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:37,deployability,version,version,37,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:37,integrability,version,version,37,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:37,modifiability,version,version,37,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:290,availability,Down,Downgrading,290,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:276,deployability,version,version,276,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:157,integrability,Sub,Subject,157,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:276,integrability,version,version,276,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:453,integrability,Messag,Message,453,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:453,interoperability,Messag,Message,453,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:276,modifiability,version,version,276,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:433,security,auth,authored,433,"Thanks a lot. ---Original---. From: ""James ***@***.***&gt;. Date: Thu, Sep 29, 2022 00:06 AM. To: ***@***.***&gt;;. Cc: ""Sijian ***@***.******@***.***&gt;;. Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). . I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:94,availability,failur,failure,94,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:94,deployability,fail,failure,94,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:62,performance,time,times,62,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:94,performance,failur,failure,94,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:94,reliability,fail,failure,94,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:16,usability,help,help,16,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:5,availability,error,error,5,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:72,availability,down,downgrading,72,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:463,availability,cluster,clustering,463,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:619,availability,cluster,clustering,619,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:138,deployability,depend,dependent,138,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:226,deployability,version,version,226,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:463,deployability,cluster,clustering,463,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:515,deployability,modul,modularity,515,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:619,deployability,cluster,clustering,619,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:138,integrability,depend,dependent,138,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:226,integrability,version,version,226,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:515,integrability,modular,modularity,515,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:138,modifiability,depend,dependent,138,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:226,modifiability,version,version,226,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:515,modifiability,modul,modularity,515,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:5,performance,error,error,5,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:5,safety,error,error,5,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:138,safety,depend,dependent,138,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:515,safety,modul,modularity,515,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:138,testability,depend,dependent,138,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:515,testability,modula,modularity,515,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:5,usability,error,error,5,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue. leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None). g = sc._utils.get_igraph_from_adjacency(adjacency). clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5). adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:132,deployability,version,versions,132,![image](https://github.com/scverse/scanpy/assets/56467838/aa14c824-0d86-467c-a8e3-8e8dab2cc4a7). could anyone give some advice？the versions are below. leidenalg 0.8.1. igraph 0.9.9. python-igraph 0.9.9。. Thanks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:132,integrability,version,versions,132,![image](https://github.com/scverse/scanpy/assets/56467838/aa14c824-0d86-467c-a8e3-8e8dab2cc4a7). could anyone give some advice？the versions are below. leidenalg 0.8.1. igraph 0.9.9. python-igraph 0.9.9。. Thanks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:132,modifiability,version,versions,132,![image](https://github.com/scverse/scanpy/assets/56467838/aa14c824-0d86-467c-a8e3-8e8dab2cc4a7). could anyone give some advice？the versions are below. leidenalg 0.8.1. igraph 0.9.9. python-igraph 0.9.9。. Thanks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:11,deployability,version,versions,11,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:82,deployability,updat,update,82,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:105,deployability,instal,install,105,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:11,integrability,version,versions,11,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:54,interoperability,compatib,compatible,54,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:11,modifiability,version,versions,11,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:82,safety,updat,update,82,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:82,security,updat,update,82,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:13,deployability,version,versions,13,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:84,deployability,updat,update,84,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:107,deployability,instal,install,107,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:13,integrability,version,versions,13,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:56,interoperability,compatib,compatible,56,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:13,modifiability,version,versions,13,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:84,safety,updat,update,84,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:84,security,updat,update,84,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:218,usability,help,help,218,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. > . > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2341:67,availability,error,error,67,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:2,deployability,instal,installed,2,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:67,performance,error,error,67,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:67,safety,error,error,67,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:67,usability,error,error,67,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:53,availability,down,downgrade,53,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:8,security,ident,identical,8,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:34,testability,simpl,simplest,34,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:34,usability,simpl,simplest,34,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:165,deployability,version,versions,165,"I am still facing the same issue, tries using leidenalg==0.8 and python-igraph==0.9.9 ,. Any suggestions would be of great help. #2339. ys-zong/conST#3 was the only versions that worked for me, no solution from the above worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:165,integrability,version,versions,165,"I am still facing the same issue, tries using leidenalg==0.8 and python-igraph==0.9.9 ,. Any suggestions would be of great help. #2339. ys-zong/conST#3 was the only versions that worked for me, no solution from the above worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:165,modifiability,version,versions,165,"I am still facing the same issue, tries using leidenalg==0.8 and python-igraph==0.9.9 ,. Any suggestions would be of great help. #2339. ys-zong/conST#3 was the only versions that worked for me, no solution from the above worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:123,usability,help,help,123,"I am still facing the same issue, tries using leidenalg==0.8 and python-igraph==0.9.9 ,. Any suggestions would be of great help. #2339. ys-zong/conST#3 was the only versions that worked for me, no solution from the above worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:850,deployability,updat,updated,850,"Also running into this now with pertpy. . ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.9.0. igraph 0.9.7. joblib 1.3.1. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. psutil 5.9.5. pyarrow 12.0.1. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sphinxcontrib NA. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.1+cu117. tqdm 4.65.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-6.4.3-arch1-2-x86_64-with-glibc2.37. -----. Session information updated at 2023-07-19 12:57. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:415,modifiability,pac,packaging,415,"Also running into this now with pertpy. . ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.9.0. igraph 0.9.7. joblib 1.3.1. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. psutil 5.9.5. pyarrow 12.0.1. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sphinxcontrib NA. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.1+cu117. tqdm 4.65.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-6.4.3-arch1-2-x86_64-with-glibc2.37. -----. Session information updated at 2023-07-19 12:57. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:850,safety,updat,updated,850,"Also running into this now with pertpy. . ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.9.0. igraph 0.9.7. joblib 1.3.1. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. psutil 5.9.5. pyarrow 12.0.1. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sphinxcontrib NA. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.1+cu117. tqdm 4.65.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-6.4.3-arch1-2-x86_64-with-glibc2.37. -----. Session information updated at 2023-07-19 12:57. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:830,security,Session,Session,830,"Also running into this now with pertpy. . ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.9.0. igraph 0.9.7. joblib 1.3.1. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. psutil 5.9.5. pyarrow 12.0.1. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sphinxcontrib NA. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.1+cu117. tqdm 4.65.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-6.4.3-arch1-2-x86_64-with-glibc2.37. -----. Session information updated at 2023-07-19 12:57. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:850,security,updat,updated,850,"Also running into this now with pertpy. . ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. h5py 3.9.0. igraph 0.9.7. joblib 1.3.1. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.3. psutil 5.9.5. pyarrow 12.0.1. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sphinxcontrib NA. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.1+cu117. tqdm 4.65.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0.1. -----. Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]. Linux-6.4.3-arch1-2-x86_64-with-glibc2.37. -----. Session information updated at 2023-07-19 12:57. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:42,deployability,version,version,42,@Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:42,integrability,version,version,42,@Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:50,interoperability,mismatch,mismatch,50,@Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:42,modifiability,version,version,42,@Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:44,deployability,version,version,44,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:149,deployability,updat,update,149,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:44,integrability,version,version,44,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:52,interoperability,mismatch,mismatch,52,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:44,modifiability,version,version,44,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:149,safety,updat,update,149,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:149,security,updat,update,149,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:242,usability,minim,minimum,242,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:47,deployability,instal,install,47,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:101,deployability,version,versions,101,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:114,deployability,instal,installed,114,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:101,integrability,version,versions,101,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:101,modifiability,version,versions,101,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2343:23,availability,avail,available,23,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:23,reliability,availab,available,23,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:23,safety,avail,available,23,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:23,security,availab,available,23,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/pull/2344:178,usability,document,documentation,178,"Hooray, I'm all for it! Although in all honesty I've never looked into h5py myself. I had no idea the change could be implemented so succinctly. Looks right to me based on their documentation. Very nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:10,modifiability,scal,scalar,10,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff. @@ -6,6 +6,7 @@. /another_genome/genes Dataset {343/4681}. /another_genome/indices Dataset {12/8192}. /another_genome/indptr Dataset {13/8192}. +/another_genome/scalar_dataset Dataset {SCALAR}. /another_genome/shape Dataset {2/16384}. /hg19_chr21 Group. /hg19_chr21/barcodes Dataset {12/3640}. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:351,modifiability,SCAL,SCALAR,351,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff. @@ -6,6 +6,7 @@. /another_genome/genes Dataset {343/4681}. /another_genome/indices Dataset {12/8192}. /another_genome/indptr Dataset {13/8192}. +/another_genome/scalar_dataset Dataset {SCALAR}. /another_genome/shape Dataset {2/16384}. /hg19_chr21 Group. /hg19_chr21/barcodes Dataset {12/3640}. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:40,safety,test,tests,40,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff. @@ -6,6 +6,7 @@. /another_genome/genes Dataset {343/4681}. /another_genome/indices Dataset {12/8192}. /another_genome/indptr Dataset {13/8192}. +/another_genome/scalar_dataset Dataset {SCALAR}. /another_genome/shape Dataset {2/16384}. /hg19_chr21 Group. /hg19_chr21/barcodes Dataset {12/3640}. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:40,testability,test,tests,40,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff. @@ -6,6 +6,7 @@. /another_genome/genes Dataset {343/4681}. /another_genome/indices Dataset {12/8192}. /another_genome/indptr Dataset {13/8192}. +/another_genome/scalar_dataset Dataset {SCALAR}. /another_genome/shape Dataset {2/16384}. /hg19_chr21 Group. /hg19_chr21/barcodes Dataset {12/3640}. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/issues/2345:57,security,hack,hack,57,"We're experiencing the same problem @linhuawang . We can hack our way around it, but it would be neater if `scanpy` dealt with the new files out of the box. You seem to be fully across the problem -- could you make a PR @linhuawang ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:6,usability,experien,experiencing,6,"We're experiencing the same problem @linhuawang . We can hack our way around it, but it would be neater if `scanpy` dealt with the new files out of the box. You seem to be fully across the problem -- could you make a PR @linhuawang ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:118,usability,close,close,118,"Hi @johnyaku and @linhuawang ,. apologies for late reply, we just merged #2424 in main already. Should be fixed! Will close but feel free to reopen if not fixed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2351:4,availability,error,error,4,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:4,performance,error,error,4,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:4,safety,error,error,4,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:4,usability,error,error,4,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2352:38,deployability,instal,install,38,Is this issue still relevant? Did you install scikit-misc?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:11,deployability,instal,install,11,Doing `pip install --user scikit-misc` as the last line says should solve this issue - I hope it worked out! Will close this as no more followups seen here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:21,usability,user,user,21,Doing `pip install --user scikit-misc` as the last line says should solve this issue - I hope it worked out! Will close this as no more followups seen here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:114,usability,close,close,114,Doing `pip install --user scikit-misc` as the last line says should solve this issue - I hope it worked out! Will close this as no more followups seen here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/pull/2355:79,modifiability,pac,packages,79,"Hi,. all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:347,modifiability,pac,packages,347,"Hi,. all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:576,deployability,version,version,576,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:674,deployability,scale,scalex,674,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,deployability,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:674,energy efficiency,scale,scalex,674,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:576,integrability,version,version,576,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,integrability,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,interoperability,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:87,modifiability,pac,packages,87,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:355,modifiability,pac,packages,355,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:576,modifiability,version,version,576,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:674,modifiability,scal,scalex,674,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,modifiability,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:674,performance,scale,scalex,674,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:625,reliability,doe,does,625,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,reliability,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,security,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:843,testability,integr,integration,843,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:819,usability,user,users,819,"> Hi,. > . > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,. Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR. I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:116,deployability,updat,updated,116,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:34,modifiability,pac,packages,34,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:203,modifiability,pac,package,203,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:259,modifiability,pac,packages,259,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:116,safety,updat,updated,116,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:116,security,updat,updated,116,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:128,usability,document,documentation,128,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/issues/2358:31,integrability,sub,submit,31,@YubinXie would you be able to submit a PR for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:133,availability,down,downloaded,133,"hi, it is actually just one line code. here it is:. ad['leiden'] = rapids_scanpy_funcs.leiden(ad). rapids_scanpy_funcs.leiden can be downloaded from the link",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2359:54,performance,memor,memory,54,"Can both of you ensure that you're not running out of memory, please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:54,usability,memor,memory,54,"Can both of you ensure that you're not running out of memory, please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,performance,memor,memory,56,"> Can both of you ensure that you're not running out of memory, please? I can ensure that I'm have enough memory. But it might be my environment problem. I will check it again. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:106,performance,memor,memory,106,"> Can both of you ensure that you're not running out of memory, please? I can ensure that I'm have enough memory. But it might be my environment problem. I will check it again. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,usability,memor,memory,56,"> Can both of you ensure that you're not running out of memory, please? I can ensure that I'm have enough memory. But it might be my environment problem. I will check it again. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:106,usability,memor,memory,106,"> Can both of you ensure that you're not running out of memory, please? I can ensure that I'm have enough memory. But it might be my environment problem. I will check it again. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,availability,error,error,97,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,performance,error,error,97,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,safety,error,error,97,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,usability,error,error,97,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:95,deployability,depend,dependency,95,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:95,integrability,depend,dependency,95,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:95,modifiability,depend,dependency,95,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:45,safety,isol,isolated,45,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:95,safety,depend,dependency,95,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:45,security,iso,isolated,45,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:45,testability,isol,isolated,45,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:95,testability,depend,dependency,95,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:70,energy efficiency,core,core,70,"Hi there,. I have seen that `sc.pp.neighbors` leads to a dead kernel (core dump) on Apple Silicon M1. See [tensorflow issue](https://github.com/tensorflow/tensorflow/issues/52845).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,deployability,depend,dependency,97,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,integrability,depend,dependency,97,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,modifiability,depend,dependency,97,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:47,safety,isol,isolated,47,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,safety,depend,dependency,97,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:47,security,iso,isolated,47,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:47,testability,isol,isolated,47,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,testability,depend,dependency,97,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:151,deployability,instal,installation,151,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:176,energy efficiency,core,core,176,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:72,integrability,messag,message,72,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:72,interoperability,messag,message,72,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:59,performance,memor,memory,59,"The same issue both on my M2 and Intel 12400, I'm sure the memory is not running out. I created a new envs but not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:59,usability,memor,memory,59,"The same issue both on my M2 and Intel 12400, I'm sure the memory is not running out. I created a new envs but not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:115,usability,help,helpful,115,"The same issue both on my M2 and Intel 12400, I'm sure the memory is not running out. I created a new envs but not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:11,deployability,instal,installed,11,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:269,deployability,version,versions,269,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:269,integrability,version,versions,269,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:80,interoperability,distribut,distribution,80,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1055,interoperability,platform,platformdirs,1055,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:269,modifiability,version,versions,269,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:557,modifiability,deco,decorator,557,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:960,modifiability,pac,packaging,960,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1721,modifiability,pac,packaged,1721,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:211,usability,help,helps,211,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. . My versions:. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. anndata2ri 1.2.dev11. appnope 0.1.3. asttokens NA. backcall 0.2.0. backports NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. importlib_resources NA. ipykernel 6.22.0. ipython_genutils 0.2.0. ipywidgets 8.0.6. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.4. numpy 1.22.0. packaging 23.1. pandas 1.2.5. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2023.3. pytz_deprecation_shim NA. rpy2 3.5.11. scipy 1.9.1. scrublet NA. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.3. traitlets 5.9.0. typing_extensions NA. tzlocal NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.2.0. jupyter_core 5.3.0. notebook 6.5.4. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]. macOS-13.2.1-arm64-arm-64bit. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:180,availability,operat,operations,180,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:231,deployability,log,logs,231,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:17,performance,time,times,17,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:231,safety,log,logs,231,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:231,security,log,logs,231,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:251,security,session,sessions,251,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:231,testability,log,logs,231,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:267,usability,help,helps,267,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,deployability,depend,dependency,56,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:362,deployability,depend,dependencies,362,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:154,energy efficiency,CPU,CPU,154,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,integrability,depend,dependency,56,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:362,integrability,depend,dependencies,362,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:127,interoperability,architectur,architecture,127,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,modifiability,depend,dependency,56,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:362,modifiability,depend,dependencies,362,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:46,performance,memor,memory,46,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:154,performance,CPU,CPU,154,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,safety,depend,dependency,56,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:362,safety,depend,dependencies,362,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:56,testability,depend,dependency,56,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:176,testability,simpl,simply,176,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:362,testability,depend,dependencies,362,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:46,usability,memor,memory,46,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:176,usability,simpl,simply,176,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2360:117,interoperability,format,format,117,"It is true that we can use functions such as `os.rename()` to move the generated figures right after, but the prefix format (herein `writekey`) is not fixed:. https://github.com/scverse/scanpy/blob/e5cdbbc02702d779352cbbdfa8e54020d93301ea/scanpy/plotting/_tools/__init__.py#L432. https://github.com/scverse/scanpy/blob/e5cdbbc02702d779352cbbdfa8e54020d93301ea/scanpy/plotting/_tools/__init__.py#L1201-L1205",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2360
https://github.com/scverse/scanpy/issues/2360:5,usability,close,close,5,I'll close this as duplicate of https://github.com/scverse/scanpy/issues/2324,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2360
https://github.com/scverse/scanpy/issues/2361:124,availability,error,error,124,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:101,performance,memor,memory,101,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:124,performance,error,error,124,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:124,safety,error,error,124,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:101,usability,memor,memory,101,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:124,usability,error,error,124,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:65,energy efficiency,CPU,CPU,65,Do you happen to use an Apple Mac computer with an Apple Silicon CPU? Then the following [issue](https://github.com/tensorflow/tensorflow/issues/52845) might be related.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:65,performance,CPU,CPU,65,Do you happen to use an Apple Mac computer with an Apple Silicon CPU? Then the following [issue](https://github.com/tensorflow/tensorflow/issues/52845) might be related.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:241,availability,fault,fault,241,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:461,availability,error,error,461,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:503,availability,error,errors,503,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:85,deployability,version,version,85,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:217,deployability,fail,fails,217,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:115,energy efficiency,load,loaded,115,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:241,energy efficiency,fault,fault,241,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:85,integrability,version,version,85,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:77,modifiability,pac,package,77,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:85,modifiability,version,version,85,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:971,modifiability,pac,package,971,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:115,performance,load,loaded,115,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:241,performance,fault,fault,241,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:461,performance,error,error,461,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:503,performance,error,errors,503,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:588,performance,multiprocessor,multiprocessor,588,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:674,performance,time,time,674,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:791,performance,multiprocessor,multiprocessor,791,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:35,reliability,doe,does,35,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:217,reliability,fail,fails,217,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:241,reliability,fault,fault,241,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:241,safety,fault,fault,241,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:461,safety,error,error,461,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:503,safety,error,errors,503,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:868,safety,test,test,868,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:956,safety,test,test,956,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:868,testability,test,test,868,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:956,testability,test,test,956,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:461,usability,error,error,461,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:503,usability,error,errors,503,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:1071,usability,help,helpful,1071,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files. With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error. I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be? The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step. Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:60,availability,replic,replictaed,60,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:364,availability,fault,fault,364,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:364,energy efficiency,fault,fault,364,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:371,energy efficiency,core,core,371,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:438,energy efficiency,core,core,438,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:129,integrability,messag,message,129,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:129,interoperability,messag,message,129,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:364,performance,fault,fault,364,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:364,reliability,fault,fault,364,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:364,safety,fault,fault,364,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:465,usability,help,help,465,"As expected the two other links here were of no use. I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]). WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:51,availability,sli,slightly,51,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:70,availability,cluster,clustering,70,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:173,availability,fault,fault,173,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:70,deployability,cluster,clustering,70,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:173,energy efficiency,fault,fault,173,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:180,energy efficiency,core,core,180,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:222,energy efficiency,alloc,allocate,222,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:173,performance,fault,fault,173,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:213,performance,memor,memory,213,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:51,reliability,sli,slightly,51,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:173,reliability,fault,fault,173,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:173,safety,fault,fault,173,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:213,usability,memor,memory,213,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. . The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:229,energy efficiency,core,core,229,Sad that the c(pp) problem is never discussed here. The only 'fix' was to not run muti process analysis. Has anybody looked into the summation step after the multi process step? To just restrict both OMP and OPENBLAS to only one core can not be the only solution here...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:100,interoperability,specif,specifically,100,"I'm having this issue as well -- code that used to run perfectly well is now resulting in segfaults specifically when running `sc.pp.neighbors`. Memory is not the issue, as my dataset is really small (<1k cells).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:145,performance,Memor,Memory,145,"I'm having this issue as well -- code that used to run perfectly well is now resulting in segfaults specifically when running `sc.pp.neighbors`. Memory is not the issue, as my dataset is really small (<1k cells).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:145,usability,Memor,Memory,145,"I'm having this issue as well -- code that used to run perfectly well is now resulting in segfaults specifically when running `sc.pp.neighbors`. Memory is not the issue, as my dataset is really small (<1k cells).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:566,availability,error,error,566,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:614,availability,down,download,614,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:266,deployability,depend,dependencies,266,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:466,deployability,contain,containing,466,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:487,deployability,version,versions,487,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:266,integrability,depend,dependencies,266,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:487,integrability,version,versions,487,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:266,modifiability,depend,dependencies,266,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:487,modifiability,version,versions,487,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:418,performance,lock,lockfile,418,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:566,performance,error,error,566,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:266,safety,depend,dependencies,266,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:355,safety,compl,completely,355,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:566,safety,error,error,566,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:355,security,compl,completely,355,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:418,security,lock,lockfile,418,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:266,testability,depend,dependencies,266,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:316,usability,help,helps,316,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:566,usability,error,error,566,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:679,usability,help,help,679,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment. 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:34,availability,error,error,34,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:343,availability,down,download,343,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:665,availability,error,errors,665,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:778,availability,error,error,778,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:71,deployability,updat,updating,71,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:117,deployability,version,versions,117,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:963,deployability,version,versions,963,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:995,deployability,version,version,995,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:117,integrability,version,versions,117,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:590,integrability,sub,subset,590,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:963,integrability,version,versions,963,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:995,integrability,version,version,995,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:88,modifiability,pac,packages,88,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:117,modifiability,version,versions,117,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:955,modifiability,pac,package,955,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:963,modifiability,version,versions,963,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:995,modifiability,version,version,995,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:34,performance,error,error,34,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:665,performance,error,errors,665,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:778,performance,error,error,778,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:34,safety,error,error,34,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:71,safety,updat,updating,71,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:665,safety,error,errors,665,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:778,safety,error,error,778,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:71,security,updat,updating,71,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:34,usability,error,error,34,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:665,usability,error,errors,665,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:778,usability,error,error,778,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```. # import libraries. import numpy as np. import pandas as pd. import scanpy as sc. import scvelo as scv. # download data. adata = scv.datasets.pancreas(). # preprocess . sc.pp.filter_cells(adata, min_counts=200). sc.pp.filter_genes(adata, min_cells=10). adata.raw = adata. sc.pp.highly_variable_genes(. adata, . n_top_genes=3000, . flavor='seurat_v3', . subset=True. ). sc.tl.pca(adata). # find neighbors -- this is the bit that errors. sc.pp.neighbors(. adata, . n_neighbors=20,. n_pcs=30, . metric='cosine', . random_state=312. ). ```. The error is below: . ```. OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. . ```. The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. . [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:48,availability,error,error,48,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:4,deployability,updat,update,4,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:80,deployability,version,version,80,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:80,integrability,version,version,80,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:80,modifiability,version,version,80,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:48,performance,error,error,48,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:4,safety,updat,update,4,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:48,safety,error,error,48,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:4,security,updat,update,4,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:48,usability,error,error,48,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2367:125,integrability,filter,filter,125,"Hi, sorry for my late reply. I think the reasons of this effect are not caused by the last codes, but caused by the previous filter functions. All the datasets are from HuBMAP: https://portal.hubmapconsortium.org/browse/dataset/29a538c3ddb396dee26188ae1151da46. They are in Salmon form, and they are not in the count data form (I mean not UMI). I think now we can upadte the target as: how to deal with the filtering method for pseudo-count data. Thanks a lot. Sincerely,. Tianyu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2367
https://github.com/scverse/scanpy/issues/2367:407,integrability,filter,filtering,407,"Hi, sorry for my late reply. I think the reasons of this effect are not caused by the last codes, but caused by the previous filter functions. All the datasets are from HuBMAP: https://portal.hubmapconsortium.org/browse/dataset/29a538c3ddb396dee26188ae1151da46. They are in Salmon form, and they are not in the count data form (I mean not UMI). I think now we can upadte the target as: how to deal with the filtering method for pseudo-count data. Thanks a lot. Sincerely,. Tianyu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2367
https://github.com/scverse/scanpy/issues/2369:59,deployability,version,version,59,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:110,deployability,instal,installation,110,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:59,integrability,version,version,59,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:59,modifiability,version,version,59,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:68,reliability,Doe,Does,68,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:135,safety,risk,risk,135,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:135,security,risk,risk,135,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:66,deployability,version,version,66,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:232,deployability,instal,install,232,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:253,deployability,depend,dependency,253,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:453,deployability,depend,depend,453,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:497,deployability,instal,installation,497,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:546,deployability,instal,install,546,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:66,integrability,version,version,66,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:253,integrability,depend,dependency,253,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:453,integrability,depend,depend,453,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:41,interoperability,specif,specifies,41,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:283,interoperability,compatib,compatible,283,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:378,interoperability,incompatib,incompatible,378,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:713,interoperability,format,formatting,713,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:66,modifiability,version,version,66,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:253,modifiability,depend,dependency,253,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:453,modifiability,depend,depend,453,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:214,reliability,Doe,Does,214,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:297,reliability,Doe,Does,297,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:253,safety,depend,dependency,253,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:453,safety,depend,depend,453,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:253,testability,depend,dependency,253,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:453,testability,depend,depend,453,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:600,usability,help,helpful,600,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it? - Does it refuse to install because some dependency is not Python 3.11 compatible? - Does it crash when run there? - Something else? I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:188,availability,error,error,188,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:487,availability,Avail,Available,487,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:817,availability,error,error,817,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:904,availability,error,error,904,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2682,availability,error,error,2682,"mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportErr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2712,availability,error,error,2712,"-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2829,availability,error,error,2829,"jnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3267,availability,error,error,3267,"-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3691,availability,error,error,3691,"ocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3708,availability,ERROR,ERROR,3708,"-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metad",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3766,availability,avail,available,3766,"y. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4619,availability,error,error,4619," os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4626,availability,error,error,4626,"s, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/op",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4675,availability,error,error,4675,"portError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4984,availability,operat,operations,4984,"f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5216,availability,error,error,5216,"kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/minicond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6322,availability,state,state,6322,"e exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9331,availability,operat,operations,9331,"ate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. Fil",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9602,availability,operat,operations,9602,"rnal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9820,availability,operat,operations,9820,"ib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10420,availability,operat,operations,10420,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10550,availability,error,error,10550,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:32,deployability,instal,install,32,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:116,deployability,instal,install,116,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:143,deployability,instal,install,143,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:342,deployability,fail,failed,342,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:497,deployability,version,versionsThe,497,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:683,deployability,version,version,683,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:709,deployability,version,version,709,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:734,deployability,instal,installed,734,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:744,deployability,version,version,744,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:853,deployability,instal,install,853,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1634,deployability,build,build,1634,"::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1710,deployability,build,build-tracker-,1710,"'>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1819,deployability,instal,install-,1819," Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2133,deployability,modul,module,2133,"078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2187,deployability,modul,module,2187,"6.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `dis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2263,deployability,instal,install-,2263,"n cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2343,deployability,modul,module,2343,"0. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2436,deployability,instal,install-,2436,"-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the scrip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2607,deployability,instal,install,2607,"ar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only proje",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2625,deployability,version,version,2625,") to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2646,deployability,version,versions,2646,"private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3304,deployability,instal,installed,3304,"ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3787,deployability,build,build,3787,"╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentione",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4247,deployability,instal,install-,4247,"rovides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.Ins",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4527,deployability,instal,install-,4527," not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"",",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4653,deployability,fail,failed,4653," setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4995,deployability,build,build,4995," else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/da",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5248,deployability,Instal,InstallationSubprocessError,5248,"h/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5896,deployability,instal,install,5896,"e ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10431,deployability,build,build,10431,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10628,deployability,fail,failed,10628,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10643,deployability,version,version,10643,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10673,deployability,version,version,10673,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10705,deployability,instal,installed,10705,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10903,deployability,build,build,10903,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10979,deployability,build,build-tracker-,10979,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:11012,deployability,build,build,11012,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:11089,deployability,build,build-tracker-,11089,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1216,energy efficiency,Current,Current,1216,"which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folde",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3197,energy efficiency,core,core,3197,"e ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:497,integrability,version,versionsThe,497,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:683,integrability,version,version,683,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:709,integrability,version,version,709,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:744,integrability,version,version,744,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2625,integrability,version,version,2625,") to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2646,integrability,version,versions,2646,"private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2689,integrability,sub,subprocess-exited-with-error,2689,"/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. prin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2853,integrability,sub,subprocess,2853,"b116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3273,integrability,messag,message,3273,"nh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d95",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5164,integrability,sub,subprocess,5164,"'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5730,integrability,wrap,wrapper,5730,"output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6322,integrability,state,state,6322,"e exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10643,integrability,version,version,10643,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10673,integrability,version,version,10673,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:242,interoperability,conflict,conflicts,242,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:265,interoperability,incompatib,incompatible,265,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:385,interoperability,specif,specifications,385,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:417,interoperability,incompatib,incompatible,417,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:458,interoperability,format,format,458,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:519,interoperability,specif,specifications,519,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:551,interoperability,incompatib,incompatible,551,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2553,interoperability,format,format,2553,"b1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It gener",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3232,interoperability,standard,standards,3232,"0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h000",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3273,interoperability,messag,message,3273,"nh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d95",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3505,interoperability,standard,standard,3505,"8, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5730,interoperability,wrapper,wrapper,5730,"output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10017,interoperability,distribut,distributions,10017,"olution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:278,modifiability,pac,packages,278,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:476,modifiability,pac,package,476,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:497,modifiability,version,versionsThe,497,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:683,modifiability,version,version,683,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:709,modifiability,version,version,709,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:744,modifiability,version,version,744,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1105,modifiability,pac,packages,1105," conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1521,modifiability,pac,packages,1521,"ications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1898,modifiability,pac,package,1898,"n error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2133,modifiability,modul,module,2133,"078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2187,modifiability,modul,module,2187,"6.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `dis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2343,modifiability,modul,module,2343,"0. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2625,modifiability,version,version,2625,") to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2646,modifiability,version,versions,2646,"private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3222,modifiability,pac,packaging,3222,"5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9v",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4698,modifiability,pac,package,4698,"nt(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4774,modifiability,pac,package,4774," "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4961,modifiability,pac,packages,4961," as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5135,modifiability,pac,packages,5135,"e, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = sel",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5487,modifiability,pac,packages,5487,"5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5673,modifiability,pac,packages,5673,"ror while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5864,modifiability,pac,packages,5864,"ck (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6047,modifiability,pac,packages,6047,". call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_crit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6253,modifiability,pac,packages,6253,"ionSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_crit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6508,modifiability,pac,packages,6508,"i/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/env",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6734,modifiability,pac,packages,6734," return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6974,modifiability,pac,packages,6974,"^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7185,modifiability,pac,packages,7185,"File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7357,modifiability,pac,packages,7357,", max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. Fil",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7540,modifiability,pac,packages,7540,"lvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7723,modifiability,pac,packages,7723,"1/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/U",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8009,modifiability,pac,packages,8009,"rs.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8193,modifiability,pac,packages,8193,"/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8422,modifiability,pac,packages,8422,"eturn bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8589,modifiability,pac,packages,8589,"ndidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8783,modifiability,pac,packages,8783,""", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8998,modifiability,pac,packages,8998,"1/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9308,modifiability,pac,packages,9308,"cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9579,modifiability,pac,packages,9579,"/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.M",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9797,modifiability,pac,packages,9797,"rnal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9994,modifiability,pac,packages,9994,"packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10178,modifiability,pac,packages,10178,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10397,modifiability,pac,packages,10397,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10643,modifiability,version,version,10643,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10673,modifiability,version,version,10673,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10788,modifiability,pac,packages,10788,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:188,performance,error,error,188,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:817,performance,error,error,817,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:904,performance,error,error,904,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1209,performance,cach,cache,1209,"t line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/v",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1269,performance,cach,cache-control,1269,"e packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknw",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1384,performance,cach,cached,1384,"ecifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1428,performance,cach,cached,1428,"ith each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2682,performance,error,error,2682,"mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportErr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2712,performance,error,error,2712,"-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2829,performance,error,error,2829,"jnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3267,performance,error,error,3267,"-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3691,performance,error,error,3691,"ocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3708,performance,ERROR,ERROR,3708,"-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metad",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4619,performance,error,error,4619," os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4626,performance,error,error,4626,"s, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/op",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4675,performance,error,error,4675,"portError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5216,performance,error,error,5216,"kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/minicond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10550,performance,error,error,10550,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:23,reliability,doe,does,23,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:342,reliability,fail,failed,342,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:487,reliability,Availab,Available,487,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:800,reliability,doe,does,800,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3413,reliability,doe,doesn,3413,"n1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3766,reliability,availab,available,3766,"y. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4653,reliability,fail,failed,4653," setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10628,reliability,fail,failed,10628,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:83,safety,test,test,83,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:104,safety,test,test,104,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:188,safety,error,error,188,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:487,safety,Avail,Available,487,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:817,safety,error,error,817,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:904,safety,error,error,904,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2133,safety,modul,module,2133,"078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2187,safety,modul,module,2187,"6.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `dis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2343,safety,modul,module,2343,"0. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2682,safety,error,error,2682,"mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportErr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2712,safety,error,error,2712,"-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2829,safety,error,error,2829,"jnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2950,safety,test,test,2950,"ar/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3267,safety,error,error,3267,"-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3456,safety,avoid,avoids,3456,"c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3669,safety,except,except,3669,"upported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encounter",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3691,safety,error,error,3691,"ocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3708,safety,ERROR,ERROR,3708,"-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metad",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3766,safety,avail,available,3766,"y. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4619,safety,error,error,4619," os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4626,safety,error,error,4626,"s, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/op",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4675,safety,error,error,4675,"portError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4837,safety,Except,Exception,4837," . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/tes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4936,safety,test,test,4936,"ith tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5110,safety,test,test,5110,". exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 9",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5216,safety,error,error,5216,"kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/minicond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5237,safety,except,exceptions,5237,"/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/pytho",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5327,safety,except,exception,5327,"ools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5375,safety,except,exception,5375,"ivate/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_ro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5462,safety,test,test,5462,": /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/op",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5648,safety,test,test,5648,"on-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5839,safety,test,test,5839,"ption information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6022,safety,test,test,6022,"ne 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6228,safety,test,test,6228,"ternal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py""",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6483,safety,test,test,6483,"e-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Us",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6709,safety,test,test,6709,".py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/pyth",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:6949,safety,test,test,6949,"er.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve. result = self._result = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7160,safety,test,test,7160,"solve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve. state = resolution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7332,safety,test,test,7332,"lution.resolve(requirements, max_rounds=max_rounds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCand",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7515,safety,test,test,7515,"pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve. failure_causes = self._attempt_to_pin_criterion(name). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7698,safety,test,test,7698,"a3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion. criteria = self._get_updated_criteria(candidate). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare()",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:7984,safety,test,test,7984,"/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria. self._add_to_criteria(criteria, requirement, parent=candidate). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/pyth",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8168,safety,test,test,8168,"ython3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria. if not criterion.candidates:. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8397,safety,test,test,8397,""", line 151, in __bool__. return bool(self._sequence). ^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. ret",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8564,safety,test,test,8564,"olution/resolvelib/found_candidates.py"", line 155, in __bool__. return any(self). ^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/pyt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8758,safety,test,test,8758,"olvelib/found_candidates.py"", line 143, in <genexpr>. return (c for c in iterator if id(c) not in self._incompatible_ids). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/minic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:8973,safety,test,test,8973,"a3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built. candidate = func(). ^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9283,safety,test,test,9283,"link. self._link_candidate_cache[link] = LinkCandidate(. ^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__. super().__init__(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = genera",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9554,safety,test,test,9554,"3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__. self.dist = self._prepare(). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9772,safety,test,test,9772,".11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare. dist = self._prepare_distribution(). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pyt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:9969,safety,test,test,9969,"2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution. return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000g",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10153,safety,test,test,10153,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10372,safety,test,test,10372,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10550,safety,error,error,10550,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:10571,safety,except,exceptions,10571,"_linked_requirement(self._ireq, parallel_builds=True). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement. return self._prepare_linked_requirement(req, parallel_builds). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement. dist = _get_prepared_distribution(. ^^^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution. abstract_dist.prepare_distribution_metadata(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata. self.req.prepare_metadata(). File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata. self.metadata_directory = generate_metadata_legacy(. ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata. raise MetadataGenerationFailed(package_details=details) from error. pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed. Remote version of pip: 22.3.1. Local version of pip: 22.3.1. Was pip installed by pip? False. Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:487,security,Availab,Available,487,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1275,security,control,control,1275,"ackages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1294,security,immut,immutable,1294,"ke several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d95884844",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3632,security,token,tokenize,3632,"1.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: met",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3766,security,availab,available,3766,"y. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:3942,security,token,tokenize,3942,"vs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:83,testability,test,test,83,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:104,testability,test,test,104,"The problem is that it does not install at all. . When I run. ```. conda create -n test. conda activate test. conda install python=3.11. conda install -c conda-forge scanpy. ```. I get an error output for the last line, which is:. ```. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:1275,testability,control,control,1275,"ackages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0. - feature:|@/osx-64::__osx==10.16=0. - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16. ```. Repeating this with python=3.10 does not give an error. Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```. Collecting numba>=0.41.0. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod. Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2068,testability,Trace,Traceback,2068,"""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache. Current age based on date: 1302943. Ignoring unknown cache-control directive: immutable. Freshness lifetime from max-age: 365000000. The response is ""fresh"", returning cached response. 365000000 > 1302943. Using cached numba-0.56.4.tar.gz (2.4 MB). Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'. Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba. Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:2950,testability,test,test,2950,"ar/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. Running command python setup.py egg_info. Traceback (most recent call last):. File ""<string>"", line 2, in <module>. File ""<pip-setuptools-caller>"", line 34, in <module>. File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>. _guard_py_ver(). File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver. raise RuntimeError(msg.format(cur_py, min_py, max_py)). RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported. error: subprocess-exited-with-error. . × python setup.py egg_info did not run successfully. │ exit code: 1. ╰─> See above for output. . note: This error originates from a subprocess, and is likely not a problem with pip. full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '. exec(compile('""'""''""'""''""'""'. # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py. #. # - It imports setuptools before invoking setup.py, to enable projects that directly. # import from `distutils.core` to work with newer packaging standards. # - It provides a clear error message when setuptools is not installed. # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so. # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:. # manifest_maker: standard file '""'""'-c'""'""' not found"". # - It generates a shim setup.py, for handling setup.cfg-only projects. import os, sys, tokenize. . try:. import setuptools. except ImportError as error:. print(. ""ERROR: Can not execute `setup.py` since setuptools is not available in "". ""the build environment."",. file=sys.stderr,. ). sys.exit(1). . __file__ = %r. sys.argv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4861,testability,Trace,Traceback,4861,"gv[0] = __file__. . if os.path.exists(__file__):. filename = __file__. with tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:4936,testability,test,test,4936,"ith tokenize.open(__file__) as f:. setup_py_code = f.read(). else:. filename = ""<auto-generated setuptools caller>"". setup_py_code = ""from setuptools import setup; setup()"". . exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:5110,testability,test,test,5110,". exec(compile(setup_py_code, filename, ""exec"")). '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q. cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/. Preparing metadata (setup.py) ... error. error: metadata-generation-failed. × Encountered error while generating package metadata. ╰─> See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. Exception information:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata. call_subprocess(. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess. raise error. pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper. status = run_func(*args). ^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper. return func(self, options, args). ^^^^^^^^^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run. requirement_set = resolver.resolve(. ^^^^^^^^^^^^^^^^^. File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 9",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
