id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1850:164,integrability,version,version,164,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1863,integrability,compon,components,1863,"s of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5622,integrability,Version,Versions,5622,"_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:598,interoperability,specif,specifying,598,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1863,interoperability,compon,components,1863,"s of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:164,modifiability,version,version,164,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1307,modifiability,modul,module,1307," can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1406,modifiability,pac,packages,1406,"defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1669,modifiability,pac,packages,1669,"Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1863,modifiability,compon,components,1863,"s of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1875,modifiability,layer,layer,1875,"could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 119",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:2322,modifiability,pac,packages,2322,".pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:2715,modifiability,pac,packages,2715," embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3003,modifiability,pac,packages,3003,", legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3318,modifiability,pac,packages,3318,"packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 50",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3629,modifiability,pac,packages,3629,"sing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3912,modifiability,pac,packages,3912,"ategories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4204,modifiability,pac,packages,4204,"570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4544,modifiability,pac,packages,4544," ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotIm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4835,modifiability,pac,packages,4835,"). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5085,modifiability,pac,packages,5085,"gories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5258,modifiability,pac,packages,5258,"es(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5622,modifiability,Version,Versions,5622,"_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5890,modifiability,deco,decorator,5890,""""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:6291,modifiability,pac,packaging,6291,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:6937,modifiability,pac,packaged,6937,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:36,performance,error,error,36,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:369,performance,error,error,369,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:482,performance,error,error,482,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4472,performance,Cach,CachedProperty,4472,"and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for M",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4763,performance,Cach,CachedProperty,4763,"= False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5779,performance,bottleneck,bottleneck,5779,"_(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:6234,performance,network,networkx,6234,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7070,performance,CPU,CPU,7070,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:36,safety,error,error,36,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:369,safety,error,error,369,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:482,safety,error,error,482,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1280,safety,input,input-,1280," into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1307,safety,modul,module,1307," can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7062,safety,log,logical,7062,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7116,safety,updat,updated,7116,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5329,security,hack,hack,5329,"gories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:6234,security,network,networkx,6234,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7062,security,log,logical,7062,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7096,security,Session,Session,7096,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7116,security,updat,updated,7116,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1108,testability,Trace,Traceback,1108,"[x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, ws",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1236,testability,Trace,Traceback,1236,"aster branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7062,testability,log,logical,7062,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:36,usability,error,error,36,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:124,usability,confirm,confirmed,124,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:207,usability,confirm,confirmed,207,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:369,usability,error,error,369,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:482,usability,error,error,482,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:764,usability,user,user-images,764,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:907,usability,Minim,Minimal,907,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1280,usability,input,input-,1280," into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1852:310,deployability,depend,dependencies,310,"Use session_info instead of sinfo; [`sinfo` has been replaced](https://pypi.org/project/sinfo/) with [`session_info`](https://gitlab.com/joelostblom/session_info), which is definitely a better name. We should switch over to using this. I think we'll be calling it like: `import session_info; session_info.show(dependencies=True, html=False, **extra_kwargs)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1852
https://github.com/scverse/scanpy/issues/1852:310,integrability,depend,dependencies,310,"Use session_info instead of sinfo; [`sinfo` has been replaced](https://pypi.org/project/sinfo/) with [`session_info`](https://gitlab.com/joelostblom/session_info), which is definitely a better name. We should switch over to using this. I think we'll be calling it like: `import session_info; session_info.show(dependencies=True, html=False, **extra_kwargs)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1852
https://github.com/scverse/scanpy/issues/1852:310,modifiability,depend,dependencies,310,"Use session_info instead of sinfo; [`sinfo` has been replaced](https://pypi.org/project/sinfo/) with [`session_info`](https://gitlab.com/joelostblom/session_info), which is definitely a better name. We should switch over to using this. I think we'll be calling it like: `import session_info; session_info.show(dependencies=True, html=False, **extra_kwargs)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1852
https://github.com/scverse/scanpy/issues/1852:310,safety,depend,dependencies,310,"Use session_info instead of sinfo; [`sinfo` has been replaced](https://pypi.org/project/sinfo/) with [`session_info`](https://gitlab.com/joelostblom/session_info), which is definitely a better name. We should switch over to using this. I think we'll be calling it like: `import session_info; session_info.show(dependencies=True, html=False, **extra_kwargs)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1852
https://github.com/scverse/scanpy/issues/1852:310,testability,depend,dependencies,310,"Use session_info instead of sinfo; [`sinfo` has been replaced](https://pypi.org/project/sinfo/) with [`session_info`](https://gitlab.com/joelostblom/session_info), which is definitely a better name. We should switch over to using this. I think we'll be calling it like: `import session_info; session_info.show(dependencies=True, html=False, **extra_kwargs)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1852
https://github.com/scverse/scanpy/pull/1853:26,safety,compl,complex,26,Fix is_categorical and np.complex deprecations; Fix some deprecations. Fixes #1658,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1853
https://github.com/scverse/scanpy/pull/1853:26,security,compl,complex,26,Fix is_categorical and np.complex deprecations; Fix some deprecations. Fixes #1658,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1853
https://github.com/scverse/scanpy/pull/1854:34,deployability,instal,install,34,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:334,deployability,depend,dependency,334,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:470,energy efficiency,cpu,cpu,470,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:583,energy efficiency,cpu,cpu,583,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:334,integrability,depend,dependency,334,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:203,modifiability,paramet,parameter,203,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:334,modifiability,depend,dependency,334,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:470,performance,cpu,cpu,470,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:583,performance,cpu,cpu,583,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:334,safety,depend,dependency,334,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:401,safety,test,test,401,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:629,safety,Test,Test,629,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:648,safety,Test,Test,648,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:334,testability,depend,dependency,334,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:401,testability,test,test,401,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:629,testability,Test,Test,629,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:648,testability,Test,Test,648,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:124,usability,support,support,124,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:161,usability,stop,stop,161,"Deprecate multicore tsne; I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn. - [x] Test metric. - [x] Test deprecations.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/issues/1855:35,deployability,continu,continuous,35,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:608,deployability,continu,continuous,608,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:46,modifiability,variab,variables,46,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:156,modifiability,paramet,parameters,156,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:433,modifiability,pac,package,433,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:619,modifiability,variab,variables,619,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:238,testability,simpl,simple,238,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:230,usability,tool,tool,230,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:238,usability,simpl,simple,238,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:254,usability,tool,tool,254,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:302,usability,tool,tools,302,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:402,usability,tool,tools,402,correlation between cell types and continuous variables stored in .obs; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1857:209,deployability,version,version,209,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:802,deployability,Version,Versions,802,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1026,deployability,Version,Versions,1026,"sers/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2747,deployability,log,logical,2747,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2799,deployability,updat,updated,2799,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:851,energy efficiency,core,core,851,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2755,energy efficiency,CPU,CPU,2755,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2759,energy efficiency,core,cores,2759,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:209,integrability,version,version,209,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:802,integrability,Version,Versions,802,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1026,integrability,Version,Versions,1026,"sers/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2473,integrability,wrap,wrapt,2473,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:856,interoperability,format,formatters,856,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:209,modifiability,version,version,209,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:802,modifiability,Version,Versions,802,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:834,modifiability,pac,packages,834,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1026,modifiability,Version,Versions,1026,"sers/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1351,modifiability,deco,decorator,1351,"//matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1863,modifiability,pac,packaging,1863,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:82,performance,lock,lock,82,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1009,performance,lock,lock,1009,"e or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2755,performance,CPU,CPU,2755,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2747,safety,log,logical,2747,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2799,safety,updat,updated,2799,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:82,security,lock,lock,82,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1009,security,lock,lock,1009,"e or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:1253,security,certif,certifi,1253,"rmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. sto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2747,security,log,logical,2747,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2779,security,Session,Session,2779,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2799,security,updat,updated,2799,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:730,testability,Trace,Traceback,730,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2747,testability,log,logical,2747,"Python/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2019.3. requests 2.24.0. scipy 1.4.1. seaborn 0.10.0. send2trash NA. six 1.14.0. sklearn 0.23.1. sniffio 1.2.0. statsmodels 0.12.2. storemagic NA. swig_runtime_data4 NA. tables 3.6.1. tensorboard 2.2.2. tensorflow 2.2.0. termcolor 1.1.0. texttable 1.6.3. tornado 6.1. traitlets 4.3.3. typing_extensions NA. umap 0.5.1. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.3.1. zipp NA. zmq 19.0.1. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 3.0.5. notebook 6.0.3. -----. Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]. Darwin-20.2.0-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-26 22:36. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:29,usability,User,Users,29,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:169,usability,confirm,confirmed,169,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:252,usability,confirm,confirmed,252,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:343,usability,guid,guide,343,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:398,usability,minim,minimal-bug-reports,398,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:504,usability,Minim,Minimal,504,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:956,usability,User,Users,956,"No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.highly_variable_genes(adata). ```. ```pytb. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj). ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. 0294638c8bf50491b025b096f3dba0a1 NA. absl NA. anyio NA. appnope 0.1.0. astunparse 1.6.3. attr 19.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.5. chardet 3.0.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. gast NA. get_version 2.2. google NA. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.3. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.36.0. markupsafe 1.1.1. matplotlib 3.2.1. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.0.7. numba 0.53.1. numexpr 2.7.3. numpy 1.19.0. opt_einsum v3.3.0. packaging 20.4. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/pull/1858:93,availability,sli,slightly,93,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:503,availability,consist,consistent,503,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:62,energy efficiency,Current,Currently,62,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:93,reliability,sli,slightly,93,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:956,safety,review,review,956,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:529,security,control,control,529,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:529,testability,control,control,529,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:956,testability,review,review,956,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:503,usability,consist,consistent,503,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:524,usability,user,user,524,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:595,usability,tool,tools,595,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:656,usability,tool,tools,656,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:807,usability,guid,guidelines,807,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:838,usability,guid,guide,838,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:934,usability,workflow,workflow,934,"Fixed randomness in tl.diffmap - compute_eigen (v0 argument); Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. . I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:. - tools/_diffmap.py _diffmap function (tl.diffmap function). - tools/_dpt.py _diffmap function. - neighbors/__init__.py compute_eigen function. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/issues/1859:572,availability,sli,slightly,572,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:828,availability,Sli,Slight,828,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:151,deployability,version,version,151,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:381,deployability,pipelin,pipeline,381,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:1510,deployability,Version,Versions,1510,"data.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2778,deployability,log,logical,2778,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2786,energy efficiency,CPU,CPU,2786,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2790,energy efficiency,core,cores,2790,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2814,energy efficiency,Model,Model,2814,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:151,integrability,version,version,151,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:381,integrability,pipelin,pipeline,381,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:1510,integrability,Version,Versions,1510,"data.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:483,interoperability,Specif,Specifically,483,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:151,modifiability,version,version,151,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:1510,modifiability,Version,Versions,1510,"data.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:1706,modifiability,deco,decorator,1706,"')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2058,modifiability,pac,packaging,2058,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:319,performance,time,time,319,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:596,performance,time,time,596,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:1976,performance,network,networkx,1976,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2786,performance,CPU,CPU,2786,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:572,reliability,sli,slightly,572,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:828,reliability,Sli,Slight,828,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2778,safety,log,logical,2778,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:1976,security,network,networkx,1976,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2778,security,log,logical,2778,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2814,security,Model,Model,2814,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2299,testability,simpl,simplegeneric,2299,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2778,testability,log,logical,2778,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:111,usability,confirm,confirmed,111,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:194,usability,confirm,confirmed,194,"PAGA layout not reproducible; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:. ```python. sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run. ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. nts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2299,usability,simpl,simplegeneric,2299,"d some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python. import random. random.seed(0). sc.tl.paga(adata). sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run. ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 5.0.6. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pythoncom NA. pytz 2021.1. pywintypes NA. scanpy 1.7.2. scipy 1.6.2. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1860:309,deployability,automat,automate,309,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1860:437,integrability,filter,filtered,437,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1860:408,modifiability,layer,layers,408,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1860:318,safety,input,inputting,318,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1860:225,security,modif,modification,225,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1860:309,testability,automat,automate,309,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1860:318,usability,input,inputting,318,"STARsolo Matrix with Velocyto --> Anndata function; The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1861:526,interoperability,specif,specify,526,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:116,modifiability,paramet,parameters,116,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:393,modifiability,pac,package,393,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:198,testability,simpl,simple,198,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:190,usability,tool,tool,190,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:198,usability,simpl,simple,198,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:214,usability,tool,tool,214,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:262,usability,tool,tools,262,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1861:362,usability,tool,tools,362,"`key_added` to UMAP, tSNE, PCA; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1862:0,availability,Error,Error,0,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:606,availability,down,downloaded,606,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:711,availability,error,error,711,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2910,availability,sli,sliced,2910,"37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be strin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3274,availability,sli,slice,3274,"e='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3281,availability,sli,slice,3281,"score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4187,availability,toler,tolerance,4187,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:169,deployability,version,version,169,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1585,deployability,modul,module,1585,"n one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4429,deployability,Version,Versions,4429,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4478,deployability,log,logging,4478,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4122,energy efficiency,core,core,4122,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:169,integrability,version,version,169,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:577,integrability,pub,published,577,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4429,integrability,Version,Versions,4429,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:169,modifiability,version,version,169,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1585,modifiability,modul,module,1585,"n one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1925,modifiability,pac,packages,1925,"s = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2391,modifiability,pac,packages,2391,"es_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2773,modifiability,pac,packages,2773,"l_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3130,modifiability,pac,packages,3130,"_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3481,modifiability,pac,packages,3481,"_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3771,modifiability,pac,packages,3771,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4106,modifiability,pac,packages,4106,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4429,modifiability,Version,Versions,4429,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:0,performance,Error,Error,0,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:711,performance,error,error,711,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4268,performance,Reindex,Reindexing,4268,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4361,performance,Reindex,Reindexing,4361,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2910,reliability,sli,sliced,2910,"37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be strin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3274,reliability,sli,slice,3274,"e='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3281,reliability,sli,slice,3281,"score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4187,reliability,toleran,tolerance,4187,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:0,safety,Error,Error,0,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:711,safety,error,error,711,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1558,safety,input,input-,1558," with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1585,safety,modul,module,1585,"n one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3402,safety,compl,complete,3402,"\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued In",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4284,safety,valid,valid,4284,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4377,safety,valid,valid,4377,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4478,safety,log,logging,4478,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3402,security,compl,complete,3402,"\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued In",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4478,security,log,logging,4478,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:768,testability,understand,understand,768,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1514,testability,Trace,Traceback,1514,"ing any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4478,testability,log,logging,4478,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:0,usability,Error,Error,0,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:129,usability,confirm,confirmed,129,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:212,usability,confirm,confirmed,212,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:303,usability,guid,guide,303,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:358,usability,minim,minimal-bug-reports,358,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:464,usability,Minim,Minimal,464,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:711,usability,error,error,711,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:804,usability,help,help,804,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:849,usability,Mous,Mouse,849,"Error at the cell cycle score calculation step; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,. I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1558,usability,input,input-,1558," with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python. ## Mouse. folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1861,usability,user,users,1861," ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt"". cc_genes = pd.read_table(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:1941,usability,tool,tools,1941,"le(folder, delimiter='\t'). #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'). s_genes = cc_genes['S'].dropna(). g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]. g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2327,usability,user,users,2327,"ar.index[np.in1d(adata.var.index, g2m_genes_mm)]. sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2407,usability,tool,tools,2407,"data, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ```. ```pytb. InvalidIndexError Traceback (most recent call last). <ipython-input-54-668f41c58e57> in <module>. 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]. 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:2709,usability,user,users,2709,"1d(adata.var.index, g2m_genes_mm)]. ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs). 231 ctrl_size = min(len(s_genes), len(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3066,usability,user,users,3066,"n(g2m_genes)). 232 # add s-score. --> 233 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs). 234 # add g2m-score. 235 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\loc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3417,usability,user,users,3417,"genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw). 151 gene_list = list(gene_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:3707,usability,user,users,3707,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4042,usability,user,users,4042,"_list). 152 . --> 153 X_list = _adata[:, gene_list].X. 154 if issparse(X_list):. 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index). 95 return positions # np.ndarray[int]. 96 else: # indexer should be string array. ---> 97 positions = index.get_indexer(indexer). 98 if np.any(positions < 0):. 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance). 3170 if not self.is_unique:. 3171 raise InvalidIndexError(. -> 3172 ""Reindexing only valid with uniquely valued Index objects"". 3173 ). 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1863:945,deployability,automat,automated,945,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:965,energy efficiency,predict,prediction,965,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:144,modifiability,paramet,parameters,144,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:421,modifiability,pac,package,421,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:809,modifiability,concern,concern,809,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:965,safety,predict,prediction,965,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:226,testability,simpl,simple,226,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:809,testability,concern,concern,809,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:945,testability,automat,automated,945,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:218,usability,tool,tool,218,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:226,usability,simpl,simple,226,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:242,usability,tool,tool,242,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:290,usability,tool,tools,290,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:390,usability,tool,tools,390,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:976,usability,tool,tools,976,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:1029,usability,support,supported,1029,"Putative cell type classification after sc.tl.score_genes?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1864:165,deployability,version,version,165,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1864:342,deployability,fail,fails,342,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1864:165,integrability,version,version,165,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1864:165,modifiability,version,version,165,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1864:342,reliability,fail,fails,342,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1864:125,usability,confirm,confirmed,125,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1864:208,usability,confirm,confirmed,208,"Scanpy docs not reachable via `scanpy.org`; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs seem to be unreachable via `scanpy.org`. Chrome, for example, fails with *The site can't be reached. scanpy.org took too long to respond.* Calling `scanpy.readthedocs.io` works just fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1864
https://github.com/scverse/scanpy/issues/1865:14,availability,slo,slow,14,sc.tl.pca too slow; I noticed the calculating PCA only uses one core. Is it possible to make it faster?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1865
https://github.com/scverse/scanpy/issues/1865:64,energy efficiency,core,core,64,sc.tl.pca too slow; I noticed the calculating PCA only uses one core. Is it possible to make it faster?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1865
https://github.com/scverse/scanpy/issues/1865:14,reliability,slo,slow,14,sc.tl.pca too slow; I noticed the calculating PCA only uses one core. Is it possible to make it faster?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1865
https://github.com/scverse/scanpy/issues/1866:750,availability,down,downstream,750,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1489,availability,error,error,1489,"## Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3931,availability,error,error,3931,"en(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5673,availability,error,error,5673,". 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5803,availability,error,error,5803," dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5890,availability,error,error,5890,"s=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. dec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6271,availability,down,downgrade,6271,"py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6455,availability,sli,slightly,6455,"a3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:200,deployability,version,version,200,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:823,deployability,modul,modules,823,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2508,deployability,scale,scaleoffset,2508,"s may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4163,deployability,modul,module,4163,"tion:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5978,deployability,Version,Versions,5978,"gs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6250,deployability,instal,installs,6250,"ages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6387,deployability,instal,install,6387,"(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8187,deployability,log,logical,8187,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8239,deployability,updat,updated,8239,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:818,energy efficiency,Load,Load,818,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2508,energy efficiency,scale,scaleoffset,2508,"s may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6773,energy efficiency,cloud,cloudpickle,6773,"jects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8195,energy efficiency,CPU,CPU,8195,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8199,energy efficiency,core,cores,8199,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:200,integrability,version,version,200,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1277,integrability,Transform,Transform,1277," branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2746,integrability,wrap,wrapper,2746," key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrappe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2802,integrability,wrap,wrapper,2802,"nc(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3963,integrability,Batch,Batch,3963,"nv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5029,integrability,wrap,wrapper,5029,"as the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact lis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5835,integrability,Batch,Batch,5835," 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5978,integrability,Version,Versions,5978,"gs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6148,integrability,discover,discoverable,6148,"funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwiso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6332,integrability,messag,message,6332,"128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1277,interoperability,Transform,Transform,1277," branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2746,interoperability,wrapper,wrapper,2746," key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrappe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2802,interoperability,wrapper,wrapper,2802,"nc(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5029,interoperability,wrapper,wrapper,5029,"as the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact lis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6148,interoperability,discover,discoverable,6148,"funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwiso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6332,interoperability,messag,message,6332,"128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:200,modifiability,version,version,200,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:823,modifiability,modul,modules,823,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1699,modifiability,pac,packages,1699,"156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1902,modifiability,pac,packages,1902," scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2111,modifiability,pac,packages,2111,"ta . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2347,modifiability,pac,packages,2347,".X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2508,modifiability,scal,scaleoffset,2508,"s may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3249,modifiability,pac,packages,3249," dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3452,modifiability,pac,packages,3452," fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3706,modifiability,pac,packages,3706,"ects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4163,modifiability,modul,module,4163,"tion:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4324,modifiability,pac,packages,4324," 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4568,modifiability,pac,packages,4568,"mes, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5250,modifiability,pac,packages,5250,"93/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old inst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5481,modifiability,pac,packages,5481,"905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5978,modifiability,Version,Versions,5978,"gs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6075,modifiability,pac,package,6075,". 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6200,modifiability,pac,package,6200,"ch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6890,modifiability,deco,decorator,6890," raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:7399,modifiability,pac,packaging,7399,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:818,performance,Load,Load,818,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1489,performance,error,error,1489,"## Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2508,performance,scale,scaleoffset,2508,"s may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3931,performance,error,error,3931,"en(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3963,performance,Batch,Batch,3963,"nv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5673,performance,error,error,5673,". 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5803,performance,error,error,5803," dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5835,performance,Batch,Batch,5835," 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5890,performance,error,error,5890,"s=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. dec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6682,performance,bottleneck,bottleneck,6682,"hile writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8195,performance,CPU,CPU,8195,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6455,reliability,sli,slightly,6455,"a3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:823,safety,modul,modules,823,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1489,safety,error,error,1489,"## Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1847,safety,except,except,1847,"anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.wr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1854,safety,Except,Exception,1854,"import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3113,safety,except,exception,3113,"s/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent cal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3161,safety,except,exception,3161,", shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3397,safety,except,except,3397," shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3404,safety,Except,Exception,3404,"type, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compress",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3931,safety,error,error,3931,"en(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4022,safety,except,exception,4022,"2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4070,safety,except,exception,4070,"-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4136,safety,input,input-,4136,"ause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4163,safety,modul,module,4163,"tion:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5565,safety,except,except,5565,"packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5572,safety,Except,Exception,5572,"anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5673,safety,error,error,5673,". 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5803,safety,error,error,5803," dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5890,safety,error,error,5890,"s=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. dec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6231,safety,avoid,avoid,6231,"/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6475,safety,review,review,6475,"te-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8187,safety,log,logical,8187,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8239,safety,updat,updated,8239,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6725,security,certif,certifi,6725," TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:7749,security,soc,socks,7749,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8187,security,log,logical,8187,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8219,security,Session,Session,8219,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8239,security,updat,updated,8239,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1633,testability,Trace,Traceback,1633,"GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3183,testability,Trace,Traceback,3183,"**kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter). 139 if (data is not None) and (not isinstance(data, Empty)):. --> 140 dset_id.write(h5s.ALL, h5s.ALL, data). 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4092,testability,Trace,Traceback,4092,"ings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6475,testability,review,review,6475,"te-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8187,testability,log,logical,8187,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:160,usability,confirm,confirmed,160,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:243,usability,confirm,confirmed,243,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:334,usability,guid,guide,334,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:389,usability,minim,minimal-bug-reports,389,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:495,usability,Minim,Minimal,495,"Problem saving object: Can't implicitly convert non-string objects to strings; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1489,usability,error,error,1489,"## Minimal code sample (that we can copy&paste without having any data). Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python. import anndata. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.sparse import csr_matrix, csc_matrix. ```. - Read loom object. Takes ~ 4 hrs. . ```python. gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'). gex_matrix. ```. - Read in metadata . ```python. gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0). gex_matrix.obs = gex_metadata. gex_matrix.obs. ```. - Transform to `CSR` matrix. ```python. gex_matrix.X = csr_matrix(gex_matrix.X). gex_matrix.X. ```. - Save object. ```python. gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'). ```. However, I get the following error. Any ideas what this may be related to? . ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 269 if series.dtype == object: # Assuming it’s string. --> 270 group.create_dataset(. 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 147 . --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds). 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3931,usability,error,error,3931,"en(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4136,usability,input,input-,4136,"ause of the following exception:. TypeError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last). <ipython-input-17-f0b30fa7797a> in <module>. ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5673,usability,error,error,5673,". 109 else:. 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5803,usability,error,error,5803," dataset_kwargs=dataset_kwargs). 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5890,usability,error,error,5890,"s=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. dec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6148,usability,discov,discoverable,6148,"funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwiso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:7851,usability,tool,toolz,7851,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.4. -----. PIL 8.2.0. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. fsspec 2021.05.0. get_version 2.2. google NA. h5py 3.2.1. idna 2.10. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.7.0. llvmlite 0.36.0. loompy 3.0.6. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scipy 1.6.3. send2trash NA. six 1.16.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-06-04 10:04. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1867:78,availability,consist,consistently,78,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:312,deployability,updat,updated,312,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:516,deployability,updat,updated,516,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:955,deployability,updat,updated,955,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1141,deployability,depend,depending,1141,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1636,deployability,updat,update,1636,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:46,integrability,sub,subset,46,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:212,integrability,sub,subset,212,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:417,integrability,sub,subset,417,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:537,integrability,sub,subsetted,537,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:630,integrability,sub,subset,630,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:849,integrability,sub,subset,849,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1141,integrability,depend,depending,1141,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1480,integrability,sub,subset,1480,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1557,integrability,sub,subet,1557,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1685,integrability,batch,batch,1685,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1708,integrability,sub,subset,1708,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1810,integrability,batch,batch,1810,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1833,integrability,sub,subset,1833,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1141,modifiability,depend,depending,1141,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1685,performance,batch,batch,1685,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1810,performance,batch,batch,1810,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:22,reliability,doe,does,22,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:112,safety,test,tests,112,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:312,safety,updat,updated,312,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:516,safety,updat,updated,516,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:955,safety,updat,updated,955,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1141,safety,depend,depending,1141,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1636,safety,updat,update,1636,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:312,security,updat,updated,312,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:516,security,updat,updated,516,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:955,security,updat,updated,955,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1636,security,updat,update,1636,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:112,testability,test,tests,112,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1141,testability,depend,depending,1141,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:78,usability,consist,consistently,78,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:150,usability,behavi,behavior,150,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1948,usability,behavi,behavior,1948,"sc.pp.highly_variable does not always handle `subset` and `inplace` arguments consistently; Hey,. while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`. --> Returns nothing :heavy_check_mark: . --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`. --> output is a dataframe with the original number of genes as rows :heavy_check_mark: . --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`. --> Returns nothing :x: . --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```. if inplace: . . #update adata. . if batch_key is not None:. #drop batch related keys. if subset:. adata._inplace_subset_var(df['highly_variable'].values). else:. if batch_key is None:. #drop batch related keys. if subset: . df=df.iloc[df.highly_variable.values,:]. . return df. ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: . best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/pull/1868:0,deployability,updat,update,0,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/pull/1868:38,deployability,Updat,Updated,38,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/pull/1868:80,energy efficiency,current,current,80,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/pull/1868:0,safety,updat,update,0,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/pull/1868:38,safety,Updat,Updated,38,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/pull/1868:0,security,updat,update,0,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/pull/1868:38,security,Updat,Updated,38,update bbknn arguments and docstring; Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/issues/1869:839,availability,cluster,cluster,839,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:269,deployability,log,logfoldchanges,269,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:402,deployability,log,logfoldchanges,402,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:462,deployability,version,version,462,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:839,deployability,cluster,cluster,839,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:462,integrability,version,version,462,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:677,interoperability,format,formatting,677,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:74,modifiability,pac,package,74,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:380,modifiability,variab,variable,380,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:462,modifiability,version,version,462,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:759,modifiability,variab,variable,759,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:269,safety,log,logfoldchanges,269,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:402,safety,log,logfoldchanges,402,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:723,safety,test,test,723,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:269,security,log,logfoldchanges,269,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:402,security,log,logfoldchanges,402,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:269,testability,log,logfoldchanges,269,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:402,testability,log,logfoldchanges,402,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:723,testability,test,test,723,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:981,usability,help,helpful,981,"rank_genes_groups p value decimal places; Hi,. Thank you for your amazing package! I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? . Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1870:0,integrability,filter,filter,0,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:527,integrability,filter,filter,527,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:133,modifiability,paramet,parameters,133,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:410,modifiability,pac,package,410,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:215,testability,simpl,simple,215,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:207,usability,tool,tool,207,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:215,usability,simpl,simple,215,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:231,usability,tool,tool,231,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:279,usability,tool,tools,279,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1870:379,usability,tool,tools,379,"filter based on expression cutoff for two genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I need to filter the cells which expressed 'A' and 'B' genes >1. The below line should work for one gene but how to do it for two genes? `adata = adata[adata[: , 'A'].X > 1, :] `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1871:38,deployability,stack,stacked,38,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:584,deployability,stack,stacked,584,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:143,modifiability,paramet,parameters,143,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:420,modifiability,pac,package,420,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:225,testability,simpl,simple,225,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:217,usability,tool,tool,217,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:225,usability,simpl,simple,225,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:241,usability,tool,tool,241,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:289,usability,tool,tools,289,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1871:389,usability,tool,tools,389,why there is not expression_cutoff in stacked violin plot; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi. I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1872:18,deployability,version,version,18,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:158,deployability,version,version,158,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:572,deployability,log,logging,572,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:826,deployability,Version,Versions,826,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:930,deployability,log,logging,930,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:18,integrability,version,version,18,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:158,integrability,version,version,158,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:745,integrability,batch,batch,745,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:826,integrability,Version,Versions,826,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:18,modifiability,version,version,18,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:158,modifiability,version,version,158,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:826,modifiability,Version,Versions,826,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:745,performance,batch,batch,745,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:572,safety,log,logging,572,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:930,safety,log,logging,930,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:572,security,log,logging,572,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:930,security,log,logging,930,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:572,testability,log,logging,572,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:930,testability,log,logging,930,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:118,usability,confirm,confirmed,118,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:201,usability,confirm,confirmed,201,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:292,usability,guid,guide,292,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:347,usability,minim,minimal-bug-reports,347,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:453,usability,Minim,Minimal,453,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:887,usability,learn,learn,887,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:1091,usability,learn,learn,1091,"problem in latest version of scanpy (bbknn); - I have checked that this issue has not already been reported. - I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import bbknn. sc.logging.print_header(). adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') . sc.external.pp.bbknn(adata, batch_key='batch') #error2. ```. ```pytb. tuple' object has no attribute 'tocsr'. ```. #### Versions. <bbknn : 1.5.0>. <scanpy:1.7.0>. umap: 0.1.1. umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/pull/1873:54,deployability,version,versions,54,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:54,integrability,version,versions,54,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:54,modifiability,version,versions,54,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:448,safety,review,review,448,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:448,testability,review,review,448,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:299,usability,guid,guidelines,299,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:330,usability,guid,guide,330,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:426,usability,workflow,workflow,426,"n_trees is annoy_n_trees in bbknn 1.5.x; Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/issues/1874:0,availability,error,error,0,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:124,availability,error,error,124,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:552,availability,error,error,552,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:834,availability,error,error,834,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:626,deployability,Version,Versions,626,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:626,integrability,Version,Versions,626,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:11,interoperability,format,format,11,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:563,interoperability,format,format,563,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:352,modifiability,layer,layers,352,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:626,modifiability,Version,Versions,626,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:0,performance,error,error,0,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:124,performance,error,error,124,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:552,performance,error,error,552,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:834,performance,error,error,834,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:0,safety,error,error,0,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:77,safety,test,test,77,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:124,safety,error,error,124,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:149,safety,test,test,149,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:329,safety,test,test,329,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:552,safety,error,error,552,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:834,safety,error,error,834,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:77,testability,test,test,77,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:149,testability,test,test,149,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:329,testability,test,test,329,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:0,usability,error,error,0,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:124,usability,error,error,124,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:235,usability,Minim,Minimal,235,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:552,usability,error,error,552,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:726,usability,learn,learn,726,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:834,usability,error,error,834,"error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(); Is there anybody meeting the same error with me? I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python. test_sf = de.test.wald(. data=adata.layers['counts'],. formula_loc=""~ 1 + disease + size_factors"",. factor_loc_totest=""disease"",. as_numeric=['size_factors'],. gene_names=adata.var_names,. sample_description=adata.obs. ). ```. ```pytb. error: 'i' format requires -2147483648 <= number <= 2147483647. ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1875:559,availability,down,downstream,559,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:602,deployability,scale,scaled,602,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:602,energy efficiency,scale,scaled,602,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:112,modifiability,paramet,parameters,112,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:389,modifiability,pac,package,389,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:602,modifiability,scal,scaled,602,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:602,performance,scale,scaled,602,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:194,testability,simpl,simple,194,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:186,usability,tool,tool,186,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:194,usability,simpl,simple,194,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:210,usability,tool,tool,210,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:258,usability,tool,tools,258,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:358,usability,tool,tools,358,"which data type in adata.X; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one? Can I have all them in my h5ad object and how to switch between them? In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1876:756,energy efficiency,current,currently,756,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:30,modifiability,variab,variable,30,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:64,modifiability,variab,variable,64,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:158,modifiability,paramet,parameters,158,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:435,modifiability,pac,package,435,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:240,testability,simpl,simple,240,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:740,testability,understand,understand,740,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:232,usability,tool,tool,232,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:240,usability,simpl,simple,240,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:256,usability,tool,tool,256,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:304,usability,tool,tools,304,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:404,usability,tool,tools,404,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/issues/1876:976,usability,behavi,behavior,976,"dotplot with x axis being one variable and y axis being another variable; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/pull/1877:263,safety,review,review,263,Dict literal typos in _baseplot_class.py; . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/pull/1877:263,testability,review,review,263,Dict literal typos in _baseplot_class.py; . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/pull/1877:114,usability,guid,guidelines,114,Dict literal typos in _baseplot_class.py; . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/pull/1877:145,usability,guid,guide,145,Dict literal typos in _baseplot_class.py; . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/pull/1877:241,usability,workflow,workflow,241,Dict literal typos in _baseplot_class.py; . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/issues/1878:22,integrability,Discover,Discovery,22,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:22,interoperability,Discover,Discovery,22,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:14,performance,Network,Network,14,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:244,performance,network,network,244,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:404,safety,input,input,404,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:14,security,Network,Network,14,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:244,security,network,network,244,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:22,usability,Discov,Discovery,22,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:234,usability,intuit,intuitive,234,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1878:404,usability,input,input,404,"Add Cubé Gene Network Discovery To Scanpy Ecosystem; Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1879:122,modifiability,paramet,parameters,122,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:399,modifiability,pac,package,399,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:570,modifiability,variab,variable,570,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:204,testability,simpl,simple,204,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:196,usability,tool,tool,196,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:204,usability,simpl,simple,204,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:220,usability,tool,tool,220,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:268,usability,tool,tools,268,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:368,usability,tool,tools,368,umap for one gene split by condition; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to generate two umaps for one gene split by a condition[one variable in obs] ? so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function? https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1880:1101,integrability,standardiz,standardized,1101,"The seurat converted into anndata to analyze the trajectory inference occurred the weird circumstance; Hi ,. In my case, the seurat object using the sceasy algorithm to transfer into anndata object for trajectory inference analysis. The code lying below:. import numpy as np. import pandas as pd. import matplotlib.pyplot as pl. from matplotlib import rcParams. import scanpy as sc. sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(adata). sc.pl.draw_graph(adata, color='paul15_clusters', legend_loc='on data'). The picture showing confused result posted below:. ![Uploading image.png…](). The object information:. >>> adata. AnnData object with n_obs × n_vars = 17885 × 999. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'RNA_snn_res.0.5', 'seurat_clusters', 'pANN_0.25_0.02_752', 'DF.classifications_0.25_0.02_752', 'percent.rp', 'pANN_0.25_0.02_826', 'DF.classifications_0.25_0.02_826', 'group', 'celltype', 'n_counts_all'. var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'n_counts', 'mean', 'std'. uns: 'seurat_clusters_colors', 'log1p', 'pca', 'neighbors', 'draw_graph'. obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'. varm: 'PCs'. obsp: 'distances', 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1880
https://github.com/scverse/scanpy/issues/1880:1101,interoperability,standard,standardized,1101,"The seurat converted into anndata to analyze the trajectory inference occurred the weird circumstance; Hi ,. In my case, the seurat object using the sceasy algorithm to transfer into anndata object for trajectory inference analysis. The code lying below:. import numpy as np. import pandas as pd. import matplotlib.pyplot as pl. from matplotlib import rcParams. import scanpy as sc. sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(adata). sc.pl.draw_graph(adata, color='paul15_clusters', legend_loc='on data'). The picture showing confused result posted below:. ![Uploading image.png…](). The object information:. >>> adata. AnnData object with n_obs × n_vars = 17885 × 999. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'RNA_snn_res.0.5', 'seurat_clusters', 'pANN_0.25_0.02_752', 'DF.classifications_0.25_0.02_752', 'percent.rp', 'pANN_0.25_0.02_826', 'DF.classifications_0.25_0.02_826', 'group', 'celltype', 'n_counts_all'. var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'n_counts', 'mean', 'std'. uns: 'seurat_clusters_colors', 'log1p', 'pca', 'neighbors', 'draw_graph'. obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'. varm: 'PCs'. obsp: 'distances', 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1880
https://github.com/scverse/scanpy/issues/1880:1121,modifiability,variab,variable,1121,"The seurat converted into anndata to analyze the trajectory inference occurred the weird circumstance; Hi ,. In my case, the seurat object using the sceasy algorithm to transfer into anndata object for trajectory inference analysis. The code lying below:. import numpy as np. import pandas as pd. import matplotlib.pyplot as pl. from matplotlib import rcParams. import scanpy as sc. sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(adata). sc.pl.draw_graph(adata, color='paul15_clusters', legend_loc='on data'). The picture showing confused result posted below:. ![Uploading image.png…](). The object information:. >>> adata. AnnData object with n_obs × n_vars = 17885 × 999. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'RNA_snn_res.0.5', 'seurat_clusters', 'pANN_0.25_0.02_752', 'DF.classifications_0.25_0.02_752', 'percent.rp', 'pANN_0.25_0.02_826', 'DF.classifications_0.25_0.02_826', 'group', 'celltype', 'n_counts_all'. var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'n_counts', 'mean', 'std'. uns: 'seurat_clusters_colors', 'log1p', 'pca', 'neighbors', 'draw_graph'. obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'. varm: 'PCs'. obsp: 'distances', 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1880
https://github.com/scverse/scanpy/issues/1880:772,security,ident,ident,772,"The seurat converted into anndata to analyze the trajectory inference occurred the weird circumstance; Hi ,. In my case, the seurat object using the sceasy algorithm to transfer into anndata object for trajectory inference analysis. The code lying below:. import numpy as np. import pandas as pd. import matplotlib.pyplot as pl. from matplotlib import rcParams. import scanpy as sc. sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20). sc.tl.draw_graph(adata). sc.pl.draw_graph(adata, color='paul15_clusters', legend_loc='on data'). The picture showing confused result posted below:. ![Uploading image.png…](). The object information:. >>> adata. AnnData object with n_obs × n_vars = 17885 × 999. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'RNA_snn_res.0.5', 'seurat_clusters', 'pANN_0.25_0.02_752', 'DF.classifications_0.25_0.02_752', 'percent.rp', 'pANN_0.25_0.02_826', 'DF.classifications_0.25_0.02_826', 'group', 'celltype', 'n_counts_all'. var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'n_counts', 'mean', 'std'. uns: 'seurat_clusters_colors', 'log1p', 'pca', 'neighbors', 'draw_graph'. obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'. varm: 'PCs'. obsp: 'distances', 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1880
https://github.com/scverse/scanpy/issues/1881:290,deployability,version,version,290,Public function for accessing category colors; I noticed that the order of .uns['leiden_colors'] might have changed. Previously I had a set of codes to extract color codes from that attribute and save into a dictionary. May I ask what's the proper way to extract color codes in the current version of Scanpy? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881
https://github.com/scverse/scanpy/issues/1881:282,energy efficiency,current,current,282,Public function for accessing category colors; I noticed that the order of .uns['leiden_colors'] might have changed. Previously I had a set of codes to extract color codes from that attribute and save into a dictionary. May I ask what's the proper way to extract color codes in the current version of Scanpy? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881
https://github.com/scverse/scanpy/issues/1881:0,integrability,Pub,Public,0,Public function for accessing category colors; I noticed that the order of .uns['leiden_colors'] might have changed. Previously I had a set of codes to extract color codes from that attribute and save into a dictionary. May I ask what's the proper way to extract color codes in the current version of Scanpy? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881
https://github.com/scverse/scanpy/issues/1881:290,integrability,version,version,290,Public function for accessing category colors; I noticed that the order of .uns['leiden_colors'] might have changed. Previously I had a set of codes to extract color codes from that attribute and save into a dictionary. May I ask what's the proper way to extract color codes in the current version of Scanpy? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881
https://github.com/scverse/scanpy/issues/1881:290,modifiability,version,version,290,Public function for accessing category colors; I noticed that the order of .uns['leiden_colors'] might have changed. Previously I had a set of codes to extract color codes from that attribute and save into a dictionary. May I ask what's the proper way to extract color codes in the current version of Scanpy? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881
https://github.com/scverse/scanpy/issues/1881:20,security,access,accessing,20,Public function for accessing category colors; I noticed that the order of .uns['leiden_colors'] might have changed. Previously I had a set of codes to extract color codes from that attribute and save into a dictionary. May I ask what's the proper way to extract color codes in the current version of Scanpy? Thanks,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1881
https://github.com/scverse/scanpy/issues/1882:131,modifiability,paramet,parameters,131,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:408,modifiability,pac,package,408,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:213,testability,simpl,simple,213,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:205,usability,tool,tool,205,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:213,usability,simpl,simple,213,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:229,usability,tool,tool,229,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:277,usability,tool,tools,277,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/issues/1882:377,usability,tool,tools,377,How to convert from Seurat visium to AnnData?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/pull/1883:16,usability,Learn,Learning,16,Added Cube Gene Learning Algorithm to Ecosystem;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1883
https://github.com/scverse/scanpy/pull/1884:264,safety,review,review,264,"Better strategy to compare two color arrays; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/pull/1884:264,testability,review,review,264,"Better strategy to compare two color arrays; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/pull/1884:115,usability,guid,guidelines,115,"Better strategy to compare two color arrays; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/pull/1884:146,usability,guid,guide,146,"Better strategy to compare two color arrays; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/pull/1884:242,usability,workflow,workflow,242,"Better strategy to compare two color arrays; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/issues/1885:498,availability,error,error,498,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:719,availability,error,errors,719,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5359,availability,error,error,5359,"turn bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all po",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6692,availability,error,errors,6692,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:247,deployability,contain,contains,247,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:706,deployability,releas,release,706,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:939,deployability,modul,module,939,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6427,deployability,version,versions,6427,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:698,energy efficiency,current,current,698,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:2422,energy efficiency,core,core,2422,"s, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:2714,energy efficiency,core,core,2714,"utline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 31",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3033,energy efficiency,core,core,3033,"tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3348,energy efficiency,core,core,3348,"lues. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3635,energy efficiency,core,core,3635,"d. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3931,energy efficiency,core,core,3931,"ered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4275,energy efficiency,core,core,4275,"ype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImpl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4570,energy efficiency,core,core,4570,"iniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4824,energy efficiency,core,core,4824,"5 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5001,energy efficiency,core,core,5001,"if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to sp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:1546,integrability,compon,components,1546,"n as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6427,integrability,version,versions,6427,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:310,interoperability,specif,specific,310,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:1546,interoperability,compon,components,1546,"n as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5685,interoperability,specif,specify,5685," # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # Th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6001,interoperability,specif,specify,6001,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6317,interoperability,specif,specify,6317,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:334,modifiability,paramet,parameter,334,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:939,modifiability,modul,module,939,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:1085,modifiability,pac,packages,1085," https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:1352,modifiability,pac,packages,1352,"s function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:1546,modifiability,compon,components,1546,"n as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:1558,modifiability,layer,layer,1558,"sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_cod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:2009,modifiability,pac,packages,2009,"mc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:2406,modifiability,pac,packages,2406,"ng(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:2698,modifiability,pac,packages,2698,", legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3017,modifiability,pac,packages,3017,"npy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3332,modifiability,pac,packages,3332,"all missing values. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3619,modifiability,pac,packages,3619,"ed=self.ordered. 1200 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:3915,modifiability,pac,packages,3915,"ategories, ordered=ordered, dtype=dtype. 571 ). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4259,modifiability,pac,packages,4259," 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4554,modifiability,pac,packages,4554,"assmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4808,modifiability,pac,packages,4808,"=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4985,modifiability,pac,packages,4985,"astpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if yo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6427,modifiability,version,versions,6427,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:498,performance,error,error,498,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:719,performance,error,errors,719,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4183,performance,Cach,CachedProperty,4183,"rdered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4478,performance,Cach,CachedProperty,4478,"-> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, wh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5359,performance,error,error,5359,"turn bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all po",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6692,performance,error,errors,6692,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:498,safety,error,error,498,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:719,safety,error,errors,719,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:913,safety,input,input-,913,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:939,safety,modul,module,939,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5359,safety,error,error,5359,"turn bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all po",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5499,safety,avoid,avoided,5499," ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5815,safety,avoid,avoided,5815,"ndas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6131,safety,avoid,avoided,6131,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6692,safety,error,errors,6692,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5056,security,hack,hack,5056," 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:869,testability,Trace,Traceback,869,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:498,usability,error,error,498,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:719,usability,error,errors,719,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:913,usability,input,input-,913,"seaborn.set_theme causing issues with color mapping; _Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`! > . > The following code should reproduce the error:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. -------------------------------. On current release this errors:. <details>. <summary> </summary>. ```python. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-1-4c43dbe94eaf> in <module>. 4 . 5 pbmc = sc.datasets.pbmc68k_reduced(). ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5359,usability,error,error,5359,"turn bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all po",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6692,usability,error,errors,6692,"9 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. I don't get an error from this on master, but I do get these warnings. ```. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points. ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python. import scanpy as sc. import seaborn as sns. sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]. ```. ```. [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),. (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),. (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/pull/1886:169,availability,error,errors,169,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:169,performance,error,errors,169,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:121,safety,compl,complains,121,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:169,safety,error,errors,169,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:268,safety,valid,validation,268,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:287,safety,valid,validate,287,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:121,security,compl,complains,121,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:268,security,validat,validation,268,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:287,security,validat,validate,287,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:169,usability,error,errors,169,"Set theme fix; If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/issues/1887:849,integrability,sub,subplots,849,"Issue with sc.pl.paga_compare(); Hello everyone,. I encounter a problem with the sc.pl.paga_compare() function. I have a very strange PAGA representation with edges that look messy. Do you have any idea about the source of the problem ? ```python. adata = ad.AnnData(DATA, var=GG). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata). sc.pp.neighbors(adata, n_neighbors= 25). sc.tl.leiden(adata). sc.tl.paga(adata, groups='leiden'). sc.pl.paga(adata). ```. ![Capture3](https://user-images.githubusercontent.com/25744843/122538688-16d08b80-d027-11eb-9355-c3217e16316d.PNG). ```python. sc.tl.umap(adata, init_pos='paga'). sc.pl.umap(adata, groups='leiden'). sc.pl.paga_compare(adata, basis='umap'). ```. ![Capture1](https://user-images.githubusercontent.com/25744843/122538500-e852b080-d026-11eb-838e-c7e0e0faae73.PNG). ```python. fig1, ax1 = plt.subplots(). sc.pl.umap(adata, size=40, ax=ax1, show=False). sc.pl.paga(adata, pos=adata.uns['paga']['pos'], show=False, node_size_scale=10,. node_size_power=1, ax=ax1, text_kwds={'alpha':0}, threshold = 0). ```. ![Capture2](https://user-images.githubusercontent.com/25744843/122538553-f6a0cc80-d026-11eb-88b0-056fcdf2b114.PNG). . thanks . Nicolas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1887
https://github.com/scverse/scanpy/issues/1887:481,usability,user,user-images,481,"Issue with sc.pl.paga_compare(); Hello everyone,. I encounter a problem with the sc.pl.paga_compare() function. I have a very strange PAGA representation with edges that look messy. Do you have any idea about the source of the problem ? ```python. adata = ad.AnnData(DATA, var=GG). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata). sc.pp.neighbors(adata, n_neighbors= 25). sc.tl.leiden(adata). sc.tl.paga(adata, groups='leiden'). sc.pl.paga(adata). ```. ![Capture3](https://user-images.githubusercontent.com/25744843/122538688-16d08b80-d027-11eb-9355-c3217e16316d.PNG). ```python. sc.tl.umap(adata, init_pos='paga'). sc.pl.umap(adata, groups='leiden'). sc.pl.paga_compare(adata, basis='umap'). ```. ![Capture1](https://user-images.githubusercontent.com/25744843/122538500-e852b080-d026-11eb-838e-c7e0e0faae73.PNG). ```python. fig1, ax1 = plt.subplots(). sc.pl.umap(adata, size=40, ax=ax1, show=False). sc.pl.paga(adata, pos=adata.uns['paga']['pos'], show=False, node_size_scale=10,. node_size_power=1, ax=ax1, text_kwds={'alpha':0}, threshold = 0). ```. ![Capture2](https://user-images.githubusercontent.com/25744843/122538553-f6a0cc80-d026-11eb-88b0-056fcdf2b114.PNG). . thanks . Nicolas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1887
https://github.com/scverse/scanpy/issues/1887:726,usability,user,user-images,726,"Issue with sc.pl.paga_compare(); Hello everyone,. I encounter a problem with the sc.pl.paga_compare() function. I have a very strange PAGA representation with edges that look messy. Do you have any idea about the source of the problem ? ```python. adata = ad.AnnData(DATA, var=GG). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata). sc.pp.neighbors(adata, n_neighbors= 25). sc.tl.leiden(adata). sc.tl.paga(adata, groups='leiden'). sc.pl.paga(adata). ```. ![Capture3](https://user-images.githubusercontent.com/25744843/122538688-16d08b80-d027-11eb-9355-c3217e16316d.PNG). ```python. sc.tl.umap(adata, init_pos='paga'). sc.pl.umap(adata, groups='leiden'). sc.pl.paga_compare(adata, basis='umap'). ```. ![Capture1](https://user-images.githubusercontent.com/25744843/122538500-e852b080-d026-11eb-838e-c7e0e0faae73.PNG). ```python. fig1, ax1 = plt.subplots(). sc.pl.umap(adata, size=40, ax=ax1, show=False). sc.pl.paga(adata, pos=adata.uns['paga']['pos'], show=False, node_size_scale=10,. node_size_power=1, ax=ax1, text_kwds={'alpha':0}, threshold = 0). ```. ![Capture2](https://user-images.githubusercontent.com/25744843/122538553-f6a0cc80-d026-11eb-88b0-056fcdf2b114.PNG). . thanks . Nicolas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1887
https://github.com/scverse/scanpy/issues/1887:1081,usability,user,user-images,1081,"Issue with sc.pl.paga_compare(); Hello everyone,. I encounter a problem with the sc.pl.paga_compare() function. I have a very strange PAGA representation with edges that look messy. Do you have any idea about the source of the problem ? ```python. adata = ad.AnnData(DATA, var=GG). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata). sc.pp.neighbors(adata, n_neighbors= 25). sc.tl.leiden(adata). sc.tl.paga(adata, groups='leiden'). sc.pl.paga(adata). ```. ![Capture3](https://user-images.githubusercontent.com/25744843/122538688-16d08b80-d027-11eb-9355-c3217e16316d.PNG). ```python. sc.tl.umap(adata, init_pos='paga'). sc.pl.umap(adata, groups='leiden'). sc.pl.paga_compare(adata, basis='umap'). ```. ![Capture1](https://user-images.githubusercontent.com/25744843/122538500-e852b080-d026-11eb-838e-c7e0e0faae73.PNG). ```python. fig1, ax1 = plt.subplots(). sc.pl.umap(adata, size=40, ax=ax1, show=False). sc.pl.paga(adata, pos=adata.uns['paga']['pos'], show=False, node_size_scale=10,. node_size_power=1, ax=ax1, text_kwds={'alpha':0}, threshold = 0). ```. ![Capture2](https://user-images.githubusercontent.com/25744843/122538553-f6a0cc80-d026-11eb-88b0-056fcdf2b114.PNG). . thanks . Nicolas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1887
https://github.com/scverse/scanpy/issues/1888:137,availability,error,error,137,"Bug in rank_genes_groups_violin ; When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: . ```. ValueError: Data must be 1-dimensional. ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/issues/1888:122,deployability,fail,fails,122,"Bug in rank_genes_groups_violin ; When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: . ```. ValueError: Data must be 1-dimensional. ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/issues/1888:137,performance,error,error,137,"Bug in rank_genes_groups_violin ; When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: . ```. ValueError: Data must be 1-dimensional. ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/issues/1888:122,reliability,fail,fails,122,"Bug in rank_genes_groups_violin ; When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: . ```. ValueError: Data must be 1-dimensional. ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/issues/1888:137,safety,error,error,137,"Bug in rank_genes_groups_violin ; When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: . ```. ValueError: Data must be 1-dimensional. ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/issues/1888:137,usability,error,error,137,"Bug in rank_genes_groups_violin ; When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: . ```. ValueError: Data must be 1-dimensional. ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/issues/1889:193,usability,user,user-images,193,"The saving plot had prefix; Hi,. It still had the prefix in plot even though i set the :. sc.settings.plot_suffix="""". sc.settings.plot_prefix="""". The saving plot name like:. . ![image](https://user-images.githubusercontent.com/41668708/122671142-dbd18200-d1f7-11eb-929b-a4e176010f43.png). how can i fix it? Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1889
https://github.com/scverse/scanpy/pull/1890:422,energy efficiency,adapt,adapted,422,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:422,integrability,adapt,adapted,422,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:422,interoperability,adapt,adapted,422,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:422,modifiability,adapt,adapted,422,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:434,safety,test,tests,434,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:434,testability,test,tests,434,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:209,usability,behavi,behaviour,209,"Score genes reproducibility fix; As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1891:298,deployability,fail,fail,298,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:478,deployability,log,logic,478,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:28,modifiability,variab,variables,28,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:122,modifiability,variab,variables,122,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:179,modifiability,variab,variable,179,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:274,modifiability,variab,variable,274,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:574,performance,Perform,Performance,574,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:298,reliability,fail,fail,298,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:478,safety,log,logic,478,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:478,security,log,logic,478,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:478,testability,log,logic,478,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:69,usability,behavi,behaviour,69,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:224,usability,user,user,224,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:574,usability,Perform,Performance,574,"Fix graph metrics when some variables are constant; Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way. * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/issues/1892:311,availability,ping,ping,311,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:21,deployability,updat,update,21,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:66,deployability,fail,failing,66,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:87,deployability,updat,updated,87,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:56,energy efficiency,current,currently,56,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:275,modifiability,paramet,parameters,275,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:66,reliability,fail,failing,66,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:21,safety,updat,update,21,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:35,safety,test,tests,35,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:46,safety,test,tests,46,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:87,safety,updat,updated,87,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:134,safety,test,tests,134,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:303,safety,test,test,303,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:21,security,updat,update,21,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:87,security,updat,updated,87,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:35,testability,test,tests,35,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:46,testability,test,tests,46,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:134,testability,test,tests,134,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:303,testability,test,test,303,"scipy mann-whitney U update breaks tests; The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/pull/1893:146,availability,error,error,146,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:0,deployability,Updat,Update,0,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:161,modifiability,variab,variables,161,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:146,performance,error,error,146,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:0,safety,Updat,Update,0,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:12,safety,test,test,12,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:117,safety,test,tests,117,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:146,safety,error,error,146,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:0,security,Updat,Update,0,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:7,testability,unit,unit,7,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:12,testability,test,test,12,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:117,testability,test,tests,117,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:146,usability,error,error,146,"Update unit test for mannwhitneyu to work with scipy 1.7; Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/issues/1894:111,availability,operat,operation,111,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:789,availability,error,error,789,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:828,energy efficiency,current,current,828,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:90,performance,perform,performs,90,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:341,performance,parallel,parallel,341,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:789,performance,error,error,789,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:307,reliability,pra,prange,307,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:507,reliability,pra,prange,507,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:204,safety,review,reviewing,204,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:789,safety,error,error,789,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:204,testability,review,reviewing,204,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:90,usability,perform,performs,90,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:538,usability,stop,stop,538,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:578,usability,stop,stop,578,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:789,usability,error,error,789,"_sparse_nanmean is inefficient; `_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>. <summary> possible solution </summary>. ```python. from numba import njit, prange. import numpy as np. @njit(parallel=True). def nanmean_lowlevel(data, indices, indptr, shape):. N, M = shape. sums = np.zeros(N, dtype=np.float64). nans = np.zeros(N, dtype=np.int64). for i in prange(N):. start = indptr[i]. stop = indptr[i+1]. window = data[start:stop]. n_nan = np.int64(0). i_sum = np.float64(0.). for j_val in window:. if np.isnan(j_val):. n_nan += 1. else:. i_sum += j_val. sums[i] = i_sum. nans[i] = n_nan. sums /= (M - nans). return sums. ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/pull/1895:308,availability,down,downstream,308,"If raw was not used, use_raw should be False; On current master:. ```python. import scanpy as sc. a = sc.datasets.krumsiek11(). assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]. # True. ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895
https://github.com/scverse/scanpy/pull/1895:49,energy efficiency,current,current,49,"If raw was not used, use_raw should be False; On current master:. ```python. import scanpy as sc. a = sc.datasets.krumsiek11(). assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]. # True. ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895
https://github.com/scverse/scanpy/pull/1895:128,testability,assert,assert,128,"If raw was not used, use_raw should be False; On current master:. ```python. import scanpy as sc. a = sc.datasets.krumsiek11(). assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]. # True. ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895
https://github.com/scverse/scanpy/issues/1896:142,availability,error,error,142,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:171,availability,error,error,171,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:50,deployability,instal,installed,50,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:501,deployability,Version,Versions,501,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:686,deployability,contain,container,686,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:995,deployability,modul,module,995,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2211,deployability,contain,container,2211,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2350,deployability,modul,module,2350,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2363,deployability,instal,installed,2363,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2513,deployability,modul,module,2513,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2526,deployability,instal,installed,2526,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2547,deployability,Version,Versions,2547,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:501,integrability,Version,Versions,501,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1336,integrability,wrap,wrapper,1336,"(https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1923,integrability,wrap,wrapper,1923,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2547,integrability,Version,Versions,2547,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:481,interoperability,compatib,compatible,481,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1336,interoperability,wrapper,wrapper,1336,"(https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1923,interoperability,wrapper,wrapper,1923,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:501,modifiability,Version,Versions,501,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:640,modifiability,pac,packages,640,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:995,modifiability,modul,module,995,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1578,modifiability,pac,packages,1578,"ast). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official biocon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2165,modifiability,pac,packages,2165,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2350,modifiability,modul,module,2350,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2513,modifiability,modul,module,2513,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2547,modifiability,Version,Versions,2547,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:142,performance,error,error,142,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:171,performance,error,error,171,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:142,safety,error,error,142,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:171,safety,error,error,171,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:776,safety,except,except,776,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:871,safety,except,exception,871,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:890,safety,except,exception,890,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:967,safety,input,input-,967,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:995,safety,modul,module,995,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2250,safety,except,except,2250,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2350,safety,modul,module,2350,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2513,safety,modul,module,2513,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:553,testability,Trace,Traceback,553,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:923,testability,Trace,Traceback,923,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:142,usability,error,error,142,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:171,usability,error,error,171,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:967,usability,input,input-,967,"ImportError for GProfiler in sc.queries.enrich; I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb. ImportError Traceback (most recent call last). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 264 try:. --> 265 from gprofiler import GProfiler. 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return disp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2713,usability,learn,learn,2713,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-383-c1b09359d1a1> in <module>. 14 . 15 #get gene set enrichment. ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))). 17 . 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs). 305 else:. 306 gene_list = list(de[""names""].dropna()). --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw). 805 '1 positional argument'). 806 . --> 807 return dispatch(args[0].__class__)(*args, **kw). 808 . 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs). 266 except ImportError:. 267 raise ImportError(. --> 268 ""This method requires the `gprofiler-official` module to be installed."". 269 ). 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed. ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/pull/1897:97,deployability,updat,updating,97,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:180,deployability,instal,install,180,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:192,deployability,depend,dependencies,192,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:320,deployability,build,building,320,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:192,integrability,depend,dependencies,192,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:69,interoperability,compatib,compatibility,69,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:192,modifiability,depend,dependencies,192,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:172,performance,time,time,172,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:246,performance,cach,cached,246,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:285,performance,cach,cache,285,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:97,safety,updat,updating,97,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:192,safety,depend,dependencies,192,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:97,security,updat,updating,97,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:192,testability,depend,dependencies,192,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:16,usability,support,support,16,"Drop python 3.6 support; Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1898:419,availability,error,errors,419,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:523,availability,error,error,523,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3962,availability,avail,available,3962,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:244,deployability,log,logic,244,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1061,deployability,modul,module,1061,"dinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:443,energy efficiency,current,current,443,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2989,energy efficiency,draw,drawing,2989,"width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3478,energy efficiency,draw,drawing,3478,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1339,integrability,compon,components,1339,"side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:60,interoperability,coordinat,coordinates,60,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1339,interoperability,compon,components,1339,"side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1061,modifiability,modul,module,1061,"dinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1339,modifiability,compon,components,1339,"side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2971,modifiability,pac,packages,2971,"h_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3460,modifiability,pac,packages,3460,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:419,performance,error,errors,419,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:523,performance,error,error,523,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2980,performance,network,networkx,2980,"min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3469,performance,network,networkx,3469,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3896,reliability,doe,doesn,3896,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3962,reliability,availab,available,3962,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:244,safety,log,logic,244,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:419,safety,error,errors,419,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:523,safety,error,error,523,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1034,safety,input,input-,1034,"s #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, lef",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1061,safety,modul,module,1061,"dinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3962,safety,avail,available,3962,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:4123,safety,Test,Test,4123,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:244,security,log,logic,244,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:318,security,hack,hack,318,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2980,security,network,networkx,2980,"min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3469,security,network,networkx,3469,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3962,security,availab,available,3962,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:244,testability,log,logic,244,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:871,testability,trace,traceback,871,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:990,testability,Trace,Traceback,990,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2815,testability,simpl,simplefilter,2815,"abels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:4123,testability,Test,Test,4123,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:419,usability,error,errors,419,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:523,usability,error,error,523,"Fix paga_compare node positions; Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:1034,usability,input,input-,1034,"s #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, lef",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2815,usability,simpl,simplefilter,2815,"abels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3760,usability,user,user-images,3760,"xport_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921). - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/issues/1899:16,deployability,build,building,16,Latest docs not building; `latest` docs haven't been building for a few days. Not sure what's causing this yet. There seems to be some issue around malformed doc strings being generated due to special casing around readthedocs. It looks like it might be specific to an import to `legacy_api_wrap`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1899
https://github.com/scverse/scanpy/issues/1899:53,deployability,build,building,53,Latest docs not building; `latest` docs haven't been building for a few days. Not sure what's causing this yet. There seems to be some issue around malformed doc strings being generated due to special casing around readthedocs. It looks like it might be specific to an import to `legacy_api_wrap`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1899
https://github.com/scverse/scanpy/issues/1899:254,interoperability,specif,specific,254,Latest docs not building; `latest` docs haven't been building for a few days. Not sure what's causing this yet. There seems to be some issue around malformed doc strings being generated due to special casing around readthedocs. It looks like it might be specific to an import to `legacy_api_wrap`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1899
https://github.com/scverse/scanpy/pull/1900:9,availability,failur,failures,9,Test rtd failures; Attempts to fix #1899,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900
https://github.com/scverse/scanpy/pull/1900:9,deployability,fail,failures,9,Test rtd failures; Attempts to fix #1899,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900
https://github.com/scverse/scanpy/pull/1900:9,performance,failur,failures,9,Test rtd failures; Attempts to fix #1899,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900
https://github.com/scverse/scanpy/pull/1900:9,reliability,fail,failures,9,Test rtd failures; Attempts to fix #1899,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900
https://github.com/scverse/scanpy/pull/1900:0,safety,Test,Test,0,Test rtd failures; Attempts to fix #1899,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900
https://github.com/scverse/scanpy/pull/1900:0,testability,Test,Test,0,Test rtd failures; Attempts to fix #1899,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900
https://github.com/scverse/scanpy/issues/1901:42,availability,down,down-regulated,42,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:116,availability,down,downregulated,116,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:258,availability,down,down,258,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:352,availability,down,downregulated,352,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:458,availability,down,downregulated,458,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:826,deployability,API,API,826,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:1062,deployability,contain,container,1062,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:584,energy efficiency,current,current,584,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:826,integrability,API,API,826,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:826,interoperability,API,API,826,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:1156,modifiability,paramet,parameters,1156,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:4,reliability,doe,does,4,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:68,reliability,doe,does,68,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:176,safety,input,input,176,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:376,safety,input,input,376,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:592,testability,understand,understanding,592,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:176,usability,input,input,176,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:376,usability,input,input,376,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:1026,usability,document,documentation,1026,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:1114,usability,help,helpful,1114,"how does sc.queries.enrich handle up- and down-regulated genes; How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct? More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created? p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/pull/1902:15,deployability,build,builds,15,Try fixing doc builds – pinning get_version; Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1902:71,deployability,version,versions,71,Try fixing doc builds – pinning get_version; Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1902:71,integrability,version,versions,71,Try fixing doc builds – pinning get_version; Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1902:71,modifiability,version,versions,71,Try fixing doc builds – pinning get_version; Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1902:45,safety,Test,Testing,45,Try fixing doc builds – pinning get_version; Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1902:45,testability,Test,Testing,45,Try fixing doc builds – pinning get_version; Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1903:59,testability,plan,plan,59,Prepare for deprecation of dtypes; Prepare for deprecation plan for `dtype` in `AnnData` constructor.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1903
https://github.com/scverse/scanpy/pull/1904:9,deployability,releas,release,9,"Finalize release notes; @giovp, could you check the 1.8.0 release notes to make sure I got everyone's names?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1904
https://github.com/scverse/scanpy/pull/1904:58,deployability,releas,release,58,"Finalize release notes; @giovp, could you check the 1.8.0 release notes to make sure I got everyone's names?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1904
https://github.com/scverse/scanpy/pull/1905:9,deployability,releas,release,9,Finalize release notes;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1905
https://github.com/scverse/scanpy/pull/1906:6,deployability,releas,release,6,Start release notes for 1.9.0;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1906
https://github.com/scverse/scanpy/pull/1907:12,deployability,releas,release,12,Start 1.8.1 release notes;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1907
https://github.com/scverse/scanpy/issues/1908:369,availability,down,down-sampled,369,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:161,modifiability,design decis,design decisions,161,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:24,safety,test,test,24,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:270,safety,test,tests,270,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:494,safety,test,testing,494,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:19,testability,unit,unit,19,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:24,testability,test,test,24,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:270,testability,test,tests,270,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:489,testability,unit,unit,489,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:494,testability,test,testing,494,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:59,usability,help,help,59,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:518,usability,clear,clear,518,"What is the scanpy unit test dataset?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated? I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1909:0,deployability,Build,Build,0,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:45,deployability,build,build,45,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:68,deployability,build,build,68,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:234,deployability,build,build,234,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:1008,deployability,toggl,toggleswitch,1008,"having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/scanpy/get/__in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:2075,deployability,log,logging,2075,0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/scanpy/get/__init__.py. scanpy-1.8.0/scanpy/get/get.py. scanpy-1.8.0/scanpy/logging.py. scanpy-1.8.0/scanpy/metrics/__init__.py. scanpy-1.8.0/scanpy/metrics/_gearys_c.py. scanpy-1.8.0/scanpy/metrics/_metrics.py. scanpy-1.8.0/scanpy/metrics/_morans_i.py. scanpy-1.8.0/scanpy/neighbors/__init__.py. scanpy-1.8.0/scanpy/plotting/__init__.py. scanpy-1.8.0/scanpy/plotting/_anndata.py. scanpy-1.8.0/scanpy/plotting/_baseplot_class.py. scanpy-1.8.0/scanpy/plotting/_docs.py. scanpy-1.8.0/scanpy/plotting/_dotplot.py. scanpy-1.8.0/scanpy/plotting/_matrixplot.py. scanpy-1.8.0/scanpy/plotting/_preprocessing.py. scanpy-1.8.0/scanpy/plotting/_qc.py. scanpy-1.8.0/scanpy/plotting/_rcmod.py. scanpy-1.8.0/scanpy/plotting/_stacked_violin.py. scanpy-1.8.0/scanpy/plotting/_tools/__init__.py. scanpy-1.8.0/scanpy/plotting/_tools/paga.py. scanpy-1.8.0/scanpy/plotting/_tools/scatterplots.py. scanpy-1.8.0/scanpy/plotting/_utils.py. scanpy-1.8.0/scanpy/plotting/palettes.py. scanpy-1.8.0/scanpy/preprocessing/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_combat.py. scanpy-1.8.0/scanpy/preproce,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:3906,deployability,toggl,toggleswitch,3906,"py. scanpy-1.8.0/scanpy/plotting/palettes.py. scanpy-1.8.0/scanpy/preprocessing/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_combat.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4836,deployability,build,build,4836,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4857,deployability,build,build,4857,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4919,deployability,version,version,4919,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4969,deployability,build,build,4969,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:37,energy efficiency,Current,Current,37,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:60,energy efficiency,Current,Current,60,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4919,integrability,version,version,4919,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4919,modifiability,version,version,4919,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:319,performance,content,contents,319,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:101,reliability,doe,does,101,"Build process having some issues; ## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```. git checkout 1.8.0. python -m build --sdist --wheel . tar tzf dist/scanpy-1.8.0.tar.gz . ```. <details>. <summary> contents of source dist </summary>. ```. scanpy-1.8.0/README.rst. scanpy-1.8.0/pyproject.toml. scanpy-1.8.0/scanpy/__init__.py. scanpy-1.8.0/scanpy/__main__.py. scanpy-1.8.0/scanpy/_compat.py. scanpy-1.8.0/scanpy/_metadata.py. scanpy-1.8.0/scanpy/_settings.py. scanpy-1.8.0/scanpy/_utils/__init__.py. scanpy-1.8.0/scanpy/_utils/compute/is_constant.py. scanpy-1.8.0/scanpy/cli.py. scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad. scanpy-1.8.0/scanpy/datasets/__init__.py. scanpy-1.8.0/scanpy/datasets/_datasets.py. scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py. scanpy-1.8.0/scanpy/datasets/_utils.py. scanpy-1.8.0/scanpy/datasets/krumsiek11.txt. scanpy-1.8.0/scanpy/datasets/toggleswitch.txt. scanpy-1.8.0/scanpy/external/__init__.py. scanpy-1.8.0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:2075,safety,log,logging,2075,0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/scanpy/get/__init__.py. scanpy-1.8.0/scanpy/get/get.py. scanpy-1.8.0/scanpy/logging.py. scanpy-1.8.0/scanpy/metrics/__init__.py. scanpy-1.8.0/scanpy/metrics/_gearys_c.py. scanpy-1.8.0/scanpy/metrics/_metrics.py. scanpy-1.8.0/scanpy/metrics/_morans_i.py. scanpy-1.8.0/scanpy/neighbors/__init__.py. scanpy-1.8.0/scanpy/plotting/__init__.py. scanpy-1.8.0/scanpy/plotting/_anndata.py. scanpy-1.8.0/scanpy/plotting/_baseplot_class.py. scanpy-1.8.0/scanpy/plotting/_docs.py. scanpy-1.8.0/scanpy/plotting/_dotplot.py. scanpy-1.8.0/scanpy/plotting/_matrixplot.py. scanpy-1.8.0/scanpy/plotting/_preprocessing.py. scanpy-1.8.0/scanpy/plotting/_qc.py. scanpy-1.8.0/scanpy/plotting/_rcmod.py. scanpy-1.8.0/scanpy/plotting/_stacked_violin.py. scanpy-1.8.0/scanpy/plotting/_tools/__init__.py. scanpy-1.8.0/scanpy/plotting/_tools/paga.py. scanpy-1.8.0/scanpy/plotting/_tools/scatterplots.py. scanpy-1.8.0/scanpy/plotting/_utils.py. scanpy-1.8.0/scanpy/plotting/palettes.py. scanpy-1.8.0/scanpy/preprocessing/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_combat.py. scanpy-1.8.0/scanpy/preproce,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:2075,security,log,logging,2075,0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/scanpy/get/__init__.py. scanpy-1.8.0/scanpy/get/get.py. scanpy-1.8.0/scanpy/logging.py. scanpy-1.8.0/scanpy/metrics/__init__.py. scanpy-1.8.0/scanpy/metrics/_gearys_c.py. scanpy-1.8.0/scanpy/metrics/_metrics.py. scanpy-1.8.0/scanpy/metrics/_morans_i.py. scanpy-1.8.0/scanpy/neighbors/__init__.py. scanpy-1.8.0/scanpy/plotting/__init__.py. scanpy-1.8.0/scanpy/plotting/_anndata.py. scanpy-1.8.0/scanpy/plotting/_baseplot_class.py. scanpy-1.8.0/scanpy/plotting/_docs.py. scanpy-1.8.0/scanpy/plotting/_dotplot.py. scanpy-1.8.0/scanpy/plotting/_matrixplot.py. scanpy-1.8.0/scanpy/plotting/_preprocessing.py. scanpy-1.8.0/scanpy/plotting/_qc.py. scanpy-1.8.0/scanpy/plotting/_rcmod.py. scanpy-1.8.0/scanpy/plotting/_stacked_violin.py. scanpy-1.8.0/scanpy/plotting/_tools/__init__.py. scanpy-1.8.0/scanpy/plotting/_tools/paga.py. scanpy-1.8.0/scanpy/plotting/_tools/scatterplots.py. scanpy-1.8.0/scanpy/plotting/_utils.py. scanpy-1.8.0/scanpy/plotting/palettes.py. scanpy-1.8.0/scanpy/preprocessing/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_combat.py. scanpy-1.8.0/scanpy/preproce,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:2075,testability,log,logging,2075,0/scanpy/external/exporting.py. scanpy-1.8.0/scanpy/external/pl.py. scanpy-1.8.0/scanpy/external/pp/__init__.py. scanpy-1.8.0/scanpy/external/pp/_bbknn.py. scanpy-1.8.0/scanpy/external/pp/_dca.py. scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py. scanpy-1.8.0/scanpy/external/pp/_hashsolo.py. scanpy-1.8.0/scanpy/external/pp/_magic.py. scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py. scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py. scanpy-1.8.0/scanpy/external/pp/_scrublet.py. scanpy-1.8.0/scanpy/external/tl/__init__.py. scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py. scanpy-1.8.0/scanpy/external/tl/_palantir.py. scanpy-1.8.0/scanpy/external/tl/_phate.py. scanpy-1.8.0/scanpy/external/tl/_phenograph.py. scanpy-1.8.0/scanpy/external/tl/_pypairs.py. scanpy-1.8.0/scanpy/external/tl/_sam.py. scanpy-1.8.0/scanpy/external/tl/_trimap.py. scanpy-1.8.0/scanpy/external/tl/_wishbone.py. scanpy-1.8.0/scanpy/get/__init__.py. scanpy-1.8.0/scanpy/get/get.py. scanpy-1.8.0/scanpy/logging.py. scanpy-1.8.0/scanpy/metrics/__init__.py. scanpy-1.8.0/scanpy/metrics/_gearys_c.py. scanpy-1.8.0/scanpy/metrics/_metrics.py. scanpy-1.8.0/scanpy/metrics/_morans_i.py. scanpy-1.8.0/scanpy/neighbors/__init__.py. scanpy-1.8.0/scanpy/plotting/__init__.py. scanpy-1.8.0/scanpy/plotting/_anndata.py. scanpy-1.8.0/scanpy/plotting/_baseplot_class.py. scanpy-1.8.0/scanpy/plotting/_docs.py. scanpy-1.8.0/scanpy/plotting/_dotplot.py. scanpy-1.8.0/scanpy/plotting/_matrixplot.py. scanpy-1.8.0/scanpy/plotting/_preprocessing.py. scanpy-1.8.0/scanpy/plotting/_qc.py. scanpy-1.8.0/scanpy/plotting/_rcmod.py. scanpy-1.8.0/scanpy/plotting/_stacked_violin.py. scanpy-1.8.0/scanpy/plotting/_tools/__init__.py. scanpy-1.8.0/scanpy/plotting/_tools/paga.py. scanpy-1.8.0/scanpy/plotting/_tools/scatterplots.py. scanpy-1.8.0/scanpy/plotting/_utils.py. scanpy-1.8.0/scanpy/plotting/palettes.py. scanpy-1.8.0/scanpy/preprocessing/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_combat.py. scanpy-1.8.0/scanpy/preproce,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4000,usability,tool,tools,4000,". scanpy-1.8.0/scanpy/preprocessing/_combat.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4039,usability,tool,tools,4039,"mbat.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4081,usability,tool,tools,4081,"/_deprecated/__init__.py. scanpy-1.8.0/scanpy/preprocessing/_deprecated/highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4120,usability,tool,tools,4120,"scanpy/preprocessing/_deprecated/highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4155,usability,tool,tools,4155,"ghly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated any",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4197,usability,tool,tools,4197,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4246,usability,tool,tools,4246,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4284,usability,tool,tools,4284,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4322,usability,tool,tools,4322,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4361,usability,tool,tools,4361,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4412,usability,tool,tools,4412,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4448,usability,tool,tools,4448,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4483,usability,tool,tools,4483,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4532,usability,tool,tools,4532,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4575,usability,tool,tools,4575,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4610,usability,tool,tools,4610,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4651,usability,tool,tools,4651,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4687,usability,tool,tools,4687,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4723,usability,tool,tools,4723,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:4760,usability,tool,tools,4760,"anpy/preprocessing/_distributed.py. scanpy-1.8.0/scanpy/preprocessing/_docs.py. scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py. scanpy-1.8.0/scanpy/preprocessing/_normalization.py. scanpy-1.8.0/scanpy/preprocessing/_pca.py. scanpy-1.8.0/scanpy/preprocessing/_qc.py. scanpy-1.8.0/scanpy/preprocessing/_recipes.py. scanpy-1.8.0/scanpy/preprocessing/_simple.py. scanpy-1.8.0/scanpy/preprocessing/_utils.py. scanpy-1.8.0/scanpy/queries/__init__.py. scanpy-1.8.0/scanpy/queries/_queries.py. scanpy-1.8.0/scanpy/readwrite.py. scanpy-1.8.0/scanpy/sim_models/__init__.py. scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt. scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt. scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt. scanpy-1.8.0/scanpy/tools/__init__.py. scanpy-1.8.0/scanpy/tools/_dendrogram.py. scanpy-1.8.0/scanpy/tools/_diffmap.py. scanpy-1.8.0/scanpy/tools/_dpt.py. scanpy-1.8.0/scanpy/tools/_draw_graph.py. scanpy-1.8.0/scanpy/tools/_embedding_density.py. scanpy-1.8.0/scanpy/tools/_ingest.py. scanpy-1.8.0/scanpy/tools/_leiden.py. scanpy-1.8.0/scanpy/tools/_louvain.py. scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py. scanpy-1.8.0/scanpy/tools/_paga.py. scanpy-1.8.0/scanpy/tools/_pca.py. scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py. scanpy-1.8.0/scanpy/tools/_score_genes.py. scanpy-1.8.0/scanpy/tools/_sim.py. scanpy-1.8.0/scanpy/tools/_top_genes.py. scanpy-1.8.0/scanpy/tools/_tsne.py. scanpy-1.8.0/scanpy/tools/_umap.py. scanpy-1.8.0/scanpy/tools/_utils.py. scanpy-1.8.0/scanpy/tools/_utils_clustering.py. scanpy-1.8.0/PKG-INFO. ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect, but get's the version wrong on the wheel. ```. rm -r dist. flit build. ls dist. ```. ```. scanpy-1.8.0.dev112+g1a3ae03c.d20210628-py3-none-any.whl. scanpy-1.8.0.tar.gz. ```. ## `setup.py`. Is including a bunch of files it shouldn't and is deprecated anyways. ---------. @flying-sheep @Zethson",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1910:367,availability,error,error,367,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:206,integrability,filter,filtering,206,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:452,integrability,batch,batch,452,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:148,modifiability,variab,variable,148,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:367,performance,error,error,367,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:452,performance,batch,batch,452,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:367,safety,error,error,367,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:367,usability,error,error,367,"Handle non-expressed genes in all highly_variable_genes variations; It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell! `sc.pp.filter_genes(adata, min_cells=1)`. If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/pull/1911:47,deployability,releas,release,47,Backport PR #1907 on branch 1.8.x (Start 1.8.1 release notes); Backport PR #1907: Start 1.8.1 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1911
https://github.com/scverse/scanpy/pull/1911:94,deployability,releas,release,94,Backport PR #1907 on branch 1.8.x (Start 1.8.1 release notes); Backport PR #1907: Start 1.8.1 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1911
https://github.com/scverse/scanpy/issues/1912:16,deployability,instal,install,16,Add conda-forge install instructions; We should mention that scanpy is now distributed through conda forge in the installation instructions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1912
https://github.com/scverse/scanpy/issues/1912:114,deployability,instal,installation,114,Add conda-forge install instructions; We should mention that scanpy is now distributed through conda forge in the installation instructions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1912
https://github.com/scverse/scanpy/issues/1912:75,interoperability,distribut,distributed,75,Add conda-forge install instructions; We should mention that scanpy is now distributed through conda forge in the installation instructions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1912
https://github.com/scverse/scanpy/issues/1913:193,deployability,scale,scaled,193,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:547,deployability,depend,dependent,547,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:193,energy efficiency,scale,scaled,193,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:588,energy efficiency,cool,cool,588,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:547,integrability,depend,dependent,547,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:193,modifiability,scal,scaled,193,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:547,modifiability,depend,dependent,547,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:193,performance,scale,scaled,193,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:547,safety,depend,dependent,547,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:458,testability,simpl,simply,458,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:547,testability,depend,dependent,547,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:458,usability,simpl,simply,458,"Gene expression color legends and gene names; I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1914:6,availability,cluster,clusters,6,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1914:164,availability,cluster,clusters,164,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1914:247,availability,cluster,clusters,247,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1914:6,deployability,cluster,clusters,6,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1914:164,deployability,cluster,clusters,164,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1914:247,deployability,cluster,clusters,247,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1914:221,interoperability,specif,specify,221,Order clusters in pl.dotplot; I have been using `sc.pl.dotplot` to summarize marker gene expression patterns. But it seems that this function always sorts the cell clusters in alphabetical order. Is there a way for me to specify the order of cell clusters? I'm using `scanpy 1.5.0`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1914
https://github.com/scverse/scanpy/issues/1915:431,availability,error,errors,431,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:528,availability,ERROR,ERROR,528,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2230,availability,error,error,2230,"ats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1152,deployability,modul,module,1152,"data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1334,deployability,log,log,1334,"his works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2602,deployability,Version,Versions,2602,"df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4630,deployability,log,logical,4630,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4682,deployability,updat,updated,4682,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2970,energy efficiency,cloud,cloudpickle,2970,"gory_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4638,energy efficiency,CPU,CPU,4638,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4642,energy efficiency,core,cores,4642,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2253,integrability,sub,subsetting,2253,"/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. job",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2602,integrability,Version,Versions,2602,"df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:647,interoperability,Mismatch,Mismatch,647,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2279,interoperability,specif,specifying,2279,"py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsons",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2559,interoperability,specif,specific,2559,"roup_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:589,modifiability,paramet,parameter,589,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1152,modifiability,modul,module,1152,"data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1578,modifiability,layer,layer,1578,"`order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2378,modifiability,variab,variable,2378,"y_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2602,modifiability,Version,Versions,2602,"df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:3071,modifiability,deco,decorator,3071,"_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:3615,modifiability,pac,packaging,3615,">. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:431,performance,error,errors,431,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:528,performance,ERROR,ERROR,528,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2230,performance,error,error,2230,"ats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2324,performance,time,time,2324,"se_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4638,performance,CPU,CPU,4638,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:43,reliability,doe,doesn,43,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:431,safety,error,errors,431,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:528,safety,ERROR,ERROR,528,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1126,safety,input,input-,1126,"&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. Attribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1152,safety,modul,module,1152,"data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1334,safety,log,log,1334,"his works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2230,safety,error,error,2230,"ats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2514,safety,reme,remember,2514," var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4630,safety,log,logical,4630,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4682,safety,updat,updated,4682,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1334,security,log,log,1334,"his works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2922,security,certif,certifi,2922," 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g09",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4066,security,soc,socks,4066,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4630,security,log,logical,4630,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4662,security,Session,Session,4662,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4682,security,updat,updated,4682,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1082,testability,Trace,Traceback,1082," ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1334,testability,log,log,1334,"his works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4630,testability,log,logical,4630,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:92,usability,Minim,Minimal,92,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:431,usability,error,errors,431,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:528,usability,ERROR,ERROR,528,"sc.pl.dotplot(..., categories_order=[...]) doesn't handle not providing all categories; ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1126,usability,input,input-,1126,"&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). cats = pbmc.obs[""louvain""].cat.categories. genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:. sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ```. ```pytb. ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-580bb69f9615> in <module>. ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. Attribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2230,usability,error,error,2230,"ats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2342,usability,behavi,behaviour,2342,"gories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2439,usability,behavi,behaviour,2439,"dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2490,usability,behavi,behaviour,2490,"ndrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 982 return dp. 983 else:. --> 984 dp.make_figure(). 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self). 606 mainplot_height = len(self.categories) * category_height. 607 mainplot_width = (. --> 608 len(self.var_names) * category_width + self.group_extra_size. 609 ). 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'. ```. First, what's up with the printed error? Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>. <summary> </summary>. ```python. -----. anndata 0.7.7.dev4+g49739eb. scanpy 1.9.0.dev7+g092376d2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4232,usability,tool,toolz,4232,"0.3.1. -----. PIL 8.2.0. anndata 0.7.7.dev4+g49739eb. anyio NA. appnope 0.1.0. argon2 20.1.0. asciitree NA. attr 20.3.0. babel 2.8.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli 1.0.9. certifi 2020.06.20. cffi 1.14.0. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dask 2021.05.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. fsspec 2021.06.0. google NA. h5py 3.2.1. idna 2.10. igraph 0.9.6. ipykernel 5.5.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.8.0. jupyterlab_server 2.6.0. kiwisolver 1.2.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. nbinom_ufunc NA. numba 0.53.1. numcodecs 0.8.0. numexpr 2.7.2. numpy 1.21.0. packaging 20.9. pandas 1.2.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.18. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.0. pyparsing 2.4.7. pyrsistent NA. pytoml NA. pytz 2020.1. requests 2.25.1. scanpy 1.9.0.dev7+g092376d2. scipy 1.7.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sparse 0.12.0+21.gc96cc1a. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.6.0. terminado 0.8.3. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.61.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.4. wcwidth 0.2.5. websocket 1.1.0. yaml 5.3.1. zappy NA. zarr 2.8.3. zmq 19.0.2. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.16. notebook 6.4.0. -----. Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-07-01 15:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1916:52,availability,error,error,52,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:371,availability,Error,Error,371,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:607,availability,toler,tolerance,607,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2352,availability,toler,tolerance,2352,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2493,availability,toler,tolerance,2493,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1194,deployability,modul,module,1194,"0"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2540,deployability,Version,Versions,2540,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2753,deployability,log,logging,2753,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:556,energy efficiency,core,core,556,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2034,energy efficiency,core,core,2034,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2301,energy efficiency,core,core,2301,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2540,integrability,Version,Versions,2540,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:266,interoperability,platform,platforms,266,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:540,modifiability,pac,packages,540,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1194,modifiability,modul,module,1194,"0"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1286,modifiability,pac,packages,1286,"ina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1639,modifiability,pac,packages,1639,"n self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-lear",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2018,modifiability,pac,packages,2018,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2285,modifiability,pac,packages,2285,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2540,modifiability,Version,Versions,2540,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:52,performance,error,error,52,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:371,performance,Error,Error,371,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1361,performance,cach,cache,1361,". ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1718,performance,cach,cache,1718,"/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:607,reliability,toleran,tolerance,607,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2352,reliability,toleran,tolerance,2352,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2493,reliability,toleran,tolerance,2493,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:52,safety,error,error,52,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:371,safety,Error,Error,371,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:684,safety,except,except,684,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1054,safety,except,exception,1054,"hen I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getite",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1102,safety,except,exception,1102,"les (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1167,safety,input,input-,1167,"ated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1194,safety,modul,module,1194,"0"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2415,safety,except,except,2415,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2753,safety,log,logging,2753,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:901,security,hash,hashtable,901,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:994,security,hash,hashtable,994,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2753,security,log,logging,2753,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:474,testability,Trace,Traceback,474,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1123,testability,Trace,Traceback,1123,"arcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2753,testability,log,logging,2753,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:52,usability,error,error,52,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:371,usability,Error,Error,371,"Reading 10x scRNA-seq with read_10x_mtx(); I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1167,usability,input,input-,1167,"ated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:. ```python. sc.read_10x_mtx(""GSE145328_RAW""). ```. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3079 try:. -> 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2639,usability,learn,learn,2639,"get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). <ipython-input-20-26443e0aed95> in <module>. ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 481 adata = read(. 482 str(path),. 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 560 else:. 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). --> 562 adata.var['feature_types'] = genes[2].values. 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[. 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key). 3022 if self.columns.nlevels > 1:. 3023 return self._getitem_multilevel(key). -> 3024 indexer = self.columns.get_loc(key). 3025 if is_integer(indexer):. 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3080 return self._engine.get_loc(casted_key). 3081 except KeyError as err:. -> 3082 raise KeyError(key) from err. 3083 . 3084 if tolerance is not None:. KeyError: 2. ```. #### Versions. scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1917:42,deployability,fail,failing,42,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:65,integrability,coupl,couple,65,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:677,integrability,wrap,wrap,677,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:13,interoperability,compatib,compatibility,13,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:65,modifiability,coupl,couple,65,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:42,reliability,fail,failing,42,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:50,safety,test,tests,50,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:50,testability,test,tests,50,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:65,testability,coupl,couple,65,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:605,usability,undo,undocumented,605,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:618,usability,behavi,behaviour,618,"Pandas 1.3.0 compatibility ; We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1919:28,deployability,releas,releases,28,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:99,deployability,releas,releases,99,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:134,deployability,releas,release,134,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:192,deployability,releas,release,192,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:322,deployability,depend,dependencies,322,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:358,deployability,releas,release,358,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:516,deployability,releas,releases,516,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:598,deployability,automat,automate,598,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:647,deployability,releas,release,647,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:707,deployability,build,build,707,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:793,deployability,releas,releases,793,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:350,energy efficiency,current,current,350,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:322,integrability,depend,dependencies,322,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:322,modifiability,depend,dependencies,322,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:453,performance,time,time,453,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:171,safety,test,tested,171,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:322,safety,depend,dependencies,322,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:549,safety,prevent,prevented,549,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:622,safety,test,testing,622,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:549,security,preven,prevented,549,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:171,testability,test,tested,171,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:322,testability,depend,dependencies,322,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:598,testability,automat,automate,598,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:622,testability,test,testing,622,"Better handling of upstream releases; It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1921:201,availability,error,error,201,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3640,availability,avail,available,3640,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:739,deployability,modul,module,739,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:121,energy efficiency,current,current,121,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2667,energy efficiency,draw,drawing,2667,"width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3156,energy efficiency,draw,drawing,3156,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:1017,integrability,compon,components,1017,"groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:1017,interoperability,compon,components,1017,"groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:739,modifiability,modul,module,739,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:1017,modifiability,compon,components,1017,"groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2649,modifiability,pac,packages,2649,"h_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3138,modifiability,pac,packages,3138,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:201,performance,error,error,201,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2658,performance,network,networkx,2658,"min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3147,performance,network,networkx,3147,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3574,reliability,doe,doesn,3574,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3640,reliability,availab,available,3640,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:201,safety,error,error,201,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:712,safety,input,input-,712,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:739,safety,modul,module,739,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3640,safety,avail,available,3640,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2658,security,network,networkx,2658,"min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3147,security,network,networkx,3147,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3640,security,availab,available,3640,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:549,testability,trace,traceback,549,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:668,testability,Trace,Traceback,668,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2493,testability,simpl,simplefilter,2493,"abels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:201,usability,error,error,201,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:712,usability,input,input-,712,"Remove `paga_compare` groups argument?; ## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata, ""louvain""). sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]). ```. On master:. <details>. <summary> traceback </summary>. ```python. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-13-e5188d753713> in <module>. 1 adata = sc.datasets.pbmc3k_processed(). 2 sc.tl.paga(adata, ""louvain""). ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params). 135 if legend_fontoutline is not None:. 136 paga_graph_params['fontoutline'] = legend_fontoutline. --> 137 paga(. 138 adata,. 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2493,usability,simpl,simplefilter,2493,"abels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3438,usability,user,user-images,3438,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 552 if title[icolor] is not None:. 553 axs[icolor].set_title(title[icolor]). --> 554 sct = _paga_graph(. 555 adata,. 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 820 with warnings.catch_warnings():. 821 warnings.simplefilter(""ignore""). --> 822 nx.draw_networkx_edges(. 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'. 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0). 654 . 655 # set edge positions. --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]). 657 . 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5. ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/pull/1922:75,availability,state,state,75,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:108,deployability,Updat,Update,108,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:147,deployability,Releas,Release,147,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:75,integrability,state,state,75,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:108,safety,Updat,Update,108,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:134,safety,test,tests,134,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:108,security,Updat,Update,108,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:134,testability,test,tests,134,"Fix paga exact reproducibility; Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests. - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/issues/1925:1786,availability,error,error,1786,"r_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2075,availability,toler,tolerance,2075,".violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3230,availability,toler,tolerance,3230,"vs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5465,availability,sli,slice,5465,"else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6410,availability,sli,slice,6410,"_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3493,deployability,modul,module,3493,"e.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6234,deployability,manag,managers,6234,"bc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2024,energy efficiency,core,core,2024,"], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2946,energy efficiency,core,core,2946,"oni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3179,energy efficiency,core,core,3179,"a04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4604,energy efficiency,core,core,4604,"'counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4985,energy efficiency,core,core,4985,"ercent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, jus",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5308,energy efficiency,core,core,5308,"r_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_sha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5586,energy efficiency,core,core,5586,"packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5878,energy efficiency,core,core,5878,"/data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6219,energy efficiency,core,core,6219,"/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, place",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6234,energy efficiency,manag,managers,6234,"bc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6612,energy efficiency,core,core,6612,"_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6930,energy efficiency,core,core,6930,"_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:691,modifiability,layer,layer,691,"code that worked months ago not working anymore?; Hello. I wrote this code months ago and it worked fine. However it is not working anymore. I did not change one line and it is the exact same object. . This is what my object looks like. ```. AnnData object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2008,modifiability,pac,packages,2008," qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 37",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2266,modifiability,pac,packages,2266,"])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2432,modifiability,pac,packages,2432,"ounts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (mo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2930,modifiability,pac,packages,2930,"s04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calcul",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3163,modifiability,pac,packages,3163," as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3493,modifiability,modul,module,3493,"e.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3668,modifiability,layer,layer,3668,"PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3888,modifiability,pac,packages,3888,"onda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/proj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3999,modifiability,layer,layer,3999,"ry:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4237,modifiability,pac,packages,4237," 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4340,modifiability,layer,layer,4340,"During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4588,modifiability,pac,packages,4588,"ta, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4969,modifiability,pac,packages,4969,"pe, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5292,modifiability,pac,packages,5292," expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5570,modifiability,pac,packages,5570,"ython3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5862,modifiability,pac,packages,5862,"(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_mem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6203,modifiability,pac,packages,6203,"a04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6596,modifiability,pac,packages,6596,"_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6914,modifiability,pac,packages,6914,"_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:747,performance,parallel,parallel,747,"code that worked months ago not working anymore?; Hello. I wrote this code months ago and it worked fine. However it is not working anymore. I did not change one line and it is the exact same object. . This is what my object looks like. ```. AnnData object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1786,performance,error,error,1786,"r_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3725,performance,parallel,parallel,3725,"e above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4031,performance,parallel,parallel,4031,"s.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:4375,performance,parallel,parallel,4375,"on, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2075,reliability,toleran,tolerance,2075,".violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3230,reliability,toleran,tolerance,3230,"vs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5465,reliability,sli,slice,5465,"else:. 137 return obs_metrics. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3595 self._setitem_frame(key, value). 3596 elif isinstance(key, (Series, np.ndarray, list, Index)):. -> 3597 self._setitem_array(key, value). 3598 elif isinstance(value, DataFrame):. 3599 self._set_item_frame_value(key, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6410,reliability,sli,slice,6410,"_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1786,safety,error,error,1786,"r_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2152,safety,except,except,2152,"counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2737,safety,except,exception,2737,"='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2785,safety,except,exception,2785,"r. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3056,safety,except,except,3056,"f, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_z",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3247,safety,except,except,3247,"/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3372,safety,except,exception,3372,"bbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3391,safety,except,exception,3391,"da_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3467,safety,input,input-,3467,"das._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3493,safety,modul,module,3493,"e.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:5933,safety,except,except,5933,"envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _setitem_array(self, key, value). 3634 check_key_length(self.columns, key, value). 3635 for k1, k2 in zip(key, value.columns):. -> 3636 self[k1] = value[k2]. 3637 . 3638 elif not is_list_like(value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:6234,safety,manag,managers,6234,"bc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3605 else:. 3606 # set column. -> 3607 self._set_item(key, value). 3608 . 3609 def _setitem_slice(self, key: slice, value):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3790 value = np.tile(value, (len(existing_piece.columns), 1)).T. 3791 . -> 3792 self._set_item_mgr(key, value). 3793 . 3794 def _set_value(. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3747 except KeyError:. 3748 # This item wasn't present, just insert at end. -> 3749 self._mgr.insert(len(self._info_axis), key, value). 3750 else:. 3751 self._iset_item_mgr(loc, value). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/managers.py in insert(self, loc, item, value). 1153 value = ensure_block_shape(value, ndim=self.ndim). 1154 . -> 1155 block = new_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1)). 1156 . 1157 for blkno, count in _fast_count_smallints(self.blknos[loc:]):. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in new_block(values, placement, ndim, klass). 1920 . 1921 values, _ = extract_pandas_array(values, None, ndim). -> 1922 check_ndim(values, placement, ndim). 1923 . 1924 if klass is None:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/internals/blocks.py in check_ndim(values, placement, ndim). 1962 ). 1963 if len(placement) != len(values):. -> 1964 raise ValueError(. 1965 f""Wrong number of items passed {len(values)}, "". 1966 f""placement implies {len(placement)}"". ValueError: Wrong number of items passed 89706, placement implies 1. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:305,security,ident,ident,305,"code that worked months ago not working anymore?; Hello. I wrote this code months ago and it worked fine. However it is not working anymore. I did not change one line and it is the exact same object. . This is what my object looks like. ```. AnnData object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:483,security,Auth,Author,483,"code that worked months ago not working anymore?; Hello. I wrote this code months ago and it worked fine. However it is not working anymore. I did not change one line and it is the exact same object. . This is what my object looks like. ```. AnnData object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1179,security,Auth,Author,1179,"xact same object. . This is what my object looks like. ```. AnnData object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1246,security,Auth,Author,1246," object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1306,security,Auth,Author,1306,"t', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1362,security,Auth,Author,1362,"t', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/Mar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2565,security,hash,hashtable,2565,"s_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2661,security,hash,hashtable,2661,"x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1884,testability,Trace,Traceback,1884,"g1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2806,testability,Trace,Traceback,2806,"--------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/proj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3423,testability,Trace,Traceback,3423,"ite-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:549,usability,visual,visualizar,549,"code that worked months ago not working anymore?; Hello. I wrote this code months ago and it worked fine. However it is not working anymore. I did not change one line and it is the exact same object. . This is what my object looks like. ```. AnnData object with n_obs × n_vars = 89706 × 34717. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'timpoint', 'condition', 'timpoint.condition', 'CellTypeRefined', 'CellTypeRefined.Rajbhandari', 'Sample.type', 'Treatment', 'Author'. var: 'features'. ```. This is the code. ```. #calcular e visualizar metricas de QC por estudo. sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . percent_top=None, layer=None, use_raw=False, inplace=True, . log1p=False, parallel=None). adata.var['mt'] = adata.var_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:1786,usability,error,error,1786,"r_names.str.startswith('mt'). sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'). sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]. Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]. Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'). sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3360 try:. -> 3361 return self._engine.get_loc(casted_key). 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3467,usability,input,input-,3467,"das._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3516,usability,visual,visualizar,3516,"/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value). 3745 try:. -> 3746 loc = self._info_axis.get_loc(key). 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 3362 except KeyError as err:. -> 3363 raise KeyError(key) from err. 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-3-69925a75d466> in <module>. 1 #calcular e visualizar metricas de QC por estudo. ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), . 3 percent_top=None, layer=None, use_raw=False, inplace=True,. 4 log1p=False, parallel=None). 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 304 X.eliminate_zeros(). 305 . --> 306 obs_metrics = describe_obs(. 307 adata,. 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 133 ). 134 if inplace:. --> 135 adata.obs[obs_metrics.columns] = obs_metrics. 136 else:. 137 return obs_metrics. /data04/projects04/Mar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/pull/1926:14,deployability,api,api-wrap,14,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:23,deployability,depend,dependency,23,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:59,deployability,releas,release,59,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:14,integrability,api,api-wrap,14,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:23,integrability,depend,dependency,23,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:14,interoperability,api,api-wrap,14,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:23,modifiability,depend,dependency,23,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:23,safety,depend,dependency,23,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1926:23,testability,depend,dependency,23,Remove legacy-api-wrap dependency; Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1927:94,availability,error,erroring,94,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:0,deployability,Updat,Update,0,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:79,deployability,build,builds,79,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:94,performance,error,erroring,94,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:0,safety,Updat,Update,0,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:94,safety,error,erroring,94,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:0,security,Updat,Update,0,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:89,usability,stop,stop,89,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/pull/1927:94,usability,error,erroring,94,Update deps pynndescent; Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/issues/1929:38,availability,error,error,38,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:448,availability,error,error,448,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:191,deployability,version,version,191,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1109,deployability,Version,Versions,1109,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1186,deployability,log,logging,1186,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:191,integrability,version,version,191,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1109,integrability,Version,Versions,1109,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:191,modifiability,version,version,191,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1109,modifiability,Version,Versions,1109,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:38,performance,error,error,38,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:448,performance,error,error,448,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:38,safety,error,error,38,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:448,safety,error,error,448,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1186,safety,log,logging,1186,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1186,security,log,logging,1186,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1186,testability,log,logging,1186,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:38,usability,error,error,38,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:151,usability,confirm,confirmed,151,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:234,usability,confirm,confirmed,234,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:404,usability,tool,tools,404,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:448,usability,error,error,448,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:947,usability,guid,guide,947,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1002,usability,minim,minimal-bug-reports,1002,"sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True; - [√] I have checked that this issue has not already been reported. - [√] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. small bug report:. https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py. line 538 wrong error raised when `use_raw=True`. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is not None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. Second `not` should be removed ,Corrected codes should be. ```python. if use_raw is None:. use_raw = adata.raw is not None. elif use_raw is True and adata.raw is None:. raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""). ```. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions. this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1930:195,deployability,version,version,195,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1930:195,integrability,version,version,195,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1930:364,interoperability,specif,specifically,364,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1930:195,modifiability,version,version,195,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1930:155,usability,confirm,confirmed,155,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1930:238,usability,confirm,confirmed,238,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1930:515,usability,user,user-images,515,"Docs for `sc.tl.filter_rank_genes_group()` missing argument descriptions; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The docs for `sc.tl.filter_rank_genes_group()` are incomplete, specifically missing argument descriptions https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ![image](https://user-images.githubusercontent.com/6869320/124576569-b7f37a80-de4c-11eb-8293-508e746e2eea.png). Not sure if these are missing from the code or just haven't rendered for some reason.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1930
https://github.com/scverse/scanpy/issues/1931:106,availability,avail,available,106,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:223,availability,avail,available,223,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:366,availability,avail,available,366,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:526,availability,avail,available,526,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:565,availability,error,errors,565,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:455,deployability,instal,install,455,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:909,deployability,depend,dependency,909,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1036,deployability,instal,installed,1036," stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1070,deployability,instal,install,1070,"ect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the thr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1161,deployability,depend,dependencies,1161,"map` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndesce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1258,deployability,version,version,1258," came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1289,deployability,depend,dependency,1289,"the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1575,deployability,version,version,1575,"rrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2577,deployability,instal,installed,2577,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:909,integrability,depend,dependency,909,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1161,integrability,depend,dependencies,1161,"map` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndesce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1258,integrability,version,version,1258," came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1289,integrability,depend,dependency,1289,"the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1575,integrability,version,version,1575,"rrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1476,interoperability,specif,specify,1476,"es in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threadi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2461,interoperability,specif,specify,2461,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:909,modifiability,depend,dependency,909,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1161,modifiability,depend,dependencies,1161,"map` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndesce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1258,modifiability,version,version,1258," came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1289,modifiability,depend,dependency,1289,"the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1495,modifiability,pac,package,1495,"ems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after impo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1575,modifiability,version,version,1575,"rrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1630,modifiability,layer,layer,1630,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2133,modifiability,layer,layer,2133,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2397,modifiability,layer,layer,2397,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2483,modifiability,layer,layer,2483,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:27,performance,parallel,parallel,27,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:565,performance,error,errors,565,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:605,performance,parallel,parallelized,605,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1731,performance,time,time,1731,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2026,performance,parallel,parallel,2026,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2055,performance,lock,locked,2055,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2329,performance,time,time,2329,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:106,reliability,availab,available,106,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:223,reliability,availab,available,223,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:366,reliability,availab,available,366,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:526,reliability,availab,available,526,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:71,safety,detect,detect,71,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:106,safety,avail,available,106,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:223,safety,avail,available,223,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:366,safety,avail,available,366,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:526,safety,avail,available,526,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:547,safety,detect,detects,547,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:565,safety,error,errors,565,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:909,safety,depend,dependency,909,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:938,safety,avoid,avoided,938,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1118,safety,compl,complaints,1118,"as fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1161,safety,depend,dependencies,1161,"map` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndesce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1289,safety,depend,dependency,1289,"the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:71,security,detect,detect,71,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:106,security,availab,available,106,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:223,security,availab,available,223,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:366,security,availab,available,366,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:526,security,availab,available,526,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:547,security,detect,detects,547,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1118,security,compl,complaints,1118,"as fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2055,security,lock,locked,2055,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2098,security,session,session,2098,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:586,testability,trace,tracebacks,586,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:695,testability,trace,tracebacks,695,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:909,testability,depend,dependency,909,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1161,testability,depend,dependencies,1161,"map` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndesce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1289,testability,depend,dependency,1289,"the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1951,testability,understand,understanding,1951,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2225,testability,simpl,simpler,2225,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:565,usability,error,errors,565,"pynndescent 0.5.3 breaking parallel numba stuff; Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2225,usability,simpl,simpler,2225,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2455,usability,user,users,2455,"used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do? ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1932:534,availability,error,error,534,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2745,availability,operat,operator,2745,"pby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:178,deployability,version,version,178,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:891,deployability,modul,module,891,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1218,deployability,log,log,1218," confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1763,deployability,log,log,1763," use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3544,deployability,manag,managers,3544,"grams\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4976,deployability,Version,Versions,4976,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:5025,deployability,log,logging,5025,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2360,energy efficiency,core,core,2360,"itle, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2595,energy efficiency,core,core,2595,". 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_fail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2887,energy efficiency,core,core,2887,", layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3200,energy efficiency,core,core,3200," compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3529,energy efficiency,core,core,3529,"appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return metho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3544,energy efficiency,manag,managers,3544,"grams\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3818,energy efficiency,core,core,3818,"ep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4098,energy efficiency,core,core,4098,"ew_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4422,energy efficiency,core,core,4422,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4657,energy efficiency,core,core,4657,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:178,integrability,version,version,178,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2069,integrability,transform,transform,2069,"s\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 retur",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4976,integrability,Version,Versions,4976,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2069,interoperability,transform,transform,2069,"s\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 retur",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:178,modifiability,version,version,178,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:891,modifiability,modul,module,891,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1134,modifiability,pac,packages,1134,"confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1462,modifiability,layer,layer,1462,"to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1672,modifiability,pac,packages,1672,"n. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__"").",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1891,modifiability,layer,layer,1891,"ule>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2344,modifiability,pac,packages,2344,"_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(rig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2579,modifiability,pac,packages,2579,"**kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2871,modifiability,pac,packages,2871,"group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2978,modifiability,scal,scalar,2978,"ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3184,modifiability,pac,packages,3184,"f. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3308,modifiability,scal,scalar,3308,"rograms\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3513,modifiability,pac,packages,3513,"ers\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3802,modifiability,pac,packages,3802,"\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4082,modifiability,pac,packages,4082,"truct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the detai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4406,modifiability,pac,packages,4406,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4641,modifiability,pac,packages,4641,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4976,modifiability,Version,Versions,4976,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:534,performance,error,error,534,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:534,safety,error,error,534,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:864,safety,input,input-,864,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:891,safety,modul,module,891,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1218,safety,log,log,1218," confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1763,safety,log,log,1763," use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3544,safety,manag,managers,3544,"grams\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:5025,safety,log,logging,5025,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1218,security,log,log,1218," confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1763,security,log,log,1763," use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:5025,security,log,logging,5025,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:820,testability,Trace,Traceback,820,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1218,testability,log,log,1218," confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1763,testability,log,log,1763," use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:5025,testability,log,logging,5025,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:138,usability,confirm,confirmed,138,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:221,usability,confirm,confirmed,221,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:382,usability,document,document,382,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:503,usability,document,document,503,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:534,usability,error,error,534,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:547,usability,help,help,547,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:598,usability,Minim,Minimal,598,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:864,usability,input,input-,864,"Unordered Categoricals can only compare equality or not; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1070,usability,user,users,1070,"cked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # tran",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1608,usability,user,users,1608,"sample (that we can copy&paste without having any data). ```python. sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). ```. ```pytb. TypeError Traceback (most recent call last). <ipython-input-17-15b8850a67a5> in <module>. 1 #New dot plot (12 weeks feature genes). ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2280,usability,user,users,2280,", dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2515,usability,user,users,2515,"ig, **kwds). 930 dot_color_df=dot_color_df,. 931 ax=ax,. --> 932 **kwds,. 933 ). 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2807,usability,user,users,2807,"igsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds). 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:2988,usability,behavi,behavior,2988,". 151 # 1. compute fraction of cells having value > expression_cutoff. 152 # transform obs_tidy into boolean matrix using the expression_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._sp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3120,usability,user,users,3120,"ssion_cutoff. --> 153 obs_bool = self.obs_tidy > expression_cutoff. 154 . 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3449,usability,user,users,3449,"> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other). 43 @unpack_zerodim_and_defer(""__gt__""). 44 def __gt__(self, other):. ---> 45 return self._cmp_method(other, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_meth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:3738,usability,user,users,3738,"er, operator.gt). 46 . 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _cmp_method(self, other, op). 5966 . 5967 # See GH#4537 for discussion of scalar op behavior. -> 5968 new_data = self._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4018,usability,user,users,4018,"._dispatch_frame_op(other, op, axis=axis). 5969 return self._construct_result(new_data). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4342,usability,user,users,4342,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4577,usability,user,users,4577,"a). 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis). 6003 if not is_list_like(right):. 6004 # i.e. scalar, faster than checking np.ndim(right) == 0. -> 6005 bm = self._mgr.apply(array_op, right=right). 6006 return type(self)(bm). 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs). 423 try:. 424 if callable(f):. --> 425 applied = b.apply(f, **kwargs). 426 else:. 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs). 376 """""". 377 with np.errstate(all=""ignore""):. --> 378 result = func(self.values, **kwargs). 379 . 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op). 227 if should_extension_dispatch(lvalues, rvalues):. 228 # Call the method on lvalues. --> 229 res_values = op(lvalues, rvalues). 230 . 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other). 63 other = item_from_zerodim(other). 64 . ---> 65 return method(self, other). 66 . 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other). 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:. 76 raise TypeError(. ---> 77 ""Unordered Categoricals can only compare equality or not"". 78 ). 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/pull/1933:70,modifiability,variab,variable,70,Set NUMBA_THREADING_LAYER in tests; Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1933:102,modifiability,layer,layer,102,Set NUMBA_THREADING_LAYER in tests; Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1933:171,modifiability,layer,layer,171,Set NUMBA_THREADING_LAYER in tests; Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1933:29,safety,test,tests,29,Set NUMBA_THREADING_LAYER in tests; Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1933:29,testability,test,tests,29,Set NUMBA_THREADING_LAYER in tests; Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1933:156,usability,user,user,156,Set NUMBA_THREADING_LAYER in tests; Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1934:12,availability,error,error,12,Fix use_raw error with sc.tl.rank_genes_groups; Fixes #1929,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1934
https://github.com/scverse/scanpy/pull/1934:12,performance,error,error,12,Fix use_raw error with sc.tl.rank_genes_groups; Fixes #1929,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1934
https://github.com/scverse/scanpy/pull/1934:12,safety,error,error,12,Fix use_raw error with sc.tl.rank_genes_groups; Fixes #1929,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1934
https://github.com/scverse/scanpy/pull/1934:12,usability,error,error,12,Fix use_raw error with sc.tl.rank_genes_groups; Fixes #1929,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1934
https://github.com/scverse/scanpy/pull/1935:47,availability,error,error,47,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:115,availability,error,error,115,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:47,performance,error,error,47,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:115,performance,error,error,115,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:47,safety,error,error,47,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:115,safety,error,error,115,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:47,usability,error,error,47,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1935:115,usability,error,error,115,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups); Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1937:38,deployability,releas,release,38,Prep 1.8.1; Prepping for 1.8.1 bugfix release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1937
https://github.com/scverse/scanpy/issues/1940:0,integrability,sub,subset,0,"subset adata is a view; Hi thanks for your excellent work! I noticed for a subset adata object, say. batch1 = adata[adata.obs[""batch""] == ""batch1"", :]. it will be a view of the original adata. . For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),. I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1940:75,integrability,sub,subset,75,"subset adata is a view; Hi thanks for your excellent work! I noticed for a subset adata object, say. batch1 = adata[adata.obs[""batch""] == ""batch1"", :]. it will be a view of the original adata. . For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),. I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1940:127,integrability,batch,batch,127,"subset adata is a view; Hi thanks for your excellent work! I noticed for a subset adata object, say. batch1 = adata[adata.obs[""batch""] == ""batch1"", :]. it will be a view of the original adata. . For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),. I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1940:127,performance,batch,batch,127,"subset adata is a view; Hi thanks for your excellent work! I noticed for a subset adata object, say. batch1 = adata[adata.obs[""batch""] == ""batch1"", :]. it will be a view of the original adata. . For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),. I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1940:383,performance,memor,memory-efficient,383,"subset adata is a view; Hi thanks for your excellent work! I noticed for a subset adata object, say. batch1 = adata[adata.obs[""batch""] == ""batch1"", :]. it will be a view of the original adata. . For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),. I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1940:383,usability,memor,memory-efficient,383,"subset adata is a view; Hi thanks for your excellent work! I noticed for a subset adata object, say. batch1 = adata[adata.obs[""batch""] == ""batch1"", :]. it will be a view of the original adata. . For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),. I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1941:761,availability,Error,Error,761,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:147,deployability,version,version,147,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:931,deployability,modul,module,931,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2211,deployability,log,log,2211,"den_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2707,deployability,log,log,2707,"b/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:1630,energy efficiency,heat,heatmap,1630,",6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:1970,energy efficiency,heat,heatmap,1970,"nes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/proj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2000,energy efficiency,heat,heatmap,2000,"nes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_memb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2167,energy efficiency,heat,heatmap,2167,"roups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:11,integrability,filter,filtered,11,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:147,integrability,version,version,147,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:147,modifiability,version,version,147,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:931,modifiability,modul,module,931,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:1358,modifiability,pac,packages,1358,"nd other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:1730,modifiability,pac,packages,1730,"es_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2127,modifiability,pac,packages,2127,"', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2317,modifiability,layer,layer,2317,"onda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2612,modifiability,pac,packages,2612,"63 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2728,modifiability,layer,layer,2728,"ackages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `adata.obs` or in adata.ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2897,modifiability,layer,layer,2897,"tting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `adata.obs` or in adata.raw.var_names."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2903,modifiability,layer,layer,2903,"tting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `adata.obs` or in adata.raw.var_names."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:3051,modifiability,pac,packages,3051,"tting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `adata.obs` or in adata.raw.var_names."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:3112,modifiability,layer,layer,3112,"tting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `adata.obs` or in adata.raw.var_names."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:3357,modifiability,pac,packages,3357,"tting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `adata.obs` or in adata.raw.var_names."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:761,performance,Error,Error,761,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:316,safety,test,tested,316,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:761,safety,Error,Error,761,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:904,safety,input,input-,904,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:931,safety,modul,module,931,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2211,safety,log,log,2211,"den_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2707,safety,log,log,2707,"b/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2211,security,log,log,2211,"den_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2707,security,log,log,2707,"b/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:316,testability,test,tested,316,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:860,testability,Trace,Traceback,860,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2211,testability,log,log,2211,"den_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2707,testability,log,log,2707,"b/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return heatmap(. 581 adata,. 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1022 ). 1023 . -> 1024 categories, obs_tidy = _prepare_dataframe(. 1025 adata,. 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1917 groupby.remove(groupby_index). 1918 keys = list(groupby) + list(np.unique(var_names)). -> 1919 obs_tidy = get.obs_df(. 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of `ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
