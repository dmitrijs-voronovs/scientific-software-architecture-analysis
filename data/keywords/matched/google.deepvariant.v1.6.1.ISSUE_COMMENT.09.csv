id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/pull/159:20,deployability,releas,release,20,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:115,deployability,configurat,configuration,115,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:366,deployability,configurat,configuration,366,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:403,energy efficiency,estimat,estimator,403,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:115,integrability,configur,configuration,115,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:366,integrability,configur,configuration,366,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:341,interoperability,specif,specified,341,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:115,modifiability,configur,configuration,115,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:366,modifiability,configur,configuration,366,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:303,reliability,sli,slightly,303,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:115,security,configur,configuration,115,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:156,security,session,session,156,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:358,security,session,session,358,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:366,security,configur,configuration,366,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:32,testability,plan,plan,32,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:86,usability,user,users,86,"@A-Tsai In the next release, we plan to add a flag to `call_variants` that will allow users to pass in any desired configuration options for the TensorFlow session config. We won't hard code any options, but you will be able to pass in all of the options included in this pull request. The code will be slightly different from what you have specified as the session configuration will be passed to [the estimator](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L344), rather than [this code block](https://github.com/google/deepvariant/blob/5e6fe205b984c6be116dcacafdfd83ce1df4d2e9/deepvariant/call_variants.py#L330). Thanks for the suggested changes!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:53,deployability,releas,release,53,@gunjanbaid Even better. Looking forward to the next release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:31,deployability,releas,release,31,This is included in our latest release:. https://github.com/google/deepvariant/releases/tag/v0.8.0. Thank you for your contribution to DeepVariant!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/pull/159:79,deployability,releas,releases,79,This is included in our latest release:. https://github.com/google/deepvariant/releases/tag/v0.8.0. Thank you for your contribution to DeepVariant!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/159
https://github.com/google/deepvariant/issues/160:111,availability,error,error,111,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:117,integrability,messag,message,117,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:117,interoperability,messag,message,117,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:111,performance,error,error,111,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:111,safety,error,error,111,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:111,usability,error,error,111,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:113,availability,error,error,113,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:119,integrability,messag,message,119,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:119,interoperability,messag,message,119,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:113,performance,error,error,113,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:113,safety,error,error,113,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:113,usability,error,error,113,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:184,usability,user,users,184,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you! It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:281,deployability,instal,install,281,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:839,deployability,build,build,839,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:845,deployability,version,versions,845,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:845,integrability,version,versions,845,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:430,interoperability,share,share,430,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:749,interoperability,specif,specifying,749,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:845,modifiability,version,versions,845,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:1050,security,Modif,Modify,1050,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:1296,usability,clear,clear,1296,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/160:1309,usability,document,documentation,1309,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```. $ ls clif. bin clang examples include lib local pip-selfcheck.json python share. ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:. 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`. OR. 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future. @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/160
https://github.com/google/deepvariant/issues/162:122,availability,slo,slow,122,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:71,energy efficiency,model,models,71,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:91,energy efficiency,CPU,CPU,91,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:133,energy efficiency,GPU,GPUs,133,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:171,energy efficiency,CPU,CPUs,171,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:294,energy efficiency,Cloud,Cloud,294,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:626,energy efficiency,GPU,GPUs,626,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:666,energy efficiency,GPU,GPUs,666,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:748,energy efficiency,GPU,GPUs,748,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:1029,energy efficiency,GPU,GPU,1029,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:1036,energy efficiency,CPU,CPU,1036,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:300,interoperability,Platform,Platform,300,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:964,interoperability,specif,specifically,964,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:91,performance,CPU,CPU,91,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:133,performance,GPU,GPUs,133,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:171,performance,CPU,CPUs,171,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:626,performance,GPU,GPUs,626,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:666,performance,GPU,GPUs,666,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:748,performance,GPU,GPUs,748,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:1029,performance,GPU,GPU,1029,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:1036,performance,CPU,CPU,1036,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:122,reliability,slo,slow,122,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:71,security,model,models,71,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:425,usability,custom,customized,425,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/162:1048,usability,close,close,1048,"Hi @bdongucdavis , thank you for your interest in training DeepVariant models. Training on CPU is indeed going to be very slow. With GPUs, you can speed it up compared to CPUs. For example, this old tutorial that I wrote has an example: http://bit.ly/train-deepvariant. If you are using Google Cloud Platform, I would strongly recommend that you get TPU quota and try following the steps in the [Advanced Case Study: Train a customized SNP and small indel variant caller for BGISEQ-500 data](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) to use **TPU**s (which is different from GPUs), which should be much faster than GPUs. One thing on our TODO lists is to look into whether we can utilize multiple GPUs better , which we think will be particularly useful for the training use case. However, it's not on the top of our priority list right now. Hopefully we'll get there soon! And, to clarify, the `use_tpu` flag is specifically for TPU, which is a different kind of hardware from GPU or CPU. I will close this issue, but if you have relevant follow up questions, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/162
https://github.com/google/deepvariant/issues/163:190,deployability,updat,update,190,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:5,energy efficiency,Current,Currently,5,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:56,energy efficiency,GPU,GPU,56,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:68,energy efficiency,current,currently,68,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:92,energy efficiency,GPU,GPU,92,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:161,energy efficiency,gpu,gpu,161,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:56,performance,GPU,GPU,56,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:92,performance,GPU,GPU,92,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:161,performance,gpu,gpu,161,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:190,safety,updat,update,190,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:101,security,team,team,101,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:190,security,updat,update,190,"Hi,. Currently, only the call_variants step can utilize GPU. And it currently only uses one GPU. Our team is actively looking into getting it to work with multi-gpu. Hopefully we'll have an update soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:58,deployability,API,API,58,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:199,deployability,API,API,199,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:397,deployability,updat,update,397,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:48,energy efficiency,Estimat,Estimator,48,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:87,energy efficiency,predict,prediction,87,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:110,energy efficiency,GPU,GPUs,110,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:138,energy efficiency,current,currently,138,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:160,energy efficiency,GPU,GPU,160,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:167,energy efficiency,predict,prediction,167,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:290,energy efficiency,GPU,GPUs,290,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:453,energy efficiency,GPU,GPUs,453,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:58,integrability,API,API,58,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:199,integrability,API,API,199,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:58,interoperability,API,API,58,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:199,interoperability,API,API,199,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:303,interoperability,distribut,distribution,303,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:110,performance,GPU,GPUs,110,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:160,performance,GPU,GPU,160,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:178,performance,time,time,178,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:290,performance,GPU,GPUs,290,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:453,performance,GPU,GPUs,453,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:62,reliability,doe,does,62,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:203,reliability,doe,does,203,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:87,safety,predict,prediction,87,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:167,safety,predict,prediction,167,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:397,safety,updat,update,397,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:397,security,updat,update,397,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:71,usability,support,support,71,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:208,usability,support,support,208,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/163:464,usability,close,close,464,"Hi @jrvanalstine! Unfortunately, the TensorFlow Estimator API does not support running prediction on multiple GPUs, so `call_variants.py` currently uses only 1 GPU at prediction time. That said, the API does support running training and evaluation (both steps require labels) with multiple GPUs through distribution strategies (i.e. `MirroredStrategy`). We hope to look into this and will post an update if we are able to run these steps using multiple GPUs. I'll close this issue for now but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/163
https://github.com/google/deepvariant/issues/164:64,usability,help,help,64,Hi @pichuan ! Any initial hunches by any chance? Appreciate the help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:62,availability,error,error,62,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:124,availability,error,error,124,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:98,deployability,Fail,Failed,98,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:62,performance,error,error,62,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:124,performance,error,error,124,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:98,reliability,Fail,Failed,98,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:62,safety,error,error,62,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:124,safety,error,error,124,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:62,usability,error,error,62,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:124,usability,error,error,124,"Hi @ekofman , sorry forgot to answer this one. Looking at the error line:. ```. [E::fai_retrieve] Failed to retrieve block: error reading file. ```. It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:34,integrability,pub,public,34,"Thanks. If any of these files are public, let me know and we can also take a look. I'll also ask my teammates who have recently looked at the postprocess_variants code to see if they have other suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:100,security,team,teammates,100,"Thanks. If any of these files are public, let me know and we can also take a look. I'll also ask my teammates who have recently looked at the postprocess_variants code to see if they have other suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:50,availability,error,error,50,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:389,availability,reliab,reliable,389,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:74,interoperability,specif,specifying,74,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:50,performance,error,error,50,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:389,reliability,reliab,reliable,389,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:50,safety,error,error,50,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:50,usability,error,error,50,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:99,usability,command,command,99,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:314,usability,support,support,314,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:211,availability,error,error,211,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:552,availability,reliab,reliable,552,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:235,interoperability,specif,specifying,235,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:211,performance,error,error,211,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:552,reliability,reliab,reliable,552,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:211,safety,error,error,211,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:211,usability,error,error,211,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:260,usability,command,command,260,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:477,usability,support,support,477,"Theyre being copied to the local machine actually! Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:. > . > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command? > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is. > Thank you! > . > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:60,availability,error,error,60,"Hi @ekofman ,. I am unable to reproduce this FASTA querying error on my machine. Can you verify the md5sums of the files you have on your local machine? When I copy the above gs:// paths, I see. $ md5sum Homo_sapiens_assembly19.fasta*. 886ba1559393f75872c1cf459eb57f2d Homo_sapiens_assembly19.fasta. fdc0ab679f6461d78980de2a2e97e8f3 Homo_sapiens_assembly19.fasta.fai. and with those files can query the position 1:10147 successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:60,performance,error,error,60,"Hi @ekofman ,. I am unable to reproduce this FASTA querying error on my machine. Can you verify the md5sums of the files you have on your local machine? When I copy the above gs:// paths, I see. $ md5sum Homo_sapiens_assembly19.fasta*. 886ba1559393f75872c1cf459eb57f2d Homo_sapiens_assembly19.fasta. fdc0ab679f6461d78980de2a2e97e8f3 Homo_sapiens_assembly19.fasta.fai. and with those files can query the position 1:10147 successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:60,safety,error,error,60,"Hi @ekofman ,. I am unable to reproduce this FASTA querying error on my machine. Can you verify the md5sums of the files you have on your local machine? When I copy the above gs:// paths, I see. $ md5sum Homo_sapiens_assembly19.fasta*. 886ba1559393f75872c1cf459eb57f2d Homo_sapiens_assembly19.fasta. fdc0ab679f6461d78980de2a2e97e8f3 Homo_sapiens_assembly19.fasta.fai. and with those files can query the position 1:10147 successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:89,testability,verif,verify,89,"Hi @ekofman ,. I am unable to reproduce this FASTA querying error on my machine. Can you verify the md5sums of the files you have on your local machine? When I copy the above gs:// paths, I see. $ md5sum Homo_sapiens_assembly19.fasta*. 886ba1559393f75872c1cf459eb57f2d Homo_sapiens_assembly19.fasta. fdc0ab679f6461d78980de2a2e97e8f3 Homo_sapiens_assembly19.fasta.fai. and with those files can query the position 1:10147 successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:60,usability,error,error,60,"Hi @ekofman ,. I am unable to reproduce this FASTA querying error on my machine. Can you verify the md5sums of the files you have on your local machine? When I copy the above gs:// paths, I see. $ md5sum Homo_sapiens_assembly19.fasta*. 886ba1559393f75872c1cf459eb57f2d Homo_sapiens_assembly19.fasta. fdc0ab679f6461d78980de2a2e97e8f3 Homo_sapiens_assembly19.fasta.fai. and with those files can query the position 1:10147 successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:316,availability,failur,failure,316,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:156,deployability,stage,stage,156,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:201,deployability,stage,stage,201,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:316,deployability,fail,failure,316,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:774,integrability,pub,public,774,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:484,modifiability,interm,intermediate,484,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:316,performance,failur,failure,316,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:316,reliability,fail,failure,316,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:715,reliability,diagno,diagnose,715,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:215,safety,compl,completely,215,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:215,security,compl,completely,215,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:715,testability,diagno,diagnose,715,"@ekofman In this case, it seems like the gVCF file generation might have had some issues. Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there? And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:267,reliability,doe,does,267,"It makes sense that the VCF generated successfully. In the postprocess_variants program, first the VCF is created based solely upon the outputs from the call_variants program, which has knowledge of the reference and alternate bases for each candidate site (and thus does not need to interact with the FASTA at all). The gVCF is created afterwards but needs a FASTA for cases where variants ""poke holes"" in a gVCF record. For example, a single gVCF record spanning hg19.chr1:10140-10150 would be represented as. chr1 10140 . A <*> ... END=10150. but if the VCF identifies an AC->C deletion at chr1:10146, then the gVCF output will look like. chr1 10140 . A <*> ... END=10145. chr1 10146 . AC C ... chr1 10148 . C <*> ... END=10150. where we find out that the chr1:10148 position has C by querying the FASTA. So it looks like your gVCF creation is dying on the first gVCF record that requires reading from the FASTA, and this is why the gVCF is truncated to be so small. It's still unclear to me why querying this FASTA has issues though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:561,security,ident,identifies,561,"It makes sense that the VCF generated successfully. In the postprocess_variants program, first the VCF is created based solely upon the outputs from the call_variants program, which has knowledge of the reference and alternate bases for each candidate site (and thus does not need to interact with the FASTA at all). The gVCF is created afterwards but needs a FASTA for cases where variants ""poke holes"" in a gVCF record. For example, a single gVCF record spanning hg19.chr1:10140-10150 would be represented as. chr1 10140 . A <*> ... END=10150. but if the VCF identifies an AC->C deletion at chr1:10146, then the gVCF output will look like. chr1 10140 . A <*> ... END=10145. chr1 10146 . AC C ... chr1 10148 . C <*> ... END=10150. where we find out that the chr1:10148 position has C by querying the FASTA. So it looks like your gVCF creation is dying on the first gVCF record that requires reading from the FASTA, and this is why the gVCF is truncated to be so small. It's still unclear to me why querying this FASTA has issues though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:284,usability,interact,interact,284,"It makes sense that the VCF generated successfully. In the postprocess_variants program, first the VCF is created based solely upon the outputs from the call_variants program, which has knowledge of the reference and alternate bases for each candidate site (and thus does not need to interact with the FASTA at all). The gVCF is created afterwards but needs a FASTA for cases where variants ""poke holes"" in a gVCF record. For example, a single gVCF record spanning hg19.chr1:10140-10150 would be represented as. chr1 10140 . A <*> ... END=10150. but if the VCF identifies an AC->C deletion at chr1:10146, then the gVCF output will look like. chr1 10140 . A <*> ... END=10145. chr1 10146 . AC C ... chr1 10148 . C <*> ... END=10150. where we find out that the chr1:10148 position has C by querying the FASTA. So it looks like your gVCF creation is dying on the first gVCF record that requires reading from the FASTA, and this is why the gVCF is truncated to be so small. It's still unclear to me why querying this FASTA has issues though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:260,performance,time,time,260,"Hi @ekofman , with this issue, I think we might have left at a place where there is still a mystery. Now the v0.8.0 is out, do you mind trying this again and see if you're still seeing the same issue? Given that I didn't fully understand what the problem last time was, at least a sanity check on whether we're still seeing the same thing will be helpful. . If I might be forgetting something that I could have followed up from last time, please also feel free to remind me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:433,performance,time,time,433,"Hi @ekofman , with this issue, I think we might have left at a place where there is still a mystery. Now the v0.8.0 is out, do you mind trying this again and see if you're still seeing the same issue? Given that I didn't fully understand what the problem last time was, at least a sanity check on whether we're still seeing the same thing will be helpful. . If I might be forgetting something that I could have followed up from last time, please also feel free to remind me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:281,safety,sanit,sanity,281,"Hi @ekofman , with this issue, I think we might have left at a place where there is still a mystery. Now the v0.8.0 is out, do you mind trying this again and see if you're still seeing the same issue? Given that I didn't fully understand what the problem last time was, at least a sanity check on whether we're still seeing the same thing will be helpful. . If I might be forgetting something that I could have followed up from last time, please also feel free to remind me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:281,security,sanit,sanity,281,"Hi @ekofman , with this issue, I think we might have left at a place where there is still a mystery. Now the v0.8.0 is out, do you mind trying this again and see if you're still seeing the same issue? Given that I didn't fully understand what the problem last time was, at least a sanity check on whether we're still seeing the same thing will be helpful. . If I might be forgetting something that I could have followed up from last time, please also feel free to remind me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:227,testability,understand,understand,227,"Hi @ekofman , with this issue, I think we might have left at a place where there is still a mystery. Now the v0.8.0 is out, do you mind trying this again and see if you're still seeing the same issue? Given that I didn't fully understand what the problem last time was, at least a sanity check on whether we're still seeing the same thing will be helpful. . If I might be forgetting something that I could have followed up from last time, please also feel free to remind me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:347,usability,help,helpful,347,"Hi @ekofman , with this issue, I think we might have left at a place where there is still a mystery. Now the v0.8.0 is out, do you mind trying this again and see if you're still seeing the same issue? Given that I didn't fully understand what the problem last time was, at least a sanity check on whether we're still seeing the same thing will be helpful. . If I might be forgetting something that I could have followed up from last time, please also feel free to remind me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:172,deployability,version,version,172,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:51,integrability,messag,messaged,51,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:172,integrability,version,version,172,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:51,interoperability,messag,messaged,51,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:172,modifiability,version,version,172,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:570,performance,time,time,570,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:752,performance,time,time,752,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:591,safety,sanit,sanity,591,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:591,security,sanit,sanity,591,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:1062,security,auth,auth,1062,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:534,testability,understand,understand,534,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:660,usability,help,helpful,660,"Thanks! I haven't tried running with gvcf since we messaged last, but yes I. never got it to work. We'll let you know if we get a chance to get it. working with the newest version. On Fri, Apr 12, 2019 at 12:20 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > Hi @ekofman <https://github.com/ekofman> , with this issue, I think we. > might have left at a place where there is still a mystery. >. > Now the v0.8.0 is out, do you mind trying this again and see if you're. > still seeing the same issue? Given that I didn't fully understand what the. > problem last time was, at least a sanity check on whether we're still. > seeing the same thing will be helpful. >. > If I might be forgetting something that I could have followed up from last. > time, please also feel free to remind me. Thanks! >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/164#issuecomment-482431632>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AFMFwhn7aSNq8hIAj0rjxAgqHRnx7D1zks5vgAmCgaJpZM4cBchL>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/164:16,usability,close,close,16,"Thank you. I'll close this issue for now. When you have a chance to try, if you're still seeing the same issue (or different issues), feel free to open another one, or re-open this one as you see fit.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/164
https://github.com/google/deepvariant/issues/165:1358,availability,error,error,1358,"partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:145,deployability,version,version,145,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:782,deployability,version,version,782,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1138,deployability,version,version,1138,"er version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1284,deployability,version,version,1284,"at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1529,deployability,version,version,1529,"allenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2553,deployability,fail,failing,2553," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:177,energy efficiency,core,core,177,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1130,energy efficiency,current,current,1130,"ly earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1276,energy efficiency,current,current,1276,"to were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1345,energy efficiency,reduc,reduction,1345,"(Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1707,energy efficiency,estimat,estimate,1707,"of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call wo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:123,integrability,sub,substantially,123,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:145,integrability,version,version,145,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:782,integrability,version,version,782,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:805,integrability,sub,submitted,805,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:846,integrability,sub,subsequent,846,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1138,integrability,version,version,1138,"er version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1224,integrability,sub,submission,1224," examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1284,integrability,version,version,1284,"at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1529,integrability,version,version,1529,"allenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2563,integrability,filter,filter,2563," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2804,integrability,filter,filter,2804," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:145,modifiability,version,version,145,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:782,modifiability,version,version,782,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1138,modifiability,version,version,1138,"er version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1284,modifiability,version,version,1284,"at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1529,modifiability,version,version,1529,"allenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:204,performance,network,network,204,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:305,performance,time,time,305,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:561,performance,time,time,561,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1358,performance,error,error,1358,"partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2096,performance,perform,perform,2096," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:88,reliability,rpo,rpoplin-,88,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2553,reliability,fail,failing,2553," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:666,safety,avoid,avoid,666,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:702,safety,valid,validity,702,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1358,safety,error,error,1358,"partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:204,security,network,network,204,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:470,security,NIST,NIST,470,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:922,testability,instrument,instruments,922,"Hello Charles,. Let me take your questions point by point. 1) The PrecisionFDA entry is rpoplin-dv42. The corresponds to a substantially earlier version of DeepVariant, but the core elements (deep neural network classification of examples) is the same. Ryan Poplin and Mark DePristo were at Verily at the time, and since transferred to Google Brain. (Verily is partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3027,testability,coverag,coverages,3027," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1358,usability,error,error,1358,"partially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2032,usability,indicat,indicated,2032,"ries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2096,usability,perform,perform,2096," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2159,usability,feedback,feedback,2159," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2333,usability,indicat,indicate,2333," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2859,usability,indicat,indicate,2859," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:536,deployability,pipelin,pipelines,536,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1187,energy efficiency,cloud,cloud,1187,"er one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1568,energy efficiency,profil,profile,1568,". I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:219,integrability,sub,submissions,219,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:296,integrability,sub,submissions,296,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:536,integrability,pipelin,pipelines,536,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1052,integrability,messag,message,1052," response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1794,integrability,filter,filtering,1794,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1052,interoperability,messag,message,1052," response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:640,performance,time,time,640,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1167,performance,time,time,1167," question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1258,performance,time,timely,1258,"ing to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-betwee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1568,performance,profil,profile,1568,". I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1639,performance,time,time,1639,"ime. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please fe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2418,performance,time,time,2418,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2600,performance,time,time,2600,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:356,reliability,rpo,rpoplin,356,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1122,reliability,pra,practice,1122,"for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1285,reliability,pra,practice,1285,"ll the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:768,safety,test,tested,768,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2549,safety,test,testing,2549,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:968,security,assess,assess,968,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1857,security,loss,loss,1857,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:185,testability,simpl,simpler,185,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:768,testability,test,tested,768,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2473,testability,understand,understand,2473,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2549,testability,test,testing,2549,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:185,usability,simpl,simpler,185,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:832,usability,learn,learning,832,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1131,usability,learn,learning,1131,"additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1376,usability,intuit,intuition,1376,"her entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2342,usability,learn,learn,2342,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2530,usability,clear,clear,2530,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2652,usability,close,close,2652,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1379,availability,recov,recovery,1379,"the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/compariso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1439,availability,recov,recovery,1439,"d filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://prec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1629,availability,recov,recovery,1629,"ossible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1673,availability,recov,recovery,1673," wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1718,availability,recov,recovery,1718,"nt. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1766,availability,recov,recovery,1766,"**5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1810,availability,recov,recovery,1810,"d (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1857,availability,recov,recovery,1857,"/github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I thi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1967,availability,recov,recovery,1967,"rsus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA compar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2011,availability,recov,recovery,2011," wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2056,availability,recov,recovery,2056,"pts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2104,availability,recov,recovery,2104,"well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2148,availability,recov,recovery,2148,"complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 4145",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2195,availability,recov,recovery,2195,"at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2520,availability,recov,recovery,2520," for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3171,availability,recov,recovery,3171,"%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3215,availability,recov,recovery,3215,"rison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in ter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3545,availability,recov,recovery,3545,"presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3616,availability,recov,recovery,3616,"tting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4306,availability,recov,recovery,4306,"for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4713,availability,recov,recovery,4713,"lts for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is *",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4757,availability,recov,recovery,4757,"les (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4800,availability,recov,recovery,4800," fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are hig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4846,availability,recov,recovery,4846,"ack to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4888,availability,recov,recovery,4888," both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4933,availability,recov,recovery,4933,"ning the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4982,availability,recov,recovery,4982,"e-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:5476,availability,consist,consistent,5476,"ttps://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed un",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6659,availability,avail,available,6659,"linically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8452,availability,avail,available,8452,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:438,deployability,fail,failed,438,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1230,deployability,contain,containing,1230,"y default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1379,deployability,recov,recovery,1379,"the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/compariso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1439,deployability,recov,recovery,1439,"d filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://prec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1629,deployability,recov,recovery,1629,"ossible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1673,deployability,recov,recovery,1673," wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1718,deployability,recov,recovery,1718,"nt. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1766,deployability,recov,recovery,1766,"**5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1810,deployability,recov,recovery,1810,"d (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1857,deployability,recov,recovery,1857,"/github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I thi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1967,deployability,recov,recovery,1967,"rsus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA compar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2011,deployability,recov,recovery,2011," wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2056,deployability,recov,recovery,2056,"pts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2104,deployability,recov,recovery,2104,"well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2148,deployability,recov,recovery,2148,"complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 4145",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2195,deployability,recov,recovery,2195,"at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2520,deployability,recov,recovery,2520," for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3171,deployability,recov,recovery,3171,"%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3215,deployability,recov,recovery,3215,"rison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in ter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3545,deployability,recov,recovery,3545,"presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3616,deployability,recov,recovery,3616,"tting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4306,deployability,recov,recovery,4306,"for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4600,deployability,version,version,4600,"rtial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4713,deployability,recov,recovery,4713,"lts for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is *",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4757,deployability,recov,recovery,4757,"les (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4800,deployability,recov,recovery,4800," fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are hig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4846,deployability,recov,recovery,4846,"ack to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4888,deployability,recov,recovery,4888," both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4933,deployability,recov,recovery,4933,"ning the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4982,deployability,recov,recovery,4982,"e-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7135,deployability,observ,observations,7135," why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WG",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7345,deployability,continu,continuing,7345,"s/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:810,energy efficiency,Cloud,Cloud,810,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8219,energy efficiency,current,currently,8219,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:426,integrability,filter,filters,426,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:445,integrability,filter,filters,445,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1140,integrability,filter,filters,1140," you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full delet",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4199,integrability,filter,filtered,4199,"partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4600,integrability,version,version,4600,"rtial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4632,integrability,filter,filter,4632," for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7982,integrability,interfac,interface,7982,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8293,integrability,pub,public,8293,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8443,integrability,pub,publicly,8443,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2615,interoperability,format,formatting,2615,"full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP reco",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3364,interoperability,format,format,3364,"da.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7982,interoperability,interfac,interface,7982,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8069,interoperability,format,formatting,8069,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8321,interoperability,format,format,8321,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4600,modifiability,version,version,4600,"rtial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6428,modifiability,concern,concern,6428," precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7982,modifiability,interfac,interface,7982,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6544,performance,perform,performed,6544,".fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to crea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7159,performance,time,time,7159,"bers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://ww",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:438,reliability,fail,failed,438,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1379,reliability,recov,recovery,1379,"the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/compariso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1439,reliability,recov,recovery,1439,"d filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://prec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1629,reliability,recov,recovery,1629,"ossible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1673,reliability,recov,recovery,1673," wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1718,reliability,recov,recovery,1718,"nt. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1766,reliability,recov,recovery,1766,"**5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1810,reliability,recov,recovery,1810,"d (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1857,reliability,recov,recovery,1857,"/github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I thi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1967,reliability,recov,recovery,1967,"rsus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA compar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2011,reliability,recov,recovery,2011," wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2056,reliability,recov,recovery,2056,"pts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2104,reliability,recov,recovery,2104,"well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2148,reliability,recov,recovery,2148,"complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 4145",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2195,reliability,recov,recovery,2195,"at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2520,reliability,recov,recovery,2520," for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3171,reliability,recov,recovery,3171,"%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3215,reliability,recov,recovery,3215,"rison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in ter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3545,reliability,recov,recovery,3545,"presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3616,reliability,recov,recovery,3616,"tting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4306,reliability,recov,recovery,4306,"for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4713,reliability,recov,recovery,4713,"lts for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is *",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4757,reliability,recov,recovery,4757,"les (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4800,reliability,recov,recovery,4800," fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are hig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4846,reliability,recov,recovery,4846,"ack to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4888,reliability,recov,recovery,4888," both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4933,reliability,recov,recovery,4933,"ning the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4982,reliability,recov,recovery,4982,"e-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:5002,reliability,doe,does,5002,"th resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6659,reliability,availab,available,6659,"linically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8452,reliability,availab,available,8452,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:40,safety,test,testing,40,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1153,safety,compl,complex,1153,"oose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1364,safety,test,test,1364,"n_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1379,safety,recov,recovery,1379,"the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/compariso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1439,safety,recov,recovery,1439,"d filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://prec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1629,safety,recov,recovery,1629,"ossible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1673,safety,recov,recovery,1673," wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1718,safety,recov,recovery,1718,"nt. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1766,safety,recov,recovery,1766,"**5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1810,safety,recov,recovery,1810,"d (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1857,safety,recov,recovery,1857,"/github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I thi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1967,safety,recov,recovery,1967,"rsus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA compar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2011,safety,recov,recovery,2011," wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2056,safety,recov,recovery,2056,"pts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2104,safety,recov,recovery,2104,"well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2148,safety,recov,recovery,2148,"complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 4145",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2195,safety,recov,recovery,2195,"at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2520,safety,recov,recovery,2520," for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3171,safety,recov,recovery,3171,"%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3215,safety,recov,recovery,3215,"rison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in ter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3545,safety,recov,recovery,3545,"presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3616,safety,recov,recovery,3616,"tting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4306,safety,recov,recovery,4306,"for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4713,safety,recov,recovery,4713,"lts for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is *",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4757,safety,recov,recovery,4757,"les (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4800,safety,recov,recovery,4800," fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are hig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4846,safety,recov,recovery,4846,"ack to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4888,safety,recov,recovery,4888," both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4933,safety,recov,recovery,4933,"ning the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4982,safety,recov,recovery,4982,"e-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6589,safety,test,tested,6589,", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6659,safety,avail,available,6659,"linically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7603,safety,test,test,7603,"uinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8452,safety,avail,available,8452,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1153,security,compl,complex,1153,"oose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1379,security,recov,recovery,1379,"the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/compariso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1439,security,recov,recovery,1439,"d filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://prec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1629,security,recov,recovery,1629,"ossible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1673,security,recov,recovery,1673," wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1718,security,recov,recovery,1718,"nt. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1766,security,recov,recovery,1766,"**5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1810,security,recov,recovery,1810,"d (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1857,security,recov,recovery,1857,"/github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I thi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1967,security,recov,recovery,1967,"rsus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA compar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2011,security,recov,recovery,2011," wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2056,security,recov,recovery,2056,"pts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2104,security,recov,recovery,2104,"well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2148,security,recov,recovery,2148,"complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 4145",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2195,security,recov,recovery,2195,"at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:2520,security,recov,recovery,2520," for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3171,security,recov,recovery,3171,"%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3215,security,recov,recovery,3215,"rison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a *partial* recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in ter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3545,security,recov,recovery,3545,"presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:3616,security,recov,recovery,3616,"tting differences (such as with indels), I didnt feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4306,security,recov,recovery,4306,"for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4713,security,recov,recovery,4713,"lts for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is *",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4757,security,recov,recovery,4757,"les (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4800,security,recov,recovery,4800," fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are hig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4846,security,recov,recovery,4846,"ack to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4888,security,recov,recovery,4888," both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4933,security,recov,recovery,4933,"ning the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4982,security,recov,recovery,4982,"e-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6659,security,availab,available,6659,"linically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8452,security,availab,available,8452,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:40,testability,test,testing,40,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1364,testability,test,test,1364,"n_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6393,testability,verif,verification,6393,"** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6428,testability,concern,concern,6428," precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6589,testability,test,tested,6589,", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7135,testability,observ,observations,7135," why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WG",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7432,testability,understand,understanding,7432,"t the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7603,testability,test,test,7603,"uinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:756,usability,feedback,feedback,756,"Hi Again,. Ive had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and its not what I did), and I can also tell thats probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:1466,usability,close,close,1466," then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldnt expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out complex variants (with more than one variant at a position), but .vcf files containing those variants werent flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:. ```. 68759 / 72556 (94.8%) full SNP recovery. 71276 / 72556 (98.2%) partial SNP recovery. 3027 / 3648 (83.0%) full insertion recovery. 3413 / 3648 (93.6%) partial insertion recovery. 3119 / 3911 (79.7%) full deletion recovery. 3596 / 3911 (91.9%) partial deletion recovery. ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:. ```. 51417 / 54229 (94.8%) full SNP recovery. 53116 / 54229 (97.9%) partial SNP recovery. 1964 / 2391 (82.1%) full insertion recovery. 2242 / 2391 (93.8%) partial insertion recovery. 2058 / 2537 (81.1%) full deletion recovery. 2349 / 2537 (92.6%) partial deletion recovery. ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:4055,usability,close,closer,4055," and these are the statistics for the provided .vcf files (from my script):. ```. 39494 / 41450 (95.3%) full SNP recovery. 39678 / 41450 (95.7%) partial SNP recovery. ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and Im not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the *full* SNP recovery was higher for the provided variants, but the *partial* SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:5201,usability,indicat,indicates,5201,"d set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:5476,usability,consist,consistent,5476,"ttps://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```. 20765 / 21141 (98.2%) full SNP recovery. 20872 / 21141 (98.7%) partial SNP recovery. 243 / 258 (94.2%) full insertion recovery. 249 / 258 (96.5%) partial insertion recovery. 208 / 228 (91.2%) full deletion recovery. 213 / 228 (93.4%) partial deletion recovery. ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:. If you go to [explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed un",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:6544,usability,perform,performed,6544,".fda.gov/challenges/truth/results-explore)"", and select **func_cds** (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the truth set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and Im assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isnt really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to crea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7377,usability,support,support,7377,"independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). Ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7848,usability,support,supported,7848,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:7911,usability,user,users,7911,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8530,usability,user,users,8530,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/165:8634,usability,feedback,feedback,8634,"ieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You dont have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,. Charles.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/165
https://github.com/google/deepvariant/issues/166:463,availability,down,download,463,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:515,availability,down,download,515,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1009,availability,down,downloading,1009,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1046,availability,error,error,1046,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:30,energy efficiency,model,model,30,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:129,energy efficiency,model,model,129,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:211,energy efficiency,model,model,211,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:282,energy efficiency,model,model,282,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:352,energy efficiency,model,model,352,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:699,energy efficiency,model,models,699,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:815,energy efficiency,model,model,815,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:887,energy efficiency,model,model,887,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:945,energy efficiency,model,model,945,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1052,integrability,messag,message,1052,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1052,interoperability,messag,message,1052,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1046,performance,error,error,1046,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:444,safety,permiss,permissions,444,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:974,safety,test,tested,974,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1046,safety,error,error,1046,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:30,security,model,model,30,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:129,security,model,model,129,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:211,security,model,model,211,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:282,security,model,model,282,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:352,security,model,model,352,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:699,security,model,models,699,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:815,security,model,model,815,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:887,security,model,model,887,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:945,security,model,model,945,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:974,testability,test,tested,974,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:6,usability,help,helps,6,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:92,usability,user,user,92,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:101,usability,user,user,101,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:178,usability,user,user,178,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:187,usability,user,user,187,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:246,usability,user,user,246,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:255,usability,user,user,255,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:316,usability,user,user,316,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:325,usability,user,user,325,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:503,usability,command,commands,503,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:1046,usability,error,error,1046,"If it helps, this is what the model folder looks like:. ```. total 401316. -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001. -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta. -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1. ```. (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```. MODEL_VERSION=""0.7.2"". MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index. wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta. ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:198,availability,error,error,198,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:204,integrability,messag,message,204,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:204,interoperability,messag,message,204,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:98,performance,time,time,98,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:198,performance,error,error,198,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:7,safety,test,tested,7,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:198,safety,error,error,198,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:7,testability,test,tested,7,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:198,usability,error,error,198,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:308,usability,help,help,308,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:10,availability,error,error,10,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:438,availability,restor,restore,438,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:446,availability,operat,operator,446,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:513,availability,checkpoint,checkpoint,513,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:239,deployability,Fail,Failed,239,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:105,energy efficiency,core,core,105,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:527,energy efficiency,MODEL,MODEL,527,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:544,energy efficiency,MODEL,MODEL,544,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:580,energy efficiency,model,model,580,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:632,energy efficiency,MODEL,MODEL,632,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:739,energy efficiency,model,model,739,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:399,interoperability,format,format,399,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:10,performance,error,error,10,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:239,reliability,Fail,Failed,239,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:438,reliability,restor,restore,438,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:513,reliability,checkpoint,checkpoint,513,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:10,safety,error,error,10,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:527,security,MODEL,MODEL,527,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:544,security,MODEL,MODEL,544,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:580,security,model,model,580,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:632,security,MODEL,MODEL,632,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:739,security,model,model,739,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:10,usability,error,error,10,"From your error, it seems like here is the relevant part:. ```. 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator? ```. For the `call_variants` step, in this line:. ```. --checkpoint ""${MODEL}"". ```. `${MODEL}` is actually a prefix of the model file, not the directory. So, in your case, `${MODEL}` here should be:. `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`. not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:467,availability,error,error,467,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:486,availability,checkpoint,checkpoint,486,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:580,deployability,Updat,Update,580,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:113,energy efficiency,MODEL,MODEL,113,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:142,energy efficiency,model,model,142,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:384,energy efficiency,model,model,384,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:445,energy efficiency,model,model,445,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:539,modifiability,extens,extension,539,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:467,performance,error,error,467,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:486,reliability,checkpoint,checkpoint,486,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:467,safety,error,error,467,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:580,safety,Updat,Update,580,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:603,safety,reme,remembered,603,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:113,security,MODEL,MODEL,113,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:142,security,model,model,142,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:384,security,model,model,384,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:445,security,model,model,445,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:580,security,Updat,Update,580,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:258,usability,guid,guide,258,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:467,usability,error,error,467,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:636,usability,close,close,636,"Thank you very much for your prompt response, particularly on the weekend! I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works! If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:24,modifiability,concern,concern,24,"P.S. I was expressing a concern about the run-time, but **call_variants** was much faster than _make_examples_ (within 10-15 min)! In fact, it was also quicker than _postprocess_variants_ (>1 hr, but I am troubleshooting different issue). Nevertheless, I very much appreciate your help: I am definitely making progress!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:46,performance,time,time,46,"P.S. I was expressing a concern about the run-time, but **call_variants** was much faster than _make_examples_ (within 10-15 min)! In fact, it was also quicker than _postprocess_variants_ (>1 hr, but I am troubleshooting different issue). Nevertheless, I very much appreciate your help: I am definitely making progress!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:24,testability,concern,concern,24,"P.S. I was expressing a concern about the run-time, but **call_variants** was much faster than _make_examples_ (within 10-15 min)! In fact, it was also quicker than _postprocess_variants_ (>1 hr, but I am troubleshooting different issue). Nevertheless, I very much appreciate your help: I am definitely making progress!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:281,usability,help,help,281,"P.S. I was expressing a concern about the run-time, but **call_variants** was much faster than _make_examples_ (within 10-15 min)! In fact, it was also quicker than _postprocess_variants_ (>1 hr, but I am troubleshooting different issue). Nevertheless, I very much appreciate your help: I am definitely making progress!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:310,usability,progress,progress,310,"P.S. I was expressing a concern about the run-time, but **call_variants** was much faster than _make_examples_ (within 10-15 min)! In fact, it was also quicker than _postprocess_variants_ (>1 hr, but I am troubleshooting different issue). Nevertheless, I very much appreciate your help: I am definitely making progress!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:271,availability,error,error-prone,271,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:138,deployability,releas,release,138,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:298,deployability,releas,release,298,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:34,energy efficiency,model,model,34,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:57,energy efficiency,model,model,57,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:250,energy efficiency,model,model,250,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:229,interoperability,specif,specify,229,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:271,performance,error,error-prone,271,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:271,safety,error,error-prone,271,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:34,security,model,model,34,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:57,security,model,model,57,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:250,security,model,model,250,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:271,usability,error,error-prone,271,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/166:344,usability,feedback,feedback,344,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`. Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/166
https://github.com/google/deepvariant/issues/167:27,availability,error,error,27,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:255,deployability,depend,depending,255,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:141,energy efficiency,Current,Currently,141,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:428,energy efficiency,Current,Currently,428,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:255,integrability,depend,depending,255,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:255,modifiability,depend,depending,255,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:27,performance,error,error,27,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:75,performance,memor,memory,75,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:195,performance,memor,memory,195,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:248,performance,memor,memory,248,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:402,performance,memor,memory,402,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:27,safety,error,error,27,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:255,safety,depend,depending,255,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:255,testability,depend,depending,255,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:27,usability,error,error,27,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:39,usability,indicat,indicate,39,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:75,usability,memor,memory,75,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:195,usability,memor,memory,195,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:248,usability,memor,memory,248,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:402,usability,memor,memory,402,"Hi Charles,. the bad_alloc error could indicate that you're running out of memory on this machine. It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated. I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:194,availability,Cluster,Cluster,194,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:155,deployability,Resourc,Resource,155,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:194,deployability,Cluster,Cluster,194,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:149,energy efficiency,Cloud,Cloud,149,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:155,energy efficiency,Resourc,Resource,155,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:149,performance,Cloud Resourc,Cloud Resource,149,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:172,performance,Perform,Performance,172,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:155,safety,Resourc,Resource,155,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:155,testability,Resourc,Resource,155,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:172,usability,Perform,Performance,172,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:237,usability,person,personal,237,"Thank you - I will look into this. I was definitely not using 128 GB of RAM on AWS, so I will keep increasing this. I think you almost have to use a Cloud Resource or High-Performance Computing Cluster/Server for that: definitely not my personal home computer :(. While I also have WGS data, this is Exome data. I thought the _call_variants_ output seemed kind of small, but I don't know what is the typical size for this program.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:299,availability,cluster,cluster,299,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:299,deployability,cluster,cluster,299,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:325,deployability,instal,installed,325,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:578,deployability,configurat,configuration,578,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1155,deployability,updat,update,1155,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:196,energy efficiency,core,cores,196,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:225,energy efficiency,current,currently,225,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:359,energy efficiency,core,cores,359,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:657,energy efficiency,Cloud,Cloud,657,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:971,energy efficiency,core,cores,971,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1076,energy efficiency,Cloud,Cloud,1076,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:151,integrability,sub,submitted,151,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:530,integrability,Batch,Batch,530,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:578,integrability,configur,configuration,578,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:578,modifiability,configur,configuration,578,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:434,performance,time,time,434,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:530,performance,Batch,Batch,530,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1043,performance,perform,perform,1043,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:392,reliability,doe,doesn,392,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:235,safety,test,testing,235,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:823,safety,test,test,823,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1155,safety,updat,update,1155,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:578,security,configur,configuration,578,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1155,security,updat,update,1155,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:235,testability,test,testing,235,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:823,testability,test,test,823,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:62,usability,learn,learning,62,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:703,usability,clear,clear,703,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:751,usability,learn,learning,751,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1016,usability,confirm,confirm,1016,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1043,usability,perform,perform,1043,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1269,usability,command,command,1269,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:270,availability,error,error,270,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:423,deployability,log,logs,423,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:243,interoperability,format,format,243,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:257,interoperability,format,format,257,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:270,performance,error,error,270,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:270,safety,error,error,270,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:423,safety,log,logs,423,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:423,security,log,logs,423,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:204,testability,simpl,simply,204,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:423,testability,log,logs,423,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:204,usability,simpl,simply,204,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:270,usability,error,error,270,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:394,usability,help,helpful,394,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow. It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1272,availability,operat,operation,1272,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:112,energy efficiency,Cloud,Cloud,112,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:547,energy efficiency,Cloud,Cloud,547,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:650,energy efficiency,current,currently,650,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1287,integrability,sub,substantially,1287,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1393,integrability,topic,topic,1393,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:206,interoperability,format,format,206,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:213,interoperability,convers,conversion,213,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1167,interoperability,distribut,distributions,1167,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:329,performance,time,time,329,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:611,performance,time,time,611,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1263,performance,parallel,parallel,1263,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1318,performance,time,time,1318,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:353,reliability,doe,does,353,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:95,security,access,access,95,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:522,testability,plan,plan,522,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:926,testability,understand,understand,926,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:371,usability,experien,experience,371,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:700,usability,clear,clear,700,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:721,usability,user,users,721,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:775,usability,usab,usability,775,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:691,availability,cluster,clusters,691,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1576,availability,state,state,1576,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:45,deployability,orchestr,orchestrations,45,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:358,deployability,pipelin,pipelines,358,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:608,deployability,pipelin,pipeline,608,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:658,deployability,scale,scale,658,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:691,deployability,cluster,clusters,691,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:823,deployability,pipelin,pipeline,823,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:873,deployability,pipelin,pipeline,873,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1188,deployability,Pipelin,Pipeline,1188,"es. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1316,deployability,Pipelin,Pipeline,1316,"tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1744,deployability,pipelin,pipeline,1744,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1999,deployability,depend,depends,1999,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:39,energy efficiency,Cloud,Cloud,39,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:265,energy efficiency,Cloud,Cloud,265,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:289,energy efficiency,cloud,cloud,289,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:368,energy efficiency,optim,optimized,368,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:658,energy efficiency,scale,scale,658,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:687,energy efficiency,GPU,GPU,687,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:843,energy efficiency,GPU,GPU,843,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:972,energy efficiency,core,core,972,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:977,energy efficiency,CPU,CPU-only,977,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1220,energy efficiency,core,core,1220,"n these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1722,energy efficiency,optim,optimized,1722,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:45,integrability,orchestr,orchestrations,45,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:358,integrability,pipelin,pipelines,358,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:608,integrability,pipelin,pipeline,608,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:823,integrability,pipelin,pipeline,823,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:873,integrability,pipelin,pipeline,873,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1137,integrability,interfac,interface,1137,"st accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1188,integrability,Pipelin,Pipeline,1188,"es. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1316,integrability,Pipelin,Pipeline,1316,"tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1372,integrability,protocol,protocol,1372,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1576,integrability,state,state,1576,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1744,integrability,pipelin,pipeline,1744,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1999,integrability,depend,depends,1999,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2254,integrability,messag,message,2254,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:271,interoperability,Platform,Platform,271,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1046,interoperability,platform,platform,1046,"strations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1137,interoperability,interfac,interface,1137,"st accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1157,interoperability,platform,platform,1157,"tion, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1372,interoperability,protocol,protocol,1372,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1763,interoperability,platform,platform,1763,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2254,interoperability,messag,message,2254,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:215,modifiability,maintain,maintain,215,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:658,modifiability,scal,scale,658,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1137,modifiability,interfac,interface,1137,"st accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1999,modifiability,depend,depends,1999,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:368,performance,optimiz,optimized,368,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:658,performance,scale,scale,658,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:687,performance,GPU,GPU,687,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:843,performance,GPU,GPU,843,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:977,performance,CPU,CPU-only,977,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1103,performance,parallel,parallelized,1103,"de the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1247,performance,parallel,parallel,1247,"ant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1722,performance,optimiz,optimized,1722,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:206,reliability,doe,does,206,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2296,reliability,diagno,diagnose,2296,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:215,safety,maintain,maintain,215,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1999,safety,depend,depends,1999,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2040,safety,input,input,2040,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2117,safety,input,input,2117,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:201,security,team,team,201,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1351,security,auth,auth,1351,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1396,security,auth,auth,1396,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1999,testability,depend,depends,1999,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2296,testability,diagno,diagnose,2296,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:669,usability,support,support,669,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:775,usability,tool,tools,775,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:847,usability,support,support,847,"Hi Charles,. there are a few 3rd party Cloud orchestrations for DeepVariant that you can consider. I'll provide the links below. To get the most accurate information, please visit their websites. (Our team does not maintain these). * [Running DeepVariant on Google Cloud Platform](https://cloud.google.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1295,usability,support,support,1295,"le.com/genomics/docs/tutorials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to dia",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2040,usability,input,input,2040,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2117,usability,input,input,2117,"ials/deepvariant) | Docker-based pipelines optimized for cost and speed. Code can be found [here](https://github.com/googlegenomics/gcp-deepvariant-runner). * [DeepVariant-on-spark from ATGENOMIX](https://github.com/atgenomix/deepvariant-on-spark) | A germline short variant calling pipeline that runs DeepVariant on Apache Spark at scale with support for multi-GPU clusters (e.g. NVIDIA DGX-1). * [Parabricks](https://docs.parabricks.com/standalone-tools/deepvariant) | An accelerated DeepVariant pipeline with multi-GPU support that runs our WGS pipeline in just 40 minutes, at a cost of $2-$3 per sample. This provides a 7.5x speedup over a 64-core CPU-only machine at lower cost. * [DNAnexus DeepVariant App](https://platform.dnanexus.com/app/deepvariant_germline) | Offers parallelized execution with a GUI interface (requires platform account). * [Nextflow Pipeline](https://github.com/nf-core/deepvariant) | Offers parallel processing of multiple BAMs and Docker support. * [DNAstack Pipeline](https://app.dnastack.com/auth/realms/DNAstack/protocol/openid-connect/auth?client_id=dnastack-client&redirect_uri=https%3A%2F%2Fapp.dnastack.com%2F%3Fredirect_fragment%3D%252Forg%252F473079%252Fproj%252F473096%252Fapp%252Fworkflow%252F425685%252Frun&state=42231553-9fbc-4d71-a10e-d6ce42415c01&nonce=daf2568d-4fe7-48e2-ab60-858937244a87&response_mode=query&response_type=code&scope=openid) | Cost-optimized DeepVariant pipeline (requires platform account). However, I'm quite curious why 64G didn't work for you. I will need to check back to see how much our postprocess_variants use for the HG002 Case Study. I don't think it should need 64G of RAM. But it would certainly depends on your data and the size of the input. A few things to follow up:. (1) If you can let me know how big is the input file for postprocess_variants (output from call_variants), that might be useful information. (2) I'll follow up with you through a message to see what we can do in order to diagnose this particular run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1103,deployability,version,version,1103,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:208,energy efficiency,Cloud,Cloud,208,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:712,energy efficiency,current,currently,712,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1043,energy efficiency,current,currently,1043,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1462,energy efficiency,Cloud,Cloud,1462,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:276,integrability,Bridg,Bridges,276,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:556,integrability,Bridg,Bridges,556,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1103,integrability,version,version,1103,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:276,interoperability,Bridg,Bridges,276,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:556,interoperability,Bridg,Bridges,556,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1571,interoperability,platform,platform,1571,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1103,modifiability,version,version,1103,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1439,performance,time,time,1439,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1035,reliability,doe,doesn,1035,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:920,safety,test,test,920,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1468,safety,test,test,1468,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:168,security,command-lin,command-line,168,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:832,security,sign,sign,832,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:920,testability,test,test,920,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1468,testability,test,test,1468,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:168,usability,command,command-line,168,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:861,usability,user,user,861,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1174,usability,help,helpful,1174,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:334,availability,error,error,334,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:433,availability,cluster,cluster,433,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:433,deployability,cluster,cluster,433,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:153,energy efficiency,current,current,153,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:467,energy efficiency,core,cores,467,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:340,integrability,messag,message,340,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:340,interoperability,messag,message,340,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:334,performance,error,error,334,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:692,performance,memor,memory,692,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:773,performance,time,time,773,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:334,safety,error,error,334,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1076,safety,test,test,1076,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1112,safety,test,test,1112,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1179,safety,test,testing,1179,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1245,safety,compl,completes,1245,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1245,security,compl,completes,1245,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:821,testability,understand,understand,821,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1076,testability,test,test,1076,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1112,testability,test,test,1112,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1179,testability,test,testing,1179,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:131,usability,experien,experience,131,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:334,usability,error,error,334,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:692,usability,memor,memory,692,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1288,usability,close,close,1288,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1438,usability,close,close,1438,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning. **2)** After an 1-2 hours I would have expected to see that error message with the previous runs. **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:95,availability,error,error,95,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:303,deployability,stage,stage,303,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:101,integrability,messag,message,101,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:101,interoperability,messag,message,101,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:95,performance,error,error,95,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:95,safety,error,error,95,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:42,usability,help,help,42,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:73,usability,stop,stopped,73,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:95,usability,error,error,95,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:240,usability,document,documentation,240,"You are very welcome - thank you for your help! FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:983,availability,down,downloaded,983,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1025,availability,Down,Downloading,1025,"try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've notice",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1364,availability,Down,Download,1364,"_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:147,deployability,resourc,resource,147,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:147,energy efficiency,resourc,resource,147,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:308,energy efficiency,cloud,cloud,308,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:816,energy efficiency,cloud,cloud,816,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2096,energy efficiency,CPU,CPU,2096,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:288,interoperability,standard,standard-,288,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:468,interoperability,share,share,468,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:845,interoperability,standard,standard-,845,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:147,performance,resourc,resource,147,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:160,performance,time,time,160,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1623,performance,time,time,1623,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1994,performance,memor,memory,1994,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2096,performance,CPU,CPU,2096,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2105,performance,TIME,TIME,2105,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:147,safety,resourc,resource,147,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:998,safety,input,input,998,"i Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:891,security,ssh,ssh,891,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:956,security,ssh,ssh,956,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:147,testability,resourc,resource,147,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:669,usability,command,command,669,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:741,usability,USER,USER,741,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:926,usability,command,command,926,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:963,usability,USER,USER,963,"Hi Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:998,usability,input,input,998,"i Charles,. I had a chance to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:. It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1546,usability,command,command,1546,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1925,usability,user,user,1925,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1994,usability,memor,memory,1994,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2069,usability,USER,USER,2069,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2111,usability,COMMAND,COMMAND,2111,"**3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result. And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:. ```. gcloud compute instances create ""${USER}-1"" \. --image-family ""ubuntu-1604-lts"" \. --image-project ""ubuntu-os-cloud"" \. --machine-type ""n1-standard-1"" \. --zone ""us-west1-b"". ```. 2. I ssh'ed into the machine using this command:. ```. gcloud compute ssh ""${USER}-1"". ```. 3. I downloaded the input file needed:. ```. # Downloading the reference file takes a while. # It's only used for the header in postprocess_variants. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz. gunzip ucsc.hg19.fasta.gz. wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz. gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:. wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz. ```. 4. I pull the docker image, and run the command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. As I mentioned, this took:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:. ```. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND. 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python. ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS). ```. $ zcat output.vcf.gz | grep -v '^#' | wc -l. 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l. 78085. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:81,energy efficiency,Cloud,Cloud,81,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:239,energy efficiency,Cloud,Cloud,239,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:114,safety,test,test,114,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:114,testability,test,test,114,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:26,usability,command,commands,26,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:43,usability,help,helpful,43,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:56,usability,learn,learn,56,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:213,usability,confirm,confirm,213,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:217,deployability,resourc,resource,217,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:217,energy efficiency,resourc,resource,217,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:135,interoperability,compatib,compatible,135,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:217,performance,resourc,resource,217,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:161,safety,test,test,161,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:217,safety,resourc,resource,217,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:229,safety,test,test,229,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:384,safety,test,test,384,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:84,security,team,team,84,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:336,security,team,team,336,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:161,testability,test,test,161,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:217,testability,resourc,resource,217,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:229,testability,test,test,229,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:384,testability,test,test,384,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:393,usability,confirm,confirm,393,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why. Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:733,availability,servic,service,733,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:688,deployability,instal,install,688,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:733,deployability,servic,service,733,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:733,integrability,servic,service,733,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:733,modifiability,servic,service,733,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:252,performance,time,time,252,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:680,security,apt,apt,680,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:175,usability,command,command,175,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:539,usability,user,user,539,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:631,usability,experien,experience,631,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:935,usability,command,command,935,"@cwarden45 . I got a `t1.micro` machine on AWS , and I basically repeated what I did in https://github.com/google/deepvariant/issues/167#issuecomment-480150395. With the same command:. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \. -v ${PWD}:/data \. gcr.io/deepvariant-docker/deepvariant:0.7.2 \. /opt/deepvariant/bin/postprocess_variants \. --ref /data/ucsc.hg19.fasta \. --infile /data/call_variants_output.tfrecord.gz \. --outfile /data/output.vcf.gz. ```. It took me:. ```. real 0m24.779s. user 0m0.033s. sys 0m0.022s. ```. on a t1.micro AWS instance. A few differences from my GCP experience is:. (1) I had to use yum (instead of apt) to install docker. (2) I had to first run `sudo service docker start` before I pull and run the docker image. Other than these, everything seems mostly the same. At this point I have one more question for you -- where are your files located? In your command in the original post, they're from `/mnt`. Where are these files mounted from? In my setting, I wget all the files first. So that could be one difference that I can think of now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:295,availability,error,error,295,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:645,deployability,instal,installed,645,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1926,deployability,contain,contains,1926,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:301,integrability,messag,message,301,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:495,integrability,coupl,couple,495,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1335,integrability,sub,submitted,1335,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1369,integrability,Batch,Batch,1369,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1399,integrability,batch,batch,1399,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1520,integrability,sub,submitted,1520,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:301,interoperability,messag,message,301,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:495,modifiability,coupl,couple,495,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:295,performance,error,error,295,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1140,performance,time,time,1140,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1369,performance,Batch,Batch,1369,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1399,performance,batch,batch,1399,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:163,safety,test,test,163,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:206,safety,test,tested,206,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:295,safety,error,error,295,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1677,security,access,accessible,1677,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:163,testability,test,test,163,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:206,testability,test,tested,206,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:495,testability,coupl,couple,495,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1042,testability,understand,understanding,1042," weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1773,testability,understand,understanding,1773,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:132,usability,feedback,feedback,132,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:225,usability,command,command,225,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:295,usability,error,error,295,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1430,usability,help,helpful,1430,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1589,usability,feedback,feedback,1589,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:887,availability,error,error,887,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1150,deployability,stage,stage,1150,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1092,energy efficiency,Cloud,Cloud,1092,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1116,energy efficiency,current,currently,1116,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:893,integrability,messag,message,893,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:893,interoperability,messag,message,893,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:887,performance,error,error,887,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:96,safety,avoid,avoids,96,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:887,safety,error,error,887,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1098,safety,test,testing,1098,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1098,testability,test,testing,1098,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:233,usability,interact,interactively,233,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:328,usability,interact,interactive,328,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:455,usability,command,commands,455,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:887,usability,error,error,887,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:928,usability,command,command,928,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:936,usability,stop,stops,936,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1289,usability,help,help,1289,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```. OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant. REF=/mnt/efs-genome/Ref/hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:858,availability,error,error,858,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:157,deployability,contain,container,157,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:960,deployability,updat,update,960,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:68,energy efficiency,core,cores,68,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:864,integrability,messag,message,864,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:864,interoperability,messag,message,864,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:858,performance,error,error,858,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:858,safety,error,error,858,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:960,safety,updat,update,960,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:960,security,updat,update,960,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:170,usability,interact,interactive,170,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:230,usability,User,Users,230,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:244,usability,Document,Documents,244,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:765,usability,interact,interactive,765,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:858,usability,error,error,858,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1018,usability,experien,experience,1018,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```. OUTPUT_DIR=Genos_Provided. REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"". FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \. --ref ""${REF}"" \. --infile ""${CALL_VARIANTS_OUTPUT}"" \. --outfile ""${FINAL_OUTPUT_VCF}"". ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:404,availability,slo,slow-down,404,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:609,availability,error,error,609,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1025,availability,error,error,1025,"r instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1661,availability,Down,Downloaded,1661," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1970,availability,error,error,1970," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2050,availability,error,error,2050," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2135,availability,error,error,2135," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:234,deployability,instal,install,234,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:275,deployability,instal,installation,275,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:368,deployability,instal,install,368,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2285,deployability,Updat,Update,2285," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2599,energy efficiency,Cloud,Cloud,2599," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2625,energy efficiency,current,currently,2625," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:615,integrability,messag,message,615,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1031,integrability,messag,message,1031,"uctions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script sto",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1976,integrability,messag,message,1976," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2056,integrability,messag,message,2056," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2141,integrability,messag,message,2141," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2353,integrability,event,eventually,2353," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:615,interoperability,messag,message,615,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:693,interoperability,socket,socket,693,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1031,interoperability,messag,message,1031,"uctions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script sto",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1976,interoperability,messag,message,1976," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2056,interoperability,messag,message,2056," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2141,interoperability,messag,message,2141," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:609,performance,error,error,609,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1025,performance,error,error,1025,"r instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1970,performance,error,error,1970," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2050,performance,error,error,2050," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2135,performance,error,error,2135," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:404,reliability,slo,slow-down,404,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:193,safety,reme,remember,193,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:353,safety,test,test,353,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:609,safety,error,error,609,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:630,safety,permiss,permission,630,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:830,safety,permiss,permission,830,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1025,safety,error,error,1025,"r instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1243,safety,compl,complete,1243,"r on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1272,safety,compl,complete,1272,"nstallation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1301,safety,compl,complete,1301,"nd I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1330,safety,compl,complete,1330,"n't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1359,safety,compl,complete,1359," yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1388,safety,compl,complete,1388,", there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1417,safety,compl,complete,1417,"ulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker grou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1446,safety,compl,complete,1446,"ibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1475,safety,compl,complete,1475,"nce?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1504,safety,compl,complete,1504," terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh sess",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1533,safety,compl,complete,1533,"ker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1562,safety,compl,complete,1562,"everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1910,safety,input,input,1910," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1970,safety,error,error,1970," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2050,safety,error,error,2050," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2135,safety,error,error,2135," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2285,safety,Updat,Update,2285," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2364,safety,reme,remembered,2364," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2635,safety,test,testing,2635," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:491,security,sign,sign,491,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:693,security,soc,socket,693,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:726,security,soc,sock,726,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:765,security,soc,sock,765,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:815,security,soc,sock,815,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1243,security,compl,complete,1243,"r on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1272,security,compl,complete,1272,"nstallation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1301,security,compl,complete,1301,"nd I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1330,security,compl,complete,1330,"n't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1359,security,compl,complete,1359," yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1388,security,compl,complete,1388,", there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1417,security,compl,complete,1417,"ulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker grou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1446,security,compl,complete,1446,"ibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1475,security,compl,complete,1475,"nce?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1504,security,compl,complete,1504," terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh sess",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1533,security,compl,complete,1533,"ker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1562,security,compl,complete,1562,"everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1964,security,soc,sock,1964," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2285,security,Updat,Update,2285," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2500,security,ssh,ssh,2500," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2504,security,session,session,2504," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:353,testability,test,test,353,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2635,testability,test,testing,2635," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:553,usability,confirm,confirm,553,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:609,usability,error,error,609,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:920,usability,command,command,920,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:955,usability,stop,stopped,955,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1025,usability,error,error,1025,"r instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1653,usability,Statu,Status,1653," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1910,usability,input,input,1910," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:1970,usability,error,error,1970," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2032,usability,stop,stopped,2032," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2050,usability,error,error,2050," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2135,usability,error,error,2135," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2252,usability,progress,progress,2252," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2435,usability,user,usermod,2435," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2460,usability,user,user,2460," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:2523,usability,command,command,2523," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```. sudo sh run_deepvariant.sh. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally. latest: Pulling from deepvariant-docker/deepvariant. 18d680d61657: Pull complete. 0addb6fece63: Pull complete. 78e58219b215: Pull complete. eb6959a66df2: Pull complete. 54de1d38bbd7: Pull complete. d17c3563217d: Pull complete. ba1bdbdefce9: Pull complete. 94eba53c4ad9: Pull complete. 413f494b0501: Pull complete. 4d89363e7fb4: Pull complete. e9213d1ccf36: Pull complete. fb6121657d6b: Pull complete. Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest. docker images. terminate called after throwing an instance of 'std::bad_alloc'. what(): std::bad_alloc. ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:318,deployability,Stack,StackExchange,318,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:385,deployability,configurat,configuration,385,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:385,integrability,configur,configuration,385,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:115,interoperability,specif,specified,115,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:385,modifiability,configur,configuration,385,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:234,reliability,doe,doesn,234,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:385,security,configur,configuration,385,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:105,usability,command,commands,105,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:226,usability,Support,Support,226,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:442,usability,efficien,efficiently,442,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:503,usability,support,support,503,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:533,usability,close,close,533,"It took about 8 hours, but I could run the **postprocess_variants** step on my local computer (using the commands [specified above](https://github.com/google/deepvariant/issues/167#issuecomment-480640009)). If Official Amazon Support doesn't have a solution for running this program on AWS, I might cross-post this on StackExchange (to see if I can figure out if there is some sort of configuration issue on AWS, and/or if I am not using ECS efficiently/correctly). However, I realize you have a lot of support to provide, so I will close this ticket and provide the successful output from my local computer:. ```. 2019-04-07 21:06:30.591035: I deepvariant/postprocess_variants.cc:88] Read from: Genos_Provided/call_variants_output.tfrecord.gz. 2019-04-07 21:06:33.504711: I deepvariant/postprocess_variants.cc:97] Done reading: Genos_Provided/call_variants_output.tfrecord.gz. #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505181: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 91732. 2019-04-07 21:06:33.505270: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-04-07 21:06:34.914308: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I0407 21:06:36.217032 139687245461248 postprocess_variants.py:596] Writing output to VCF file: Genos_Provided/output.vcf.gz. I0407 21:06:36.221911 139687245461248 genomics_writer.py:163] Writing Genos_Provided/output.vcf.gz with NativeVcfWriter. I0407 21:06:36.231071 139687245461248 postprocess_variants.py:601] 1 variants written. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:133,availability,error,error,133,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:235,availability,error,error,235,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:346,availability,unavail,unavailable,346,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:891,availability,error,error,891,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:325,deployability,Resourc,Resource,325,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:325,energy efficiency,Resourc,Resource,325,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:139,integrability,messag,message,139,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:768,integrability,messag,messages,768,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:798,integrability,event,eventually,798,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:897,integrability,messag,message,897,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:139,interoperability,messag,message,139,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:768,interoperability,messag,messages,768,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:897,interoperability,messag,message,897,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:555,modifiability,variab,variable,555,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:133,performance,error,error,133,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:195,performance,memor,memory,195,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:235,performance,error,error,235,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:325,performance,Resourc,Resource,325,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:782,performance,time,time,782,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:891,performance,error,error,891,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:40,safety,test,testing,40,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:133,safety,error,error,133,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:235,safety,error,error,235,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:325,safety,Resourc,Resource,325,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:891,safety,error,error,891,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:40,testability,test,testing,40,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:112,testability,simpl,simple,112,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:325,testability,Resourc,Resource,325,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:112,usability,simpl,simple,112,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:133,usability,error,error,133,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:195,usability,memor,memory,195,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:235,usability,error,error,235,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:850,usability,help,helps,850,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:891,usability,error,error,891,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```. terminate called after throwing an instance of 'std::system_error'. what(): Resource temporarily unavailable. ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/167:31,usability,help,help,31,Yes - thank you again for your help!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/167
https://github.com/google/deepvariant/issues/168:308,deployability,pipelin,pipelines,308,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:15,energy efficiency,current,currently,15,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:65,energy efficiency,GPU,GPUs,65,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:114,energy efficiency,current,currently,114,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:280,energy efficiency,GPU,GPU,280,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:308,integrability,pipelin,pipelines,308,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:373,modifiability,maintain,maintaining,373,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:65,performance,GPU,GPUs,65,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:80,performance,parallel,parallelized,80,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:280,performance,GPU,GPU,280,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:373,safety,maintain,maintaining,373,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:32,usability,support,support,32,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:223,usability,tool,tools,223,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/168:284,usability,support,support,284,"Hi Tomasz,. We currently do not support running make_examples on GPUs, just the parallelized threads that you are currently using. However, you could consider [this external solution](https://docs.parabricks.com/standalone-tools/deepvariant) from Parabricks, which provides multi-GPU support for running our pipelines. Please note that we are not involved with creating or maintaining this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/168
https://github.com/google/deepvariant/issues/169:60,availability,error,error,60,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/169:288,deployability,instal,install,288,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/169:60,performance,error,error,60,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/169:60,safety,error,error,60,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/169:270,testability,understand,understand,270,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/169:42,usability,command,commands,42,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/169:60,usability,error,error,60,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/169
https://github.com/google/deepvariant/issues/170:273,reliability,doe,doesn,273,"Hi @jaqueytw, thanks for the question. If I'm understanding correctly, [this issue from earlier](https://github.com/google/deepvariant/issues/83) has a solution to your problem. I will check internally whether this is something we want to change now. If the above solution doesn't work, feel free to re-open this bug.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:46,testability,understand,understanding,46,"Hi @jaqueytw, thanks for the question. If I'm understanding correctly, [this issue from earlier](https://github.com/google/deepvariant/issues/83) has a solution to your problem. I will check internally whether this is something we want to change now. If the above solution doesn't work, feel free to re-open this bug.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:28,integrability,sub,substitution,28,"Hi @sidharthgoel. I did the substitution and used the GATK CombineGVCF and GenotypeGVCF. After that, I separated only the variants where the sample was genotyped with the alternate allele. The thing is that when I compared with the variants that deepvariant discovered in the single sample, it was different from the combined (see figure). Maybe, when we use another tool to process the gvcf created by deepvariant, some information are changed. I think that's not a good alternative. ![image](https://user-images.githubusercontent.com/45243234/55978465-3fe67c00-5c66-11e9-8bc3-a6dae36c7525.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:258,integrability,discover,discovered,258,"Hi @sidharthgoel. I did the substitution and used the GATK CombineGVCF and GenotypeGVCF. After that, I separated only the variants where the sample was genotyped with the alternate allele. The thing is that when I compared with the variants that deepvariant discovered in the single sample, it was different from the combined (see figure). Maybe, when we use another tool to process the gvcf created by deepvariant, some information are changed. I think that's not a good alternative. ![image](https://user-images.githubusercontent.com/45243234/55978465-3fe67c00-5c66-11e9-8bc3-a6dae36c7525.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:258,interoperability,discover,discovered,258,"Hi @sidharthgoel. I did the substitution and used the GATK CombineGVCF and GenotypeGVCF. After that, I separated only the variants where the sample was genotyped with the alternate allele. The thing is that when I compared with the variants that deepvariant discovered in the single sample, it was different from the combined (see figure). Maybe, when we use another tool to process the gvcf created by deepvariant, some information are changed. I think that's not a good alternative. ![image](https://user-images.githubusercontent.com/45243234/55978465-3fe67c00-5c66-11e9-8bc3-a6dae36c7525.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:258,usability,discov,discovered,258,"Hi @sidharthgoel. I did the substitution and used the GATK CombineGVCF and GenotypeGVCF. After that, I separated only the variants where the sample was genotyped with the alternate allele. The thing is that when I compared with the variants that deepvariant discovered in the single sample, it was different from the combined (see figure). Maybe, when we use another tool to process the gvcf created by deepvariant, some information are changed. I think that's not a good alternative. ![image](https://user-images.githubusercontent.com/45243234/55978465-3fe67c00-5c66-11e9-8bc3-a6dae36c7525.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:367,usability,tool,tool,367,"Hi @sidharthgoel. I did the substitution and used the GATK CombineGVCF and GenotypeGVCF. After that, I separated only the variants where the sample was genotyped with the alternate allele. The thing is that when I compared with the variants that deepvariant discovered in the single sample, it was different from the combined (see figure). Maybe, when we use another tool to process the gvcf created by deepvariant, some information are changed. I think that's not a good alternative. ![image](https://user-images.githubusercontent.com/45243234/55978465-3fe67c00-5c66-11e9-8bc3-a6dae36c7525.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:502,usability,user,user-images,502,"Hi @sidharthgoel. I did the substitution and used the GATK CombineGVCF and GenotypeGVCF. After that, I separated only the variants where the sample was genotyped with the alternate allele. The thing is that when I compared with the variants that deepvariant discovered in the single sample, it was different from the combined (see figure). Maybe, when we use another tool to process the gvcf created by deepvariant, some information are changed. I think that's not a good alternative. ![image](https://user-images.githubusercontent.com/45243234/55978465-3fe67c00-5c66-11e9-8bc3-a6dae36c7525.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:386,usability,clear,clear,386,"@xunjieli yes, I can. I only extracted the variants where the analyzed sample had the alternative allele (genotype 1/1,0/1,./1). I did this for the single vcf obtained from deepvariant and for the combined vcf (obtained from gatk using the gvcf created with deepvariant). Then, I compared only the variants (chromosome, position, reference and alternate allele) of this two sets. Is it clear?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:35,usability,tool,tool,35,"When you say ""_when we use another tool to process the gvcf created by deepvariant, some information are changed_,"" it might worth figuring out what exactly is changed. Without that info, the feedback isn't actionable.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:192,usability,feedback,feedback,192,"When you say ""_when we use another tool to process the gvcf created by deepvariant, some information are changed_,"" it might worth figuring out what exactly is changed. Without that info, the feedback isn't actionable.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:19,testability,understand,understand,19,"@xunjieli . Yes, I understand. I will look it further. Additionally, you should not encourage people to use GATK tools to process your vcf files, since it is changing the genotypes given originally by deepvariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:113,usability,tool,tools,113,"@xunjieli . Yes, I understand. I will look it further. Additionally, you should not encourage people to use GATK tools to process your vcf files, since it is changing the genotypes given originally by deepvariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:41,energy efficiency,current,currently,41,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:298,reliability,pra,practice,298,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:67,usability,user,users,67,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:85,usability,tool,tools,85,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:133,usability,document,documentation,133,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:326,usability,feedback,feedback,326,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:27,deployability,updat,update,27,"Hi @jaqueytw . I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r0.9/docs/trio-merge-case-study.md). We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:116,deployability,releas,release,116,"Hi @jaqueytw . I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r0.9/docs/trio-merge-case-study.md). We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:144,reliability,pra,practices,144,"Hi @jaqueytw . I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r0.9/docs/trio-merge-case-study.md). We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:27,safety,updat,update,27,"Hi @jaqueytw . I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r0.9/docs/trio-merge-case-study.md). We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:27,security,updat,update,27,"Hi @jaqueytw . I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r0.9/docs/trio-merge-case-study.md). We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/170:311,usability,user,users,311,"Hi @jaqueytw . I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r0.9/docs/trio-merge-case-study.md). We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/170
https://github.com/google/deepvariant/issues/171:322,availability,state,state,322,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1146,availability,slo,slow,1146," . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1538,availability,down,downloads,1538,"the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2715,availability,checkpoint,checkpoint,2715,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:279,deployability,configurat,configuration,279,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:390,deployability,pipelin,pipelines,390,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:557,deployability,orchestr,orchestration,557,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:688,deployability,orchestr,orchestration,688,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:833,deployability,orchestr,orchestration,833,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2527,deployability,updat,updating,2527,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2795,deployability,contain,container,2795,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:72,energy efficiency,estimat,estimate,72,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:103,energy efficiency,Cloud,Cloud,103,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:221,energy efficiency,core,core,221,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:226,energy efficiency,CPU,CPU-only,226,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:269,energy efficiency,optim,optimized,269,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:510,energy efficiency,estimat,estimates,510,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:551,energy efficiency,cloud,cloud-orchestration,551,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:623,energy efficiency,optim,optimized,623,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:960,energy efficiency,CPU,CPU,960,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1054,energy efficiency,estimat,estimation,1054,"es your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-empti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1084,energy efficiency,core,core,1084," hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1109,energy efficiency,core,core-hours,1109,"de upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at curr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1236,energy efficiency,core,core-hours,1236,"(which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1395,energy efficiency,CPU,CPU,1395,"es exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1449,energy efficiency,estimat,estimates,1449,"ant to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1501,energy efficiency,CPU,CPU-hours,1501,"our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mountin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1621,energy efficiency,Cloud,Cloud,1621,"ptimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1949,energy efficiency,clock,clock,1949,"ew your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genom",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1981,energy efficiency,CPU,CPU,1981,"ation used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2028,energy efficiency,CPU,CPU-hours,2028,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2097,energy efficiency,core,core-hour,2097,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2110,energy efficiency,current,current,2110,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2666,energy efficiency,Model,Models,2666,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2709,energy efficiency,model,model,2709,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2753,energy efficiency,model,models,2753,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2764,energy efficiency,model,model,2764,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:279,integrability,configur,configuration,279,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:322,integrability,state,state,322,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:390,integrability,pipelin,pipelines,390,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:557,integrability,orchestr,orchestration,557,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:688,integrability,orchestr,orchestration,688,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:833,integrability,orchestr,orchestration,833,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:199,interoperability,specif,specific,199,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1985,interoperability,standard,standard,1985,"used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:279,modifiability,configur,configuration,279,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:67,performance,time,time,67,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:124,performance,time,time,124,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:182,performance,perform,performance,182,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:226,performance,CPU,CPU-only,226,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:269,performance,optimiz,optimized,269,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:623,performance,optimiz,optimized,623,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:960,performance,CPU,CPU,960,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1395,performance,CPU,CPU,1395,"es exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1501,performance,CPU,CPU-hours,1501,"our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mountin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1955,performance,time,time,1955,"ur CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1981,performance,CPU,CPU,1981,"ation used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2028,performance,CPU,CPU-hours,2028,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:57,reliability,doe,does,57,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1146,reliability,slo,slow,1146," . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1379,reliability,Pra,Practices,1379,"rated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2267,reliability,doe,does,2267,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2715,reliability,checkpoint,checkpoint,2715,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1896,safety,test,tests,1896,"ware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --en",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2301,safety,permiss,permission,2301,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2527,safety,updat,updating,2527,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:279,security,configur,configuration,279,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:607,security,team,team,607,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1593,security,ident,identical,1593,"l to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1647,security,ident,identical,1647," However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2355,security,modif,modify,2355,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2527,security,updat,updating,2527,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2666,security,Model,Models,2666,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2709,security,model,model,2709,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2753,security,model,models,2753,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2764,security,model,model,2764,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2843,security,modif,modify,2843,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:35,testability,understand,understand,35,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:850,testability,understand,understand,850,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1896,testability,test,tests,1896,"ware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --en",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:182,usability,perform,performance,182,"Hi @cwarden45, just to make sure I understand correctly, does your time estimate of 24 hours on Google Cloud include upload time to the machine? 1a) . The 5 hour runtime is based on performance on a specific set-up: a 64-core CPU-only setup (which is not the most cost-optimized configuration for running DeepVariant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1303,usability,efficien,efficiently,1303,"Variant). We state this runtime as a baseline, and mention that many accelerated pipelines exist that allow WGS to run as fast as 40 minutes. I want to clarify the runtimes a bit more. Previously, our estimates for speed was based on the GCP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permissi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1603,usability,command,command,1603,"team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1721,usability,efficien,efficiency,1721,"ricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2169,usability,efficien,efficient,2169,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2367,usability,command,command,2367,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2808,usability,interact,interactive,2808,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2922,usability,user,user,2922,"ariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware? 1b). With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests? The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\). Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```. docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1411,availability,servic,service-account-scopes,1411,"tas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3317,availability,error,error,3317,"age cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3448,availability,state,state,3448,"t now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'paralle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3653,availability,state,state,3653,"sing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s do",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4662,availability,Error,Error,4662,"ation... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be intere",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4690,availability,error,error,4690,"lready the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4836,availability,error,error,4836,"ission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4847,availability,error,error,4847,"ed. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***Ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5339,availability,Error,Error,5339,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5367,availability,error,error,5367,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5490,availability,error,error,5490,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1258,deployability,pipelin,pipeline,1258,"eepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1341,deployability,pipelin,pipelines,1341,"=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1411,deployability,servic,service-account-scopes,1411,"tas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1488,deployability,log,logging,1488,"NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1572,deployability,log,log,1572,"nome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2034,deployability,version,version,2034,"ET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3414,deployability,Build,Building,3414,"stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3423,deployability,depend,dependency,3423," my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3502,deployability,version,version,3502," have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3527,deployability,upgrad,upgraded,3527,"and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Compute",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3545,deployability,instal,installed,3545," Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3578,deployability,upgrad,upgraded,3578,"ly beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Aver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3619,deployability,Build,Building,3619,"l close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3628,deployability,depend,dependency,3628,"e issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3711,deployability,version,version,3711,"have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3735,deployability,upgrad,upgraded,3735,"me) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3753,deployability,instal,installed,3753,"ome directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3786,deployability,upgrad,upgraded,3786,"ecause it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3828,deployability,log,logs,3828,"t it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4209,deployability,log,login,4209,"t.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4865,deployability,contain,container,4865,"tem 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4914,deployability,fail,failed,4914,"8maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5508,deployability,contain,container,5508,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5579,deployability,version,version,5579,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5643,deployability,version,versions,5643,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5697,deployability,version,version,5697,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5971,deployability,contain,container,5971,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:115,energy efficiency,core,cores,115,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:164,energy efficiency,Cloud,Cloud,164,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:220,energy efficiency,cloud,cloud,220,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:548,energy efficiency,Model,Model,548,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:596,energy efficiency,MODEL,MODEL,596,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:619,energy efficiency,model,models,619,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1070,energy efficiency,model,model,1070,"urs was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1078,energy efficiency,MODEL,MODEL,1078,"on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly wh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1467,energy efficiency,cloud,cloud-platform,1467,"t. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1919,energy efficiency,cloud,cloud,1919,"vided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2261,energy efficiency,Cloud,Cloud,2261,"ne. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2439,energy efficiency,Cloud,Cloud,2439,"/www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3891,energy efficiency,CPU,CPU,3891,"o"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4195,energy efficiency,Power,Power,4195,"run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4478,energy efficiency,CPU,CPU,4478,"is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4482,energy efficiency,core,cores,4482,"ready the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5829,energy efficiency,model,models,5829,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1175,integrability,filter,filter,1175,"he 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1258,integrability,pipelin,pipeline,1258,"eepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1341,integrability,pipelin,pipelines,1341,"=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1411,integrability,servic,service-account-scopes,1411,"tas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2034,integrability,version,version,2034,"ET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3323,integrability,messag,message,3323,"t is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3423,integrability,depend,dependency,3423," my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3448,integrability,state,state,3448,"t now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'paralle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3502,integrability,version,version,3502," have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3628,integrability,depend,dependency,3628,"e issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3653,integrability,state,state,3653,"sing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s do",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3711,integrability,version,version,3711,"have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4119,integrability,pub,publication,4119,"olved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5579,integrability,version,version,5579,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5643,integrability,version,versions,5643,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5697,integrability,version,version,5697,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1473,interoperability,platform,platform,1473,"STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3323,interoperability,messag,message,3323,"t is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5557,interoperability,specif,specifying,5557,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5570,interoperability,specif,specific,5570,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1411,modifiability,servic,service-account-scopes,1411,"tas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2034,modifiability,version,version,2034,"ET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3245,modifiability,paramet,parameter,3245," on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3391,modifiability,pac,package,3391,"ve started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel witho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3423,modifiability,depend,dependency,3423," my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3502,modifiability,version,version,3502," have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3527,modifiability,upgrad,upgraded,3527,"and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Compute",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3578,modifiability,upgrad,upgraded,3578,"ly beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Aver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3596,modifiability,pac,package,3596,"e of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3628,modifiability,depend,dependency,3628,"e issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3711,modifiability,version,version,3711,"have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating moun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3735,modifiability,upgrad,upgraded,3735,"me) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3786,modifiability,upgrad,upgraded,3786,"ecause it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5579,modifiability,version,version,5579,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5643,modifiability,version,versions,5643,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5697,modifiability,version,version,5697,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5836,modifiability,pac,pacbio,5836,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1860,performance,time,time,1860,"ROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3317,performance,error,error,3317,"age cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3475,performance,time,time,3475," there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers /",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3680,performance,parallel,parallel,3680," DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from da",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3891,performance,CPU,CPU,3891,"o"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4090,performance,Parallel,Parallel,4090,"ucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/R",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4167,performance,Parallel,Parallel,4167," quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4381,performance,Parallel,Parallel,4381,"ading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4444,performance,parallel,parallel,4444,"state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cw",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4478,performance,CPU,CPU,4478,"is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4662,performance,Error,Error,4662,"ation... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be intere",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4690,performance,error,error,4690,"lready the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4802,performance,time,time,4802,"annot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactiv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4836,performance,error,error,4836,"ission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4847,performance,error,error,4847,"ed. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***Ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4895,performance,parallel,parallel,4895,"gtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5339,performance,Error,Error,5339,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5367,performance,error,error,5367,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5490,performance,error,error,5490,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4914,reliability,fail,failed,4914,"8maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1488,safety,log,logging,1488,"NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1572,safety,log,log,1572,"nome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1839,safety,test,test,1839,"nner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mn",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2225,safety,test,testing,2225,"a \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without ad",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2952,safety,test,tested,2952,"n my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0maj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3180,safety,test,test,3180," is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3209,safety,test,test,3209,"inish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3317,safety,error,error,3317,"age cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3423,safety,depend,dependency,3423," my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3628,safety,depend,dependency,3628,"e issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3828,safety,log,logs,3828,"t it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3835,safety,Permiss,Permission,3835,"nt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=erro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4209,safety,log,login,4209,"t.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4551,safety,compl,completed,4551,"0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4597,safety,compl,complete,4597,"ge lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4662,safety,Error,Error,4662,"ation... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be intere",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4690,safety,error,error,4690,"lready the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4836,safety,error,error,4836,"ission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4847,safety,error,error,4847,"ed. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***Ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5339,safety,Error,Error,5339,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5367,safety,error,error,5367,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5490,safety,error,error,5490,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:548,security,Model,Model,548,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:596,security,MODEL,MODEL,596,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:619,security,model,models,619,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1070,security,model,model,1070,"urs was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1078,security,MODEL,MODEL,1078,"on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly wh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1462,security,auth,auth,1462,"iant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)*",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1488,security,log,logging,1488,"NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1572,security,log,log,1572,"nome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1665,security,command-lin,command-line,1665,"7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3828,security,log,logs,3828,"t it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4182,security,Command-Lin,Command-Line,4182,"d I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4209,security,log,login,4209,"t.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4551,security,compl,completed,4551,"0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4597,security,compl,complete,4597,"ge lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5829,security,model,models,5829,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1488,testability,log,logging,1488,"NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1572,testability,log,log,1572,"nome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1839,testability,test,test,1839,"nner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mn",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2225,testability,test,testing,2225,"a \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without ad",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2952,testability,test,tested,2952,"n my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0maj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3180,testability,test,test,3180," is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3209,testability,test,test,3209,"inish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3423,testability,depend,dependency,3423," my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3628,testability,depend,dependency,3628,"e issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3828,testability,log,logs,3828,"t it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4209,testability,log,login,4209,"t.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4876,testability,context,context,4876,"0elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5519,testability,context,context,5519,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:185,usability,command,command,185,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:786,usability,COMMAND,COMMAND,786,"Hi @gunjanbaid - thank you very much for your response! **1a)** The 18 hours was on an AWS _m5.2xlarge_ machine (8 cores, 32 GB of RAM). The 24 hours was on Google Cloud, using the 1st command in [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant):. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=cdw-deepvariant-wgs-exome. OUTPUT_BUCKET=gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/DeepVariant_Output. STAGING_FOLDER_NAME=wgs_staging. OUTPUT_FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1665,usability,command,command-line,1665,"7.2+data-wgs_standard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1681,usability,COMMAND,COMMAND,1681,"tandard. IMAGE_VERSION=0.7.2. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1792,usability,command,commands,1792,"opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --sample_name VeritasProvided \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \. --ref gs://cdw-genome/Ref/hg19.gatk.fasta \. --gcsfuse"". . # Run the pipeline. # run after 'gcloud config set compute/region """"'. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --regions us-west2 \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2625,usability,close,close,2625,"riant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:2896,usability,command,commands,2896,"that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avg",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:3317,usability,error,error,3317,"age cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4182,usability,Command,Command-Line,4182,"d I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4201,usability,Tool,Tool,4201,"touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4263,usability,help,helps,4263,"udo). However, I am unfortunately still getting an error message:. ```. sh deepvariant_run_Exome_BWA_MEM_by-step.sh. Reading package lists... Done. Building dependency tree. Reading state information... Done. time is already the newest version (1.7-25.1+b1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. Reading package lists... Done. Building dependency tree. Reading state information... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-M",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4662,usability,Error,Error,4662,"ation... Done. parallel is already the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be intere",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4690,usability,error,error,4690,"lready the newest version (20161222-1). 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. mkdir: cannot create directory logs: Permission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4836,usability,error,error,4836,"ission denied. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4847,usability,error,error,4847,"ed. 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***Ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:4884,usability,cancel,canceled,4884," 0%CPU (0avgtext+0avgdata 1828maxresident)k. 0inputs+0outputs (0major+73minor)pagefaults 0swaps. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5339,usability,Error,Error,5339,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5367,usability,error,error,5367,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5490,usability,error,error,5490,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5527,usability,cancel,canceled,5527,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5794,usability,interact,interactive,5794,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:5870,usability,command,command,5870,"arallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled"". parallel: This job failed:. sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0. docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists. ERRO[0000] error waiting for container: context canceled. ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue? Thank you very much for your assistance! Sincerely,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:924,availability,error,error,924,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:80,energy efficiency,core,core,80,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:110,energy efficiency,CPU,CPUs,110,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:127,energy efficiency,core,cores,127,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:189,energy efficiency,core,core-hours,189,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:371,energy efficiency,core,cores,371,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:398,energy efficiency,core,core,398,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:611,energy efficiency,optim,optimized,611,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:680,energy efficiency,Cloud,Cloud,680,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:793,integrability,repositor,repository,793,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:793,interoperability,repositor,repository,793,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:110,performance,CPU,CPUs,110,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:281,performance,time,time,281,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:611,performance,optimiz,optimized,611,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:924,performance,error,error,924,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:924,safety,error,error,924,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1112,safety,input,input,1112,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:231,usability,efficien,efficient,231,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:924,usability,error,error,924,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1059,usability,close,closely,1059,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1112,usability,input,input,1112,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1186,usability,clear,clearly,1186,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:104,energy efficiency,Cloud,Cloud,104,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:206,energy efficiency,Cloud,Cloud,206,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:506,energy efficiency,Cloud,Cloud,506,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:368,testability,understand,understand,368,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:187,usability,command,commands,187,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:394,usability,support,support,394,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:555,usability,help,help,555,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:597,usability,close,close,597,"Hi @AndrewCarroll -. Thank you very much for your response. Cost-wise, I thought the default for Google Cloud was reasonable, but the goal of my question was to see about running the AWS commands on Google Cloud (which it sounds like was a reasonable way to run DeepVariant, at least on AWS or a local system, if I got a newer computer / server). However, I certainly understand that you can't support all the details of running Docker (especially if there is another strategy to run DeepVariant on Google Cloud that I have working). So, I appreciate the help from you and @gunjanbaid, and I will close this ticket in order to allow you to focus on other issues. Best Wishes,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:837,availability,Servic,Service,837,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:862,availability,SLA,SLA,862,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:837,deployability,Servic,Service,837,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:68,energy efficiency,current,current,68,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:95,energy efficiency,core,core,95,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:100,energy efficiency,CPU,CPU-only,100,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:239,energy efficiency,core,cores,239,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:259,energy efficiency,core,cores,259,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:451,energy efficiency,core,core,451,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:458,energy efficiency,CPU,CPU-only,458,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:695,energy efficiency,core,cores,695,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:708,energy efficiency,cloud,cloud,708,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1040,energy efficiency,estimat,estimated,1040,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:837,integrability,Servic,Service,837,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:837,modifiability,Servic,Service,837,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:100,performance,CPU,CPU-only,100,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:322,performance,time,time,322,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:458,performance,CPU,CPU-only,458,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:911,performance,time,time,911,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:862,reliability,SLA,SLA,862,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1019,reliability,doe,does,1019,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:130,safety,compl,completes,130,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:130,security,compl,completes,130,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:16,testability,understand,understand,16,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:583,usability,user,users,583,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/171:1052,usability,minim,minimum,1052,"Also, I think I understand better what you were saying before:. The current quote is ""_On a 64-core CPU-only machine, DeepVariant completes a 50x WGS in 5 hours_"". I have ~25X WGS, so divide that by 2 (*2.5 hours*). However, I was using 8 cores instead of 64 cores, so multiply by 8 (*20 hours*). This matches the AWS run-time (*~18 hours*), but with an on-demand instance (without additional cost savings). My mistake is that I overlooked ""On a **64-core** CPU-only machine."" I apologize that it took me a little while to realize this, but I think this discussion may benefit other users (who probably don't have that on their local machine, or may want to decrease costs and not use that many cores on the cloud). On the cost side, the tutorial says ""*preemptible VMs, which are up to 80% cheaper than regular VMs...not covered by any Service Level Agreement (SLA), so if you require guarantees on turnaround time, do not use the --preemptible flag.*"" So, if my cost without the preemptible VMs is ~$10, 80% of that *does* match the $2-3 estimated **minimum preemptible** cost.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/171
https://github.com/google/deepvariant/issues/172:52,safety,valid,validation,52,This could be due to no examples were generated for validation set. When you run make_example step there multiple files generated. Could you attach one of the text files generated during make_example validation set step?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:200,safety,valid,validation,200,This could be due to no examples were generated for validation set. When you run make_example step there multiple files generated. Could you attach one of the text files generated during make_example validation set step?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:52,security,validat,validation,52,This could be due to no examples were generated for validation set. When you run make_example step there multiple files generated. Could you attach one of the text files generated during make_example validation set step?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:200,security,validat,validation,200,This could be due to no examples were generated for validation set. When you run make_example step there multiple files generated. Could you attach one of the text files generated during make_example validation set step?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:38,safety,valid,validation,38,"I attached two files. One is shuffled validation set, the other one is without shuffled. These data sets are from google quick-start test dataset. Region is chr20:10,005,000-10,008,000. . [validation_set_with_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082816/validation_set_with_shuffled.tar.gz). [validation_set_without_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082817/validation_set_without_shuffled.tar.gz). @akolesnikov Thanks very much.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:133,safety,test,test,133,"I attached two files. One is shuffled validation set, the other one is without shuffled. These data sets are from google quick-start test dataset. Region is chr20:10,005,000-10,008,000. . [validation_set_with_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082816/validation_set_with_shuffled.tar.gz). [validation_set_without_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082817/validation_set_without_shuffled.tar.gz). @akolesnikov Thanks very much.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:38,security,validat,validation,38,"I attached two files. One is shuffled validation set, the other one is without shuffled. These data sets are from google quick-start test dataset. Region is chr20:10,005,000-10,008,000. . [validation_set_with_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082816/validation_set_with_shuffled.tar.gz). [validation_set_without_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082817/validation_set_without_shuffled.tar.gz). @akolesnikov Thanks very much.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:133,testability,test,test,133,"I attached two files. One is shuffled validation set, the other one is without shuffled. These data sets are from google quick-start test dataset. Region is chr20:10,005,000-10,008,000. . [validation_set_with_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082816/validation_set_with_shuffled.tar.gz). [validation_set_without_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082817/validation_set_without_shuffled.tar.gz). @akolesnikov Thanks very much.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:14,deployability,contain,contains,14,Your eval set contains only 8 examples. Batch size is specified as 32. Number of examples should be greater than batch_size. You need to either set batch_size to something less than 8 or provide more examples in eval set.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:40,integrability,Batch,Batch,40,Your eval set contains only 8 examples. Batch size is specified as 32. Number of examples should be greater than batch_size. You need to either set batch_size to something less than 8 or provide more examples in eval set.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:54,interoperability,specif,specified,54,Your eval set contains only 8 examples. Batch size is specified as 32. Number of examples should be greater than batch_size. You need to either set batch_size to something less than 8 or provide more examples in eval set.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:40,performance,Batch,Batch,40,Your eval set contains only 8 examples. Batch size is specified as 32. Number of examples should be greater than batch_size. You need to either set batch_size to something less than 8 or provide more examples in eval set.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:29,integrability,batch,batch,29,"Thanks !!! You are right, my batch size is larger than my eval set. Where did you get 8? I read the *.pbtxt file in validation_set_with_shuffled. It says num_examples: 13. Not sure if that is the correct place to find out. @akolesnikov",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:29,performance,batch,batch,29,"Thanks !!! You are right, my batch size is larger than my eval set. Where did you get 8? I read the *.pbtxt file in validation_set_with_shuffled. It says num_examples: 13. Not sure if that is the correct place to find out. @akolesnikov",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:30,deployability,log,log,30,"It is at the beginning of the log. I copied it from your first post. `. Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3). I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:316,energy efficiency,model,model,316,"It is at the beginning of the log. I copied it from your first post. `. Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3). I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:30,safety,log,log,30,"It is at the beginning of the log. I copied it from your first post. `. Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3). I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:30,security,log,log,30,"It is at the beginning of the log. I copied it from your first post. `. Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3). I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:316,security,model,model,316,"It is at the beginning of the log. I copied it from your first post. `. Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3). I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/172:30,testability,log,log,30,"It is at the beginning of the log. I copied it from your first post. `. Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3). I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/172
https://github.com/google/deepvariant/issues/173:177,testability,simpl,simplicity,177,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:85,usability,user,users,85,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:105,usability,command,command,105,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:177,usability,simpl,simplicity,177,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:333,usability,support,support,333,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:499,usability,command,commands,499,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:678,usability,command,command,678,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/173:851,usability,close,close,851,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```. sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ . /opt/deepvariant/bin/make_examples. ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/173
https://github.com/google/deepvariant/issues/174:96,energy efficiency,model,model,96,"Hi Peter,. We used multiple HG002 samples generated with PacBio (CCS mode). We didn't test this model for CLR reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:57,modifiability,Pac,PacBio,57,"Hi Peter,. We used multiple HG002 samples generated with PacBio (CCS mode). We didn't test this model for CLR reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:86,safety,test,test,86,"Hi Peter,. We used multiple HG002 samples generated with PacBio (CCS mode). We didn't test this model for CLR reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:96,security,model,model,96,"Hi Peter,. We used multiple HG002 samples generated with PacBio (CCS mode). We didn't test this model for CLR reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:86,testability,test,test,86,"Hi Peter,. We used multiple HG002 samples generated with PacBio (CCS mode). We didn't test this model for CLR reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:925,deployability,resourc,resources,925,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:391,energy efficiency,model,model,391,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:722,energy efficiency,model,model,722,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:925,energy efficiency,resourc,resources,925,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:193,interoperability,specif,specifically,193,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:175,modifiability,Pac,PacBio,175,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:263,performance,perform,performed,263,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:887,performance,time,time,887,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:917,performance,compute resourc,compute resources,917,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:251,safety,test,testing,251,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:867,safety,compl,complicated,867,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:925,safety,resourc,resources,925,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:322,security,access,access,322,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:391,security,model,model,391,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:722,security,model,model,722,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:867,security,compl,complicated,867,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:905,security,sign,significant,905,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:251,testability,test,testing,251,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:925,testability,resourc,resources,925,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/174:263,usability,perform,performed,263,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/174
https://github.com/google/deepvariant/issues/175:270,modifiability,scenario,scenario,270,"Hi,. This can happen if you terminate things (ctrl-c) in the middle of a run, but sometimes the python processes are still running in the background. I also need to use top to inspect the jobs, and forcefully kill all DeepVariant jobs before I restart. This is the only scenario that I've seen this happen before. if you might be encountering other cases where things can override each other (for example, accidentally running two things that write to the same place), this could also happen. I'm going to close this issue, but if you think there might be something else going on, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:406,safety,accid,accidentally,406,"Hi,. This can happen if you terminate things (ctrl-c) in the middle of a run, but sometimes the python processes are still running in the background. I also need to use top to inspect the jobs, and forcefully kill all DeepVariant jobs before I restart. This is the only scenario that I've seen this happen before. if you might be encountering other cases where things can override each other (for example, accidentally running two things that write to the same place), this could also happen. I'm going to close this issue, but if you think there might be something else going on, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:506,usability,close,close,506,"Hi,. This can happen if you terminate things (ctrl-c) in the middle of a run, but sometimes the python processes are still running in the background. I also need to use top to inspect the jobs, and forcefully kill all DeepVariant jobs before I restart. This is the only scenario that I've seen this happen before. if you might be encountering other cases where things can override each other (for example, accidentally running two things that write to the same place), this could also happen. I'm going to close this issue, but if you think there might be something else going on, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:388,availability,cluster,cluster,388,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:152,deployability,contain,container,152,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:227,deployability,fail,failed,227,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:388,deployability,cluster,cluster,388,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:346,energy efficiency,schedul,scheduled,346,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:346,performance,schedul,scheduled,346,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:227,reliability,fail,failed,227,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:418,safety,avoid,avoided,418,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:306,usability,behavi,behavior,306,"@pichuan I just stumbled upon the same thing, and it took me quite a while to figure out what's going on there. I am running deepvariant v0.9.0 (docker container), and I found that there is quite a lot of files left behind for failed jobs under /tmp on the execution host. Can you comment on deepvariant's behavior when two (or more) DV jobs are scheduled to the same execution host in a cluster setup? Should that be avoided?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:494,availability,error,errors,494,"@ptrebert . One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names? Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:119,performance,time,time,119,"@ptrebert . One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names? Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:494,performance,error,errors,494,"@ptrebert . One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names? Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:494,safety,error,errors,494,"@ptrebert . One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names? Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:218,usability,user,user,218,"@ptrebert . One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names? Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:494,usability,error,errors,494,"@ptrebert . One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names? Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:173,availability,cluster,cluster,173,"@pichuan Thanks for getting back at me about this. I am processing a single dataset, but each chromosome in a separate DeepVariant job (i.e., a single execution host in the cluster may run the jobs for, say, chr17, chr12 and chr5 in parallel). My question now is if it is guaranteed that the files created underneath /tmp have distinct names. To me, it just looked like consecutive numbers, which could be the cause for the DataLossError I observed. The output files for the different jobs are of course different (carrying the respective chromosome name), but what about the temp file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:173,deployability,cluster,cluster,173,"@pichuan Thanks for getting back at me about this. I am processing a single dataset, but each chromosome in a separate DeepVariant job (i.e., a single execution host in the cluster may run the jobs for, say, chr17, chr12 and chr5 in parallel). My question now is if it is guaranteed that the files created underneath /tmp have distinct names. To me, it just looked like consecutive numbers, which could be the cause for the DataLossError I observed. The output files for the different jobs are of course different (carrying the respective chromosome name), but what about the temp file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:440,deployability,observ,observed,440,"@pichuan Thanks for getting back at me about this. I am processing a single dataset, but each chromosome in a separate DeepVariant job (i.e., a single execution host in the cluster may run the jobs for, say, chr17, chr12 and chr5 in parallel). My question now is if it is guaranteed that the files created underneath /tmp have distinct names. To me, it just looked like consecutive numbers, which could be the cause for the DataLossError I observed. The output files for the different jobs are of course different (carrying the respective chromosome name), but what about the temp file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:233,performance,parallel,parallel,233,"@pichuan Thanks for getting back at me about this. I am processing a single dataset, but each chromosome in a separate DeepVariant job (i.e., a single execution host in the cluster may run the jobs for, say, chr17, chr12 and chr5 in parallel). My question now is if it is guaranteed that the files created underneath /tmp have distinct names. To me, it just looked like consecutive numbers, which could be the cause for the DataLossError I observed. The output files for the different jobs are of course different (carrying the respective chromosome name), but what about the temp file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:440,testability,observ,observed,440,"@pichuan Thanks for getting back at me about this. I am processing a single dataset, but each chromosome in a separate DeepVariant job (i.e., a single execution host in the cluster may run the jobs for, say, chr17, chr12 and chr5 in parallel). My question now is if it is guaranteed that the files created underneath /tmp have distinct names. To me, it just looked like consecutive numbers, which could be the cause for the DataLossError I observed. The output files for the different jobs are of course different (carrying the respective chromosome name), but what about the temp file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:546,security,expos,exposed,546,"I just checked the code, and you're right that the temp file names will be the same:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. For now, please pass in different `intermediate_results_dir` for each run. For example:. `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:561,usability,user,users,561,"I just checked the code, and you're right that the temp file names will be the same:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. For now, please pass in different `intermediate_results_dir` for each run. For example:. `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:863,usability,user,user,863,"I just checked the code, and you're right that the temp file names will be the same:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. For now, please pass in different `intermediate_results_dir` for each run. For example:. `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/175:868,usability,experien,experience,868,"I just checked the code, and you're right that the temp file names will be the same:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. For now, please pass in different `intermediate_results_dir` for each run. For example:. `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/175
https://github.com/google/deepvariant/issues/176:358,deployability,releas,released,358,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/176:317,energy efficiency,current,currently,317,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/176:367,energy efficiency,model,models,367,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/176:408,energy efficiency,model,models,408,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/176:367,security,model,models,367,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/176:408,security,model,models,408,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/176:540,usability,visual,visualization,540,"Hi @yingchen69 . from your questions, it seems like you're asking whether you can change the height of the pileup image. I believe this previous GitHub issue is very similar, and it has a bunch of in-depth discussion: https://github.com/google/deepvariant/issues/62. A direct answer to your question:. DeepVariant is currently a germline variant caller. Our released models are trained for that purpose. The models are trained on data that are 221x100x6 in dimension (221 bases wide, 100 reads deep, 6 channels). You can see an example for visualization [here](https://github.com/google/deepvariant/blob/master/docs/visualizing_examples.ipynb). From [my answer in the earlier issue](https://github.com/google/deepvariant/issues/62#issuecomment-379107194), it is possible to change the pileup image height. However, even if you do that, it won't just work out of the box for you. I'm closing this issue, but feel free to ask if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/176
https://github.com/google/deepvariant/issues/177:50,modifiability,pac,package,50,"I've reached out to @chapmanb (owner of the conda package) to help take a look. (Brad, I still haven't got a chance to try it out myself recently. If there's anything that our team needs to fix, please let me know)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:176,security,team,team,176,"I've reached out to @chapmanb (owner of the conda package) to help take a look. (Brad, I still haven't got a chance to try it out myself recently. If there's anything that our team needs to fix, please let me know)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:62,usability,help,help,62,"I've reached out to @chapmanb (owner of the conda package) to help take a look. (Brad, I still haven't got a chance to try it out myself recently. If there's anything that our team needs to fix, please let me know)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:54,deployability,instal,install,54,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:91,deployability,instal,installing,91,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:240,deployability,instal,installing,240,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:402,energy efficiency,cloud,cloud-sdk,402,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:445,energy efficiency,cloud,cloud-sdk,445,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:315,safety,avoid,avoid,315,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:310,usability,help,help,310,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:499,usability,help,helps,499,"Peter;. Thanks for the report and apologies about the install issues. It looks like you're installing deepvariant in a python 3 environment, and it only works with python 2.7, which might be the source of the problems. Hopefully if you try installing with `'python=2.7'` as an additional requirement that will help avoid it. If you still hit issues, it might be a legit problem with the latest `google-cloud-sdk` and you could also add `'google-cloud-sdk<243.0.0'` as another requirement. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:21,deployability,instal,installing,21,Ah ok I figured that installing it fresh in an empty environment would by default force that environment to be python 2.7. let me try it with that extra requirement,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:15,availability,error,errors,15,I get the same errors with ```conda create -n deepvariant python=2.7 deepvariant```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:15,performance,error,errors,15,I get the same errors with ```conda create -n deepvariant python=2.7 deepvariant```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:15,safety,error,errors,15,I get the same errors with ```conda create -n deepvariant python=2.7 deepvariant```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:15,usability,error,errors,15,I get the same errors with ```conda create -n deepvariant python=2.7 deepvariant```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:226,deployability,depend,dependency,226,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:237,deployability,version,version,237,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:386,deployability,instal,installed,386,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:85,energy efficiency,cloud,cloud-sdk,85,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:338,energy efficiency,cloud,cloud-sdk,338,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:226,integrability,depend,dependency,226,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:237,integrability,version,version,237,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:95,modifiability,pac,packages,95,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:226,modifiability,depend,dependency,226,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:237,modifiability,version,version,237,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:19,safety,test,testing,19,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:226,safety,depend,dependency,226,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:256,safety,avoid,avoid,256,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:19,testability,test,testing,19,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:226,testability,depend,dependency,226,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:373,usability,help,helps,373,"Peter;. Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:. ```. conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. ```. Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:30,deployability,version,version,30,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:377,deployability,depend,dependency,377,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:388,deployability,version,version,388,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:537,deployability,instal,installed,537,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:20,energy efficiency,cloud,cloud-sdk,20,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:230,energy efficiency,cloud,cloud-sdk,230,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:489,energy efficiency,cloud,cloud-sdk,489,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:30,integrability,version,version,30,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:377,integrability,depend,dependency,377,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:388,integrability,version,version,388,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:30,modifiability,version,version,30,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:240,modifiability,pac,packages,240,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:377,modifiability,depend,dependency,377,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:388,modifiability,version,version,388,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:161,safety,test,testing,161,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:377,safety,depend,dependency,377,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:407,safety,avoid,avoid,407,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:593,security,auth,authored,593,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:813,security,auth,auth,813,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:161,testability,test,testing,161,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:377,testability,depend,dependency,377,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:524,usability,help,helps,524,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>. wrote:. > Peter;. > Thanks for testing, it sounds like there is a problem with the recent. > google-cloud-sdk packages. I'll take a look to see if I can figure out what. > is going wrong but an immediate thing you could try is to restrict that. > dependency version to try and avoid the issue:. >. > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'. >. > Hope this helps get it installed. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:67,deployability,updat,update,67,Thanks @chapmanb so much for you help. And Thanks @pjedge for your update. . I'm closing this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:67,safety,updat,update,67,Thanks @chapmanb so much for you help. And Thanks @pjedge for your update. . I'm closing this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:67,security,updat,update,67,Thanks @chapmanb so much for you help. And Thanks @pjedge for your update. . I'm closing this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:33,usability,help,help,33,Thanks @chapmanb so much for you help. And Thanks @pjedge for your update. . I'm closing this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:105,availability,replic,replicate,105,"Peter;. Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:225,availability,down,download,225,"Peter;. Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:66,deployability,instal,installed,66,"Peter;. Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:256,energy efficiency,cloud,cloud-sdk,256,"Peter;. Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:266,modifiability,pac,package,266,"Peter;. Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:136,safety,avoid,avoid,136,"Peter;. Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:222,availability,down,download,222,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:304,availability,error,error,304,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:406,availability,ERROR,ERROR,406,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:464,availability,error,error,464,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:886,availability,ERROR,ERROR,886,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:926,availability,error,error,926,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1681,availability,error,error,1681,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1940,availability,error,error,1940,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:16,deployability,instal,installing,16,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:52,deployability,instal,install,52,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:231,deployability,instal,install,231,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:239,deployability,updat,update,239,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:289,deployability,fail,fails,289,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:485,deployability,instal,installing,485,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:593,deployability,fail,failed,593,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:757,deployability,fail,failed,757,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:867,deployability,roll,roll,867,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:878,deployability,fail,failed,878,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:947,deployability,instal,installing,947,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1055,deployability,fail,failed,1055,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1219,deployability,fail,failed,1219,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1329,deployability,roll,roll,1329,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1340,deployability,Roll,Rolling,1340,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1400,deployability,fail,failed,1400,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1564,deployability,fail,failed,1564,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1687,deployability,instal,installing,1687,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1712,deployability,instal,install,1712,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1756,deployability,instal,install,1756,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:418,energy efficiency,core,core,418,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:898,energy efficiency,core,core,898,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1868,energy efficiency,cloud,cloud-sdk,1868,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:831,integrability,messag,messages,831,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1293,integrability,messag,messages,1293,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1638,integrability,messag,messages,1638,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:831,interoperability,messag,messages,831,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1293,interoperability,messag,messages,1293,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1638,interoperability,messag,messages,1638,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:117,modifiability,pac,package,117,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:210,modifiability,pac,packages,210,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:496,modifiability,pac,package,496,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:604,modifiability,pac,package,604,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:958,modifiability,pac,package,958,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1066,modifiability,pac,package,1066,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1411,modifiability,pac,package,1411,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:304,performance,error,error,304,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:406,performance,ERROR,ERROR,406,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:464,performance,error,error,464,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:886,performance,ERROR,ERROR,886,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:926,performance,error,error,926,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1681,performance,error,error,1681,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1940,performance,error,error,1940,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:289,reliability,fail,fails,289,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:593,reliability,fail,failed,593,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:757,reliability,fail,failed,757,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:878,reliability,fail,failed,878,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1055,reliability,fail,failed,1055,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1219,reliability,fail,failed,1219,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1400,reliability,fail,failed,1400,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1564,reliability,fail,failed,1564,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:239,safety,updat,update,239,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:304,safety,error,error,304,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:406,safety,ERROR,ERROR,406,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:464,safety,error,error,464,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:886,safety,ERROR,ERROR,886,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:926,safety,error,error,926,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1681,safety,error,error,1681,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1940,safety,error,error,1940,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:239,security,updat,update,239,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:170,testability,verif,verifies,170,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:352,testability,Verif,Verifying,352,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:304,usability,error,error,304,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:406,usability,ERROR,ERROR,406,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:464,usability,error,error,464,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:684,usability,command,command,684,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:886,usability,ERROR,ERROR,886,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:926,usability,error,error,926,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
